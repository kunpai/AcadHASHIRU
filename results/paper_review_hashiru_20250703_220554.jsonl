{"paper_id": "ZTK3SefE8_Z", "prompt": "Review the following paper for International Conference on Learning Representations (ICLR) 2023. Remember you need to make 3 reviewer agents for each paper. GIVE A FINAL DECISION in the form of \"FINAL DECISION: <Accept/Reject>\". The paper title is: Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search\n\n1 INTRODUCTION: We usually learn the behavior of a nonlinear dynamical system through its nonlinear governing differential equations. These equations can be formulated as y\u0307(t) = dy/dt = F(y(t)), where y(t) = {y1(t), y2(t), ..., yn(t)} \u2208 R1\u00d7n denotes the system state at time t, F(\u00b7) a nonlinear function set defining the state motions and n the system dimension. The explicit form of F(\u00b7) for some nonlinear dynamics remains underexplored. For example, in a mounted double pendulum system, the mathematical description of the underlying physics might be unclear due to unknown viscous and frictional damping forms. These uncertainties yield critical demands for the discovery of nonlinear dynamics given observational data. Nevertheless, distilling the analytical form of governing equations from limited noisy data, commonly seen in practice, is an intractable challenge. Ever since the early work on the data-driven discovery of nonlinear dynamics (D\u017eeroski & Todorovski, 1993; Dzeroski & Todorovski, 1995), many scientists have stepped into this field of study. In the recent decade, the escalating advances in machine learning, data science, and computing power enabled several milestone efforts of unearthing the governing equations for nonlinear dynamical systems. Notably, a breakthrough model named SINDy based on sparse regression method (Brunton et al., 2016) shedded light on this field of study. SINDy was invented to determine the sparse solution among a pre-defined basis function library recursively through a sequential threshold ridge regression (STRidge) algorithm. SINDy quickly became one of the state-of-art methods and kindled significant enthusiasm in this field of study (Rudy et al., 2017; Long et al., 2018; Champion et al., 2019; Chen et al., 2021; Sun et al., 2021; Rao et al., 2022). However, the success of this sparsity-promoting approach relies on a properly defined candidate function library that requires prior knowledge of the system. It is also restricted by the fact that a linear combination of candidate functions might be insufficient to recover complicated mathematical expressions. Moreover, when the library size is massive, it empirically fails to hold the sparsity constraint. At the same time, attempts have been made to tackle the nonlinear dynamics discovery problems by introducing neural networks with activation functions replaced by commonly seen mathematical operators (Martius & Lampert, 2017; Sahoo et al., 2018; Kim et al., 2019; Long et al., 2019). The intricate formulas are obtained via the well-trained symbolic network expansion. This interpretation of physics laws results in larger candidate pools compared to the library-based representation of physics employed by SINDy. Nevertheless, since the sparsity of discovered expressions is primarily achieved by empirical pruning of the weights, this framework exhibits sensitivity to user-defined thresholds and may fall short to produce parsimonious governing equations for noisy and scarce data. Alternatively, another benchmark work (Bongard & Lipson, 2007; Schmidt & Lipson, 2009) reenvisioned the data-driven nonlinear dynamics discovery tasks by casting them into symbolic regression problems which have been profoundly resolved by the genetic programming (GP) approach (Koza & Koza, 1992; Billard & Diday, 2003). Under this framework, a symbolic regressor is established to identify the differential equations that best describe the underlying governing physical laws through the free combination of mathematical operations and symbols, leveraging great flexibility (i.e, free combination of symbols and operators) in model selection. One essential weakness of this early methodology is that driven exclusively by the goal of empirically seeking the best-fitting expression (e.g. minimizing the mean-square error) in a genetic expansion process, the GP-based model usually overfits the target system with numerous false-positive terms under data noise, even sometimes at a subtle level, causing huge instability and uncertainty. However, this ingenious idea inspired a series of subsequent endeavors (Cornforth & Lipson, 2012; Gaucel et al., 2014; Ly & Lipson, 2012; Quade et al., 2016; Vaddireddy et al., 2020). In a more recent work titled Deep Symbolic Regression (Petersen et al., 2021; Mundhenk et al., 2021), a reinforcement learning-based model for symbolic regression was fabricated and generally outperformed the GP based models including the commercial Eureqa (Langdon & Gustafson, 2010) software. Additionally, the AI-Feynman methods (Udrescu & Tegmark, 2020; Udrescu et al., 2020; Udrescu & Tegmark, 2021) ameliorated the symbolic regression algorithm for distilling physics law from data by combining neural network fitting with a suite of physics-inspired techniques. This approach is also highlighted by a recursive decomposition of a complicated mathematical expression into different parts on a tree-based graph, which disentangles the original problem and speeds up the discovery. It outperformed Eureqa in the data-driven uncovering of Feynman physics equations (Feynman et al., 1965). The popularity of adopting the tree-based symbolic reasoning of mathematical formulas (Lample & Charton, 2019) has been rising recently to uncover unknown mathematical expressions with a reinforcement learning agent (Kubal\u00edk et al., 2019; Petersen et al., 2021; Mundhenk et al., 2021). However, some former work attempting to apply the Monte Carlo tree search (MCTS) algorithm as an alternative to GP for symbolic regression (Cazenave, 2013; White et al., 2015; Islam et al., 2018; Lu et al., 2021) failed to leverage the full flexibility of this algorithm, resulting in the similar shortage with GP-based symbolic regressors as discussed earlier. Despite these outcomes, we are conscious of the strengths of the MCTS algorithm in equation discovery: it enables the flexible representation of search space with customized computational grammars to guide the search tree expansion. A sound mathematical underpinning for the trade-off between exploration and exploitation is remarkably advantageous as well. These features make it possible to guide the MCTS agent by prior physics knowledge in nonlinear dynamics discovery rather than randomly searching in large spaces. Contribution. We propose a promising model named Symbolic Physics Learner (SPL) machine, empowered by MCTS, for discovery of nonlinear dynamics. This architecture relies on a grammar composed of computational rules and symbols to guide the search tree spanning and a composite objective rewarding function to simultaneously evaluate the generated mathematical expressions with observational data and enforce sparsity of the expression. Moreover, we design multiple adjustments to the conventional MCTS by: (1) replacing the expected reward in UCT score with maximum reward to better fit the equation discovery objective, (2) employing an adaptive scaling in policy evaluation which would eliminate the uncertainty of the reward value range owing to the unknown error of the system state derivatives, and (3) transplanting modules with high returns to the subsequent search as a single leaf node. With these adjustments, the SPL machine is capable of efficiently uncovering the best path to formulate the complex governing equations of the target dynamical system. 2 BACKGROUND: In this section, we expand and explain the background concepts brought up in the introduction to the SPL architecture, including the expression tree (parse tree) and the MCTS algorithm. Expression tree. Any mathematical expression can be represented by a combinatorial set of symbols and mathematical operations and further expressed by a parse tree structure, (Hopcroft et al., 2006; Kusner et al., 2017), which is empowered by a context-free grammar (CFG). A CFG is a formal grammar characterized by a tuple comprised of 4 elements G = (V,\u03a3, R, S), where V denotes a finite set of non-terminal nodes, \u03a3 a finite set of terminal nodes, R a finite set of production rules, each interpreted as a mapping from a single non-terminal symbol in V to one or multiple terminal/non-terminal nodes in (V \u222a\u03a3)\u2217 where \u2217 represents the Kleene star operation, and S a single non-terminal node standing for a start symbol. In our work, equations are symbolized into parse trees: we define the start node as equation symbol f , terminal symbols (leaf nodes) corresponding to the independent variables from the equation (e.g, x, y), and a placeholder symbol C for identifiable constant coefficients that stick to specific production rules. The non-terminal nodes between root and leaf nodes are represented by some symbols distinct from the start and terminal nodes (i.e., M ). The production rules denote the commonly seen mathematical operators: unary rules (one non-terminal node mapping to one node) for operators like cos(\u00b7), exp(\u00b7), log(| \u00b7 |), and binary rules (one non-terminal node mapping to two nodes) for operators such as +, \u2212, \u00d7, \u00f7. A parse tree is then generated via a pre-order traversal of production rules rooted at f and terminates when all leaf nodes are entirely filled with terminal symbols. Each mathematical expression can be denoted as such a traversal set of production rules. Monte Carlo tree search. Monte Carlo tree search (MCTS) (Coulom, 2006) is an algorithm for searching optimal decisions in large combinatorial spaces represented by search trees. This technique complies with the best-first search principle based on the evaluations of stochastic simulations. It has already been widely employed in and proved the spectacular success by various gaming artificial intelligence systems, including the famous AlphaGo and AlphaZero (Silver et al., 2017) for computer Go game. A basic MCTS algorithm can be regarded as an iterative process of four steps: 1. Selection. The MCTS agent, starting from the root node, moves through the visited nodes of the search tre and selects the next node according to a given selection policy until it reaches an expandable node or a leaf node. 2. Expansion. At an an expandable node, the MCTS agent expands the search tree by selecting one of its unvisited children. 3. Simulation. After expansion, if the current node is non-terminal, the agent performs one or multiple independent simulations starting from the current node until reaching the terminal state. In this process, actions are randomly selected. 4. Backpropagation. Statistics of nodes along the path from the current node to the root are updated with respect to search results (scores evaluated from the terminate states reached). To maintain a proper balance between the less-tested paths and the best policy identified so far, the MCTS agent stikcs to a trade-off between exploration and exploitation through selecting the action that maximizes the Upper Confidence Bounds applied for Trees (UCT), which is formulated as: UCT (s, a) = Q(s, a) + c \u221a ln[N(s)]/N(s, a) (1) where Q(s, a) denotes the average result/reward of playing action a in state s in the simulations performed in the history, encouraging the exploitation of current best child node; N(s) denotes number of times state s has been visited, N(s, a) the number of times action a has been selected at state s, and \u221a ln[N(s)]/N(s, a) consequently encourages the exploration of less-visited child nodes. Constant c controls the balance between exploration and exploitation and is usually empirically defined depend on the specific problem. 3 METHODS: It has been demonstrated that the MCTS agent continuously gains knowledge of the given discovery task via the expansion of the search tree and, based on the backpropagation of evaluation results (i.e., rewards and number of visits), render a proper selection policy on visited states to guide the upcoming searching. In the proposed SPL machine, this process is integrated with the symbolic reasoning of mathematical expressions to reproduce and evaluate valid mathematical expressions of the physics laws in nonlinear dynamics step-by-step, and then obtain a favorable selection policy pointing to the best solution. This algorithm is depicted in Figure 1 with an illustrative example and its overall training scheme is shown in Algorithm 1. Rewarding. To evaluate the mathematical expression f\u0303 projected from a parse tree, we define a numerical reward r \u2208 R \u2282 R based on this expression and input data D = {Y; Y\u0307i}, serving as the search result of the current expansion or simulation. It is formulated as r = \u03b7n 1 + \u221a 1 N \u2225\u2225Y\u0307i \u2212 f\u0303(Y)\u2225\u222522 (2) where Y = {y1,y2, ...,ym} \u2208 Rm\u00d7N is the m dimensional system state variables, Y\u0307i \u2208 R1\u00d7N the numerically estimated state derivative for ith dimension, and N the number of measurement data points. \u03b7 denotes a discount factor, assigned slightly smaller than 1; n is empirically defined as the total number of production rules in the parse tree. This numerator arrangement is designated to penalize non-parsimonious solutions. This rewarding formulation outputs a reasonable assessment to the distilled equations and encourages parsimonious solution by discounting the reward of a non-parsimonious one. The rooted mean square error (RMSE) in denominator evaluates the goodnessof-fit of the discovered equation w.r.t. the measurement data. Training scheme. A grammar G = (V,\u03a3, R, S) is defined with appropriate nodes and production rules to cover all possible forms of equations. To keep track of non-terminal nodes of the parsing tree, we apply a last-in-first-out (LIFO) strategy and denote the non-terminal node placed last on the stack NT as the current node. We define the action space A = R and the state space S as all possible traversals of complete/incomplete parse trees (i.e., production rules selected) in ordered sequences. At the current state st = [a1, a2, ...at] where t \u2208 N is the discrete traversal step-index of the upcoming production rule, the MCTS agent masks out the invalid production rules for current non-terminal node and on that basis selects a valid rule as action at+1 (i.e, the left-hand side of a valid production rule is the current non-terminal symbol). Consequently, the parse tree gains a new terminal/non-terminal branch in accordance with at+1, meanwhile the agent finds itself in a new state st+1 = [a1, a2, ...at, at+1]. The agent subsequently pops off the current non-terminal symbol from NT and pushes the non-terminal nodes, if there are any, on the right-hand side of the selected rule onto the stack. Once the agent attains an unvisited node, a certain amount of simulations are performed, where the agent starts to randomly select the next node until the parse tree is completed. Algorithm 1: Training the SPL machine for ith dimension governing equation discovery 1 Input: Grammar G = (V,\u03a3, R, S), measurement data D = {Y; Y\u0307i}; 2 Parameters: discount factor \u03b7, exploration rate c, tmax; 3 Output: Optimal governing equation f\u0303\u22c6; 4 for each episode do 5 Selection: Initialize s0 = \u2205, t = 0, NT = [S]; 6 while st expandable and t < tmax do 7 Choose at+1 = argmaxA UCT (st, a); 8 Take action at+1, observe s\u2032, NT ; 9 st+1 \u2190 s\u2032 note as visited, t\u2190 t+ 1; 10 end 11 Expansion: Randomly take an unvisited path with action a, observe s\u2032, NT ; 12 st+1 \u2190 s\u2032 note as visited, t\u2190 t+ 1; 13 if NT = \u2205 then 14 Project f\u0303 , Backpropagate rt+1 and visited count and finish the episode; 15 end 16 Simulation: Fix the starting point st, NT ; 17 for each simulation do 18 while st non-terminal and t < tmax do 19 Randomly take an action a, observe s\u2032, NT ; 20 st+1 \u2190 s\u2032, t\u2190 t+ 1; 21 end 22 if NT = \u2205 then 23 Project f\u0303 and calculate rt+1; 24 end 25 end 26 Backpropagate simulation results; 27 end The reward is calculated or the maximal size is exceeded, resulting in a zero reward. The best result from the attempts counts as the reward of the current simulation phase and backpropagates from the current unvisited node all the way to the root node. Greedy search. Different from the MCTS-based gaming AIs where the agents are inclined to pick the action with a high expected reward (average returns), the SPL machine seeks the unique optimal solution. In the proposed training framework, we apply a greedy search heuristic to encourage the agent to explore the branch which yields the best solution in the past: Q(s, a) is defined as the maximum reward of the state-action pair, and its value is backpropagated from the highest reward in the simulations upon the selection of the pair. Meanwhile, to overcome the local minima problems due to this greedy approach in policy search, we enforce a certain level of randomness by empirically adopting the \u03f5-greedy algorithm, a commonly seen approach in reinforcement learning models. Adaptive-scaled rewarding. Owing to the unknown level of error from the numerically estimated state derivatives, the range of the RMSE in the SPL reward function is unpredicTable This uncertainty affects the scale of rewarding values thus the balance between exploration and exploitation is presented in Eq. (1). Besides adding \u201c1\u201d to the denominator of Eq. (2) to avoid dramatically large numerical rewards, we also apply an adaptive scale of the reward that Q(s, a) = r\u2217(s, a) maxs\u2032\u2208S,a\u2032\u2208A Q(s\u2032, a\u2032) (3) where r\u2217 denotes the maximum reward of the state-action pair. It is scaled by the current maximum reward among all states S and actions A to reach an equilibrium that the Q-values are stretched to the scale [0, 1] at any time. This self-adaptive fashion yields a well-scaled calculation of UCT under different value ranges of rewards throughout the training. Module transplantation. A function can be decomposed into smaller modules where each is simpler than the original one (Udrescu et al., 2020). This modularity feature, as shown in Figure 2, helps us develop a divide-and-conquer heuristic for distilling some complicated functions: after every certain amount of MCTS iterations, the discovered parse trees with high rewards are picked out and thereupon A A A\u00d7 A A\u00d7 xx A A\u00d7 xx f A A \u00d7 A A\u00d7 xx f A x \ud835\udc5a\u2217: \ud835\udc53 \ud835\udc65 \ud835\udc54\u2217 \u2190 \ud835\udc5a\u2217 A A A + A A A \u2010 A A A \u00d7 A A A \u00f7 A A cos A A sin A A exp A x A 1 \ud835\udc5a\u2217 : \ud835\udc53 \ud835\udc65 A \ud835\udc65 Grammars A \ud835\udc65 \ud835\udc54\u2217 \u2190 \ud835\udc5a\u2217 Figure 2: A module transplantation process: A complete parse serves as a single production rule and is appended to the grammar pool. reckoned as individual production rules and appended to the set of production rules R; accordingly, these trees are \u201ctransplanted\u201d to the future ones as their modules (i.e, the leaves). To avoid early overfitting problem, we incrementally enlarge the sizes of such modules from a baseline length to the maximum allowed size of the parse tree throughout the iterations. The augmentation part of R is refreshed whenever new production rules are created, keeping only the ones engendering high rewards. This approach accelerates the policy search by capturing and locking some modules that likely contribute to, or appear as part of the optimal solution, especially in the cases of the mathematical expression containing \u201cdeep\u201d operations (e.g., high-order polynomials) whose structures are difficult for the MCTS agent to repeatedly obtain during the selection and expansion. 4 SYMBOLIC REGRESSION: FINDING MATHEMATICAL FORMULAS: 4.1 DATA NOISE & SCARCITY GP SPL Figure 3: The effect of data noise/scarcity on recovery rate. The heatmaps demonstrate the recovery rate of GP-based symbolic regressor and the SPL machine under different data conditions, summarized over 100 independent trials. Data scarcity and noise are commonly seen in measurement data and become one of the bottleneck issues for discovering the governing equations of nonlinear dynamics. Tackling the challenges in high-level data scarcity and noise situations is traditionally regarded as an essential robustness indicator for a nonlinear dynamics discovery model. Prior to this, we present an examination of the proposed SPL machine by an equation discovery task in the presence of multiple levels of data noise and volumes, comparing with a GP-based symbolic regressor (implemented with gplearn python package)1. The target equation is f(x) = 0.3x3 + 0.5x2 + 2x, and the independent variable X is uniformly sampled in the given range [\u221210, 10]. Gaussian white noise is added to the dependent variable Y with the noise level defined as the root-mean-square ratio between the noise and the exact values. For discovery, the two models are fed with equivalent search space: {+,\u2212,\u00d7,\u00f7, cost, x} as candidate mathematical operations and symbols. The hyperparameters of te SPL machine are set as \u03b7 = 0.99, tmax = 50, and 10,000 episodes of training is regarded as one trail. For the GP-based symbolic regressor, population of programs is set to as 2000, number of generations as 20, the range of constant values is [\u221210, 10]. For 16 different data noise and scarcity levels, each model performs 100 independent trails. The recovery rates are displayed as a 4\u00d7 4 mesh grid with different noise and scarcity levels in Figure 3. It is clearly observed that the SPL machine outperforms the GP-based symbolic regressor in all the cases. A T-test also proves that recovery rate of the SPL machine is significantly higher than that of the GP-based symbolic regressor (p-value = 1.06\u00d7 10\u22127). 4.2 NGUYEN\u2019S SYMBOLIC REGRESSION BENCHMARK: Nguyen\u2019s symbolic regression benchmark task (Uy et al., 2011) is widely used by the equation discovery work as an indicator of a model\u2019s robustness in symbolic regression problems. Given a set of allowed operators, a target equation, and data generated by this equation, the tested model is supposed to distill mathematical expression that is identical to the target equation, or equivalent to it (e.g., Nguyen-7 equation can be recovered as log(x3 + x2 + x+ 1), Nguyen-10 equation can 1All simulations are performed on a workstation with a NVIDIA GeForce RTX 2080Ti GPU. be recovered as sin(x + y), and Nguyen-11 equation can be recovered as exp(y log(x))). Some variants of Nguyen\u2019s benchmark equations are also considered in this experiment. Their discoveries require numerical estimation of constant values. Each equation generates two datasets: one for training and another for testing purposes. The discovered equation that perfectly fits the testing data is regarded as a successful discovery. The recovery rate is calculated based on 100 independent tests for each task. In these benchmark tasks, three algorithms are tested: GP-based symbolic regressor, the neural-guided GP (NGGP) (Mundhenk et al., 2021), and the proposed SPL machine. Note that NGGP is an improved approach over DSR (Petersen et al., 2021). They are given the same set of candidate operations: {+,\u2212,\u00d7,\u00f7, exp(\u00b7), cos(\u00b7), sin(\u00b7)} for all benchmarks and { \u221a \u00b7, ln(\u00b7)} are added to the 7, 8, 11 benchmarks. The hyperparameters of the GP-based symbolic regressor are the same as those mentioned in Section 4.1; configurations of the NGGP models are obtained from its source code2; detailed setting of the benchmark tasks and the SPL model is described in Appendix Section A. The success rates are shown in Table 1. It is observed that the SPL machine and the NGGP model both produce reliable results in Nguyen\u2019s benchmark problems and the SPL machine slightly outperformed the NGGP. This experiment betokens the capacity of the SPL machine in equation discoveries with divergent forms. Ablation Study: We consider three ablation studies by removing: (a) the adaptive scaling in reward calculation, (b) the discount factor \u03b7n that drives equation parsimony in Eq. (2), and (c) module transplantation in tree generation. The ablated models were tested on the above 17 Nguyen equations. Results show that the average recovery rates for these models are all below 60% (numbers are not listed due to space limit). Hence, these modules are critical to guarantee the proposed model efficacy. 5 PHYSICS LAW DISCOVERY: FREE FALLING BALLS WITH AIR RESISTANCE: Table 2: Baseline models (ci: unknown constants). Physics Model Derived model expression Model-1 H(t) = c0 + c1t+ c2t2 + c3t3 Model-2 H(t) = c0 + c1t+ c2ec3t Model-3 H(t) = c0 + c1 log(cosh(c2t)) It is well known that in 1589\u201392 Galileo dropped two objects of unequal mass from the Leaning Tower of Pisa and drew a conclusion that their velocities were not affected by the mass. This has been well recognized globally as the \u201ctextbook\u201d physics law for the vertical motion of a free-falling object: the 2NGGP source code: https://github.com/brendenpetersen/deep-symbolic-optimization/tree/master/dso/dso height of the object is formulated as H(t) = h0 + v0t\u2212 12gt 2, where h0 denotes initial height, v0 the initial velocity, and g the gravitational acceleration. However, this ideal situation is rarely reached in our daily life because air resistance serves as a significant damping factor that prevents the above physics law from occurring in real-life cases. Many efforts have been made to uncover the effect of the air resistance and derive mathematical models to describe the free-falling objects with air resistance (Clancy, 1975; Lindemuth, 1971; Greenwood et al., 1986). This section provides a data-driven discovery of the physics laws of relationships between height and time in the cases of free-falling objects with air resistance based on multiple experimental ball-drop datasets (de Silva et al., 2020), which contain the records of 11 different types of balls dropped from a bridge (see Appendix Figure B.1). For discovery, each dataset is split into a train set (records from the first 2 seconds) and a test set (records after 2 seconds). Three mathematically derived physics models are selected from the literature as baseline models3,4,5 for this experiment (see Table 2), and the unknown constant values are solved by Powell\u2019s conjugate direction method (Powell, 1964). Based on prior knowledge of the physics law that may appear in this case, this experiment uses {+,\u2212,\u00d7,\u00f7, exp(\u00b7), cosh(\u00b7), log(\u00b7)} as the candidate grammars of the SPL discovery, with terminal nodes {t, const}. The hyperparameters are set as \u03b7 = 0.9999, tmax = 20, and one single discovery is built upon 6,000 episodes of training. The physics laws distilled by SPL from training data are applied to the test data and compared with the ground truth. Their prediction errors, in terms of MSE, are presented in Table 3 (the SPL-discovered equations are shown in Appendix Table B.1). The full results can be found in Appendix Section B. It can be concluded that the data-driven discovery of physical laws leads to a better approximation of the free-falling objects with air resistance. 6 CHAOTIC DYNAMICS DISCOVERY: THE LORENZ SYSTEM: The first nonlinear dynamics discovery example is a 3-dimensional Lorenz system (Lorenz, 1963) whose dynamical behavior (x, y, z) is governed by x\u0307 = \u03c3(y\u2212 x), y\u0307 = x(\u03c1 \u2212 z) \u2212 y, z\u0307 = xy \u2212 \u03b2z with parameters \u03c3 = 10, \u03b2 = 8/3, and \u03c1 = 28, under which the Lorenz attractor has two lobes and the system, starting from anywhere, makes cycles around one lobe before switching to the other and iterates repeatedly. The resulting system exhibits strong chaos. The synthetic datasets are generated by solving the nonlinear differential equations using Matlab ode113 (Shampine, 1975; Shampine & Reichelt, 1997) function. 5% Gaussian white noise is added to the clean data to generate noisy measurement. The derivatives of the system states are estimated by central difference and smoothed by the Savitzky\u2013Golay filter (Savitzky & Golay, 1964) in order to reduce the noise effect. In this experiment, the proposed SPL machine will compare with three benchmark methods, Eureqa, pySINDy and NGGP. For Eureqa, NGGP, and the SPL machine, {+,\u2212,\u00d7,\u00f7} are used as candidate operations; the upper bound of complexity is set to be 50; for pySINDy, the candidate function library includes all polynomial basis of x, y, z from degree 1 to degree 4. Appendix Table C.1 3Model 1: https://faraday.physics.utoronto.ca/IYearLab/Intros/FreeFall/FreeFall.html 4Model 2: https://physics.csuchico.edu/kagan/204A/lecturenotes/Section15.pdf 5Model 3: https://en.wikipedia.org/wiki/Free_fall presents the distilled governing dynamics by each approach and Table 4 summarizes these results: the SPL machine uncovers the explicit form of equations accurately in the context of active terms, whereas Eureqa, pySINDy and NGGP yield several false-positive terms in the governing equations. In particular, although Eureqa and NGGP are capable of uncovering the correct terms, their performance is very sensitive to the measurement noise as indicated by the redundant terms (despite with small coefficients) shown in Appendix Table C.1. Overall, the baseline methods fail to handle the large noise effect, essentially limiting their applicability in nonlinear dynamics discovery. It is evident that the SPL machine is capable of distilling the concise symbolic combination of operators and variables to correctly formulate parsimonious mathematical expressions that govern the Lorenz system, outperforming the baseline methods of Eureqa, pySINDy and NGGP. 7 EXPERIMENTAL DYNAMICS DISCOVERY: DOUBLE PENDULUM: This section shows SPL-based discovery of a chaotic double pendulum system with experimental data (Asseman et al., 2018) as shown in Appendix Figure C.3. The governing equations can be derived by the Lagrange method, given by: \u03c9\u03071 = c1\u03c9\u03072 cos(\u2206\u03b8) + c2\u03c9 2 2 sin(\u2206\u03b8) + c3 sin(\u03b81) +R1(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072), \u03c9\u03072 = c1\u03c9\u03071 cos(\u2206\u03b8) + c2\u03c9 2 1 sin(\u2206\u03b8) + c3 sin(\u03b82) +R2(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072) (4) where \u03b81, \u03b82 denote the angular displacements; \u03c91 = \u03b8\u03071, \u03c92 = \u03b8\u03072 the velocities; \u03c9\u03071, \u03c9\u03072 the accelerations; R1 and R2 denote the unknown damping forces. Note that \u2206\u03b8 = \u03b81 \u2212 \u03b82. The data source contains multiple camera-sensed datasets. Here, 5,000 denoised random sub-samples from 5 datasets are used for training, and 2,000 random sub-samples from another 2 datasets for validation, and 1 dataset for testing. The derivatives of the system states are numerically estimated by the same approach discussed in the Lorenz case. Some physics are employed to guide the discovery: (1) \u03c9\u03072 cos(\u2206\u03b8) for \u03c9\u03071 and \u03c9\u03071 cos(\u2206\u03b8) are given; (2) the angles (\u03b81, \u03b82, \u2206\u03b8) are under the trigonometric functions cos(\u00b7) and sin(\u00b7); (3) directions of velocities/relative velocities may appear in damping. Production rules fulfilling the above prior knowledge are exhibited in Appendix Section C.2. The hyperparameters are set as \u03b7 = 1, tmax = 20, and 40,000 episodes of training is regarded as one trail. 5 independent trials are performed and the equations with the highest validation scores are selected as the final results. The uncovered equations are given as follows: \u03c9\u03071 = \u22120.0991\u03c9\u03072 cos(\u2206\u03b8)\u2212 0.103\u03c922 sin(\u2206\u03b8)\u2212 69.274 sin(\u03b81) + 0.515 cos(\u03b81), \u03c9\u03072 = \u22121.368\u03c9\u03071 cos(\u2206\u03b8) + 1.363\u03c921 sin(\u2206\u03b8)\u2212 92.913 sin(\u03b82) + 0.032\u03c91, (5) where the explicit expression of physics in an ideal double pendulum system, as displayed in Eq. (5), are successfully distilled and damping terms are estimated. This set of equation is validated through interpolation on the testing set and compared with the smoothed derivatives, as shown in Appendix Figure C.4. The solution appears felicitous as the governing equations of the testing responses. 8 CONCLUSION AND DISCUSSION: This paper introduces a Symbolic Physics Learner (SPL) machine to tackle the challenge of distilling the mathematical structure of equations and nonlinear dynamics with unknown forms of measurement data. This framework is built upon the expression tree interpretation of mathematical operations and variables and an MCTS agent that searches for the optimistic policy to reconstruct the target mathematical expression. With some remarkable adjustments to the MCTS algorithms, the SPL model straightforwardly accepts prior or domain knowledge, or any sorts of constraints of the tasks in the grammar design while leveraging great flexibility in expression formulation. The robustness of the proposed SPL for complex target expression discovery with large search space is indicated in Nguyen\u2019s symbolic regression benchmark problems, where the SPL machine outperforms state-of-the-art symbolic regression methods. Moreover, encouraging results are obtained in the physics law and nonlinear dynamics discovery tasks that are based on synthetic or experimental datasets. While the proposed SPL framework shows huge potential in both symbolic regression and physics/nonlinear dynamics discovery tasks, there are still some imperfections that can be improved: (i) the computational cost is high for constant value estimation, (ii) graph modularity is underexamined, and (iii) robustness against extreme data noise and scarcity is not optimal. These limitations are further explained in Appendix Section D. A NGUYEN\u2019S BENCHMARK PROBLEMS: This section provides more detailed experiment settings for Nguyen\u2019s benchmark tasks that are described in the Section 4 of the main context and then exhibits the training hyperparameters for the SPL machine in these equation discovery experiments: Table A.1 presents the candidate mathematical operations allowed for three tested models and Table A.2 displays training hyperparameters for the SPL machine in the Nguyen\u2019s benchmark tasks. Moreover, the utilization of CFG in the SPL machine facilitates the flexibility of applying some prior knowledge including the universal mathematical rules and constraints. This feature empirically turns out to be an accessible and scalable approach for avoiding meaningless mathematical expressions. In the Nguyen\u2019s benchmark tasks, one or multiple mathematical constraints are given to the SPL machine. These constraints include 1. Only variables and constant values allowed in trigonometric functions. 2. Variables in trigonometric functions, logarithms and roots are up to the polynomial of 3. 3. Trigonometric functions, logarithms and roots are not allowed to form unreasonable composite functions with each other, such as sin(cos(...)). 4. Some small integers (e.g. 1, 2) are used directly as leaves. They can be easily implemented into the SPL machine by defining adjusting non-terminal nodes or production rules in the customized CFG. Constraints adopted by each task is shown in Table A.3. B FREE FALLING BALLS WITH AIR RESISTANCE: This appendix section reveals more details in the data-driven discovery of the physics laws of relationships between height and time in the cases of free-falling objects with air resistance based on multiple experimental ball-drop datasets (de Silva et al., 2020). The datasets contain the records of 11 different types of balls, as shown in Figure B.1, dropped from a bridge with a 30 Hz sampling rate. The time between dropping and landing varies in each case, which is due to the fact that air resistance has different effects on these free-dropping balls and induces divergent physics laws. Consequently, we consider each ball as an individual experiment and discover physics laws for each of them. The measurement dataset of a free-dropping ball is split into a training set (records from the first 2 seconds, 60 measurement) and a testing set (records after 2 seconds). The physics laws distilled by the three mathematically derived physics models displayed in the main text and the SPL machine from training data are exhibited in Table B.1. These discovered physics laws are then applied to forecast the height of the balls at the time slots in testing dataset. These predictions, in comparison with the ground truth trajectory recorded, are shown in Figure B.2. Prediction error is shown in the Table 3 of the main context. C NONLINEAR DYNAMICS DISCOVERY: This appendix section expands the two governing equation discovery experiments presented in the main context, including the datasets and full results. C.1 LORENZ SYSTEM The 3-dimensional Lorenz system is governed by x\u0307 = \u03c3(y \u2212 x) y\u0307 = x(\u03c1\u2212 z)\u2212 y z\u0307 = xy \u2212 \u03b2z (6) with parameters \u03c3 = 10, \u03b2 = 8/3, and \u03c1 = 28, under which the Lorenz attractor has two lobes and the system, starting from anywhere, makes cycles around one lobe before switching to the other and iterates repeatedly. The measurement data of Lorenz system in this experiment contains a clean signal with 5% Gaussian white noise. The derivatives of Lorenz\u2019s state variables are numerically estimated and smoothed by the Savitzky\u2013Golay filter. The noisy synthetic measurement and numerically obtained derivatives are shown in Figure C.1, Table C.1 presents the distilled governing equations of the Lorenz system by 4 tested models. It is observed that the SPL uncover the explicit form of equations accurately in the context of active terms, whereas Eureqa, pySINDy and NGGP yield several false-positive terms in governing equations. 5-second predicted system responses (starting from a different initial condition) simulated from these uncovered equations are shown in Figure C.2. Though it is hard to reproduce the most accurate coefficients due to the tremendous errors due to numerical differentiation of noisy measurement as depicted in Figure C.1, the SPL machine is still capable of distilling the most concise symbolic combination of operators and variables to correctly formulate parsimonious mathematical expressions that govern the Lorenz system. The predicted responses from the governing equations unearthed by the SPL machine simulates the system in a decent manner. C.2 MOUNTED DOUBLE PENDULUM SYSTEM The second nonlinear dynamics discovery experiment is on a camera-measured chaotic double pendulum system (Asseman et al., 2018). The sensed data is in form of videos of the chaotic motion of a double pendulum on the device shown in Figure C.3A filmed with a high-speed camera. The positional data is converted into angular form by using the model shown in Figure C.3C. The governing equations for a mounted pendulum system can be derived with Euler\u2013Lagrange method: (m1 +m2)l1\u03b8\u03081 +m2l2\u03b8\u03082 cos(\u03b81 \u2212 \u03b82) +m2l2\u03c922 sin(\u03b81 \u2212 \u03b82) + (m1 +m2)g sin(\u03b81) = F1, m2l2\u03b8\u03082 +m2l1\u03b8\u03081 cos(\u03b81 \u2212 \u03b82)\u2212m2l1\u03c921 sin(\u03b81 \u2212 \u03b82) +m2g sin(\u03b82) = F2, (7) which, by denoting \u03c9 as the velocity, can be converted to the form of \u03b8\u03071 = \u03c91, \u03b8\u03072 = \u03c92, \u03c9\u03071 = c1\u03c9\u03072 cos(\u2206\u03b8) + c2\u03c9 2 2 sin(\u2206\u03b8) + c3 sin(\u03b81) +R1(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072), \u03c9\u03072 = c1\u03c9\u03071 cos(\u2206\u03b8) + c2\u03c9 2 1 sin(\u2206\u03b8) + c3 sin(\u03b82) +R2(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072) (8) where \u2206\u03b8 = \u03b81 \u2212 \u03b82, and R1(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072) and R2(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072) denote the damping terms for the last two differential equations. The data source contains multiple camera-sensed datasets. For this discovery, 5,000 denoised random sub-samples from 5 datasets are used for training purposes, and 2,000 random sub-samples from another 2 datasets for validation, and 1 dataset for testing. Some prior knowledge guiding this the discovery includes: 1. \u03c9\u03072 cos(\u2206\u03b8) for \u03c9\u03071 and \u03c9\u03071 cos(\u2206\u03b8) for \u03c9\u03072 are easily derived. Both terms are given. 2. the remaining of the formulas are potentially comprised of the free combination of \u03c9\u03071, \u03c9\u03072, \u03c91, \u03c92, as well as the angles (\u03b81, \u03b82, \u2206\u03b8) under the trigonometric functions cos(\u00b7) and sin(\u00b7). 3. velocities and relative velocities of two masses, as well as their directions (sign function) might contribute to the damping. Based on these information, the candidate production rules for governing differential equations \u03c9\u03071 and \u03c9\u03072 are shown as below, where non-terminal nodes are V = {A,W, T, S} and C denotes the placeholder symbol for constant values. A \u2192 A+A, A \u2192 A\u00d7A, A \u2192 C, A \u2192 A+A, A \u2192 W , W \u2192 W \u00d7W , W \u2192 \u03c91, W \u2192 \u03c92, W \u2192 \u03c9\u03071, W \u2192 \u03c9\u03072, A \u2192 cos(T ), A \u2192 sin(T ), T \u2192 T + T , T \u2192 T \u2212 T , T \u2192 \u03b81, T \u2192 \u03b82, A \u2192 sign(S), S \u2192 S + S, S \u2192 S \u2212 S, S \u2192 \u03c91, S \u2192 \u03c92, S \u2192 \u03c9\u03071, S \u2192 \u03c9\u03072 A \u2192 \u03c9\u03071 cos(\u03b81 \u2212 \u03b82), A \u2192 \u03c9\u03072 cos(\u03b81 \u2212 \u03b82) The hyperparameters are set as \u03b7 = 1, tmax = 20, and 40,000 episodes of training is regarded as one trail. 5 independent trials are performed and the equations with the highest validation scores are selected as the final results. The uncovered equations are shown in Table C.2. They are validated through interpolation on the testing set and compared with the smoothed derivatives, as shown in Figure C.4. The solution appears felicitous as the governing equations of the testing responses. D DISCUSSION AND FUTURE DIRECTIONS: While the proposed SPL framework shows huge potential in both symbolic regression and physics law/governing equation discovery tasks, there are still some imperfections to be improved. In this appendix section, a few bottlenecks and their potential solutions are presented: 1. Computational cost. Computational cost for this framework is one of the major issues, especially when constant estimation is required. Evaluating the solution in the simulation phase happens very frequently for the MCTS algorithm where the policy selection relies heavily on a large number of historical rewards. However, constant value estimation, which can be slow, is required for evaluation purposes. The SPL machine is not the only symbolic regressor suffering from the computational cost in constant value estimation. In fact, the state-of-the-art symbolic regression model, the neural-guided GP (NGGP) (Mundhenk et al., 2021), becomes much slower in the Nguyen\u2019s benchmark variant tasks (see Table C.3). The current implementation of the SPL machine tries to empirically avoid this issue by limiting the number of placeholders in a discovered expression and simplifying the expression before evaluating, but still cannot reach a great efficiency. This bottleneck might be mitigated if parallel computing is introduced to the MCTS simulation phase. 2. Graph modularity underexamined. The current design of the SPL training scheme does not leverage the full graph modularity: modules are reached by transforming a complete parse tree into a grammar. However, in some cases, there might be some influential modules appearing frequently as part of the tree. This type of graph modularity is described in the AI-Feynman method (Udrescu et al., 2020). Deploying a more comprehensive graph modularity into the SPL machine will boost its efficacy in complex equation and nonlinear dynamics discovery tasks. 3. Robustness against extreme data noise and scarcity. Though it is observed that this reinforcement learning-based method is able to unearth the parsimonious solution to the governing equations from synthetic or measurement data with a moderate level of noise and scarcity. It is not effective when the data condition is too extreme, or if there are missing values that make it challenging to numerically calculate the state derivatives. It is reasonable to investigate the integration between the SPL framework with a physics-guided surrogate model that are built upon neural networks (Long et al., 2018; Chen et al., 2021) or spline learning (Sun et al., 2021) for further robustness in nonlinear dynamics discovery tasks.", "agent_review": [{"role": "user", "content": "Review the following paper for International Conference on Learning Representations (ICLR) 2023. Remember you need to make 3 reviewer agents for each paper. GIVE A FINAL DECISION in the form of \"FINAL DECISION: <Accept/Reject>\". The paper title is: Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search\n\n1 INTRODUCTION: We usually learn the behavior of a nonlinear dynamical system through its nonlinear governing differential equations. These equations can be formulated as y\u0307(t) = dy/dt = F(y(t)), where y(t) = {y1(t), y2(t), ..., yn(t)} \u2208 R1\u00d7n denotes the system state at time t, F(\u00b7) a nonlinear function set defining the state motions and n the system dimension. The explicit form of F(\u00b7) for some nonlinear dynamics remains underexplored. For example, in a mounted double pendulum system, the mathematical description of the underlying physics might be unclear due to unknown viscous and frictional damping forms. These uncertainties yield critical demands for the discovery of nonlinear dynamics given observational data. Nevertheless, distilling the analytical form of governing equations from limited noisy data, commonly seen in practice, is an intractable challenge. Ever since the early work on the data-driven discovery of nonlinear dynamics (D\u017eeroski & Todorovski, 1993; Dzeroski & Todorovski, 1995), many scientists have stepped into this field of study. In the recent decade, the escalating advances in machine learning, data science, and computing power enabled several milestone efforts of unearthing the governing equations for nonlinear dynamical systems. Notably, a breakthrough model named SINDy based on sparse regression method (Brunton et al., 2016) shedded light on this field of study. SINDy was invented to determine the sparse solution among a pre-defined basis function library recursively through a sequential threshold ridge regression (STRidge) algorithm. SINDy quickly became one of the state-of-art methods and kindled significant enthusiasm in this field of study (Rudy et al., 2017; Long et al., 2018; Champion et al., 2019; Chen et al., 2021; Sun et al., 2021; Rao et al., 2022). However, the success of this sparsity-promoting approach relies on a properly defined candidate function library that requires prior knowledge of the system. It is also restricted by the fact that a linear combination of candidate functions might be insufficient to recover complicated mathematical expressions. Moreover, when the library size is massive, it empirically fails to hold the sparsity constraint. At the same time, attempts have been made to tackle the nonlinear dynamics discovery problems by introducing neural networks with activation functions replaced by commonly seen mathematical operators (Martius & Lampert, 2017; Sahoo et al., 2018; Kim et al., 2019; Long et al., 2019). The intricate formulas are obtained via the well-trained symbolic network expansion. This interpretation of physics laws results in larger candidate pools compared to the library-based representation of physics employed by SINDy. Nevertheless, since the sparsity of discovered expressions is primarily achieved by empirical pruning of the weights, this framework exhibits sensitivity to user-defined thresholds and may fall short to produce parsimonious governing equations for noisy and scarce data. Alternatively, another benchmark work (Bongard & Lipson, 2007; Schmidt & Lipson, 2009) reenvisioned the data-driven nonlinear dynamics discovery tasks by casting them into symbolic regression problems which have been profoundly resolved by the genetic programming (GP) approach (Koza & Koza, 1992; Billard & Diday, 2003). Under this framework, a symbolic regressor is established to identify the differential equations that best describe the underlying governing physical laws through the free combination of mathematical operations and symbols, leveraging great flexibility (i.e, free combination of symbols and operators) in model selection. One essential weakness of this early methodology is that driven exclusively by the goal of empirically seeking the best-fitting expression (e.g. minimizing the mean-square error) in a genetic expansion process, the GP-based model usually overfits the target system with numerous false-positive terms under data noise, even sometimes at a subtle level, causing huge instability and uncertainty. However, this ingenious idea inspired a series of subsequent endeavors (Cornforth & Lipson, 2012; Gaucel et al., 2014; Ly & Lipson, 2012; Quade et al., 2016; Vaddireddy et al., 2020). In a more recent work titled Deep Symbolic Regression (Petersen et al., 2021; Mundhenk et al., 2021), a reinforcement learning-based model for symbolic regression was fabricated and generally outperformed the GP based models including the commercial Eureqa (Langdon & Gustafson, 2010) software. Additionally, the AI-Feynman methods (Udrescu & Tegmark, 2020; Udrescu et al., 2020; Udrescu & Tegmark, 2021) ameliorated the symbolic regression algorithm for distilling physics law from data by combining neural network fitting with a suite of physics-inspired techniques. This approach is also highlighted by a recursive decomposition of a complicated mathematical expression into different parts on a tree-based graph, which disentangles the original problem and speeds up the discovery. It outperformed Eureqa in the data-driven uncovering of Feynman physics equations (Feynman et al., 1965). The popularity of adopting the tree-based symbolic reasoning of mathematical formulas (Lample & Charton, 2019) has been rising recently to uncover unknown mathematical expressions with a reinforcement learning agent (Kubal\u00edk et al., 2019; Petersen et al., 2021; Mundhenk et al., 2021). However, some former work attempting to apply the Monte Carlo tree search (MCTS) algorithm as an alternative to GP for symbolic regression (Cazenave, 2013; White et al., 2015; Islam et al., 2018; Lu et al., 2021) failed to leverage the full flexibility of this algorithm, resulting in the similar shortage with GP-based symbolic regressors as discussed earlier. Despite these outcomes, we are conscious of the strengths of the MCTS algorithm in equation discovery: it enables the flexible representation of search space with customized computational grammars to guide the search tree expansion. A sound mathematical underpinning for the trade-off between exploration and exploitation is remarkably advantageous as well. These features make it possible to guide the MCTS agent by prior physics knowledge in nonlinear dynamics discovery rather than randomly searching in large spaces. Contribution. We propose a promising model named Symbolic Physics Learner (SPL) machine, empowered by MCTS, for discovery of nonlinear dynamics. This architecture relies on a grammar composed of computational rules and symbols to guide the search tree spanning and a composite objective rewarding function to simultaneously evaluate the generated mathematical expressions with observational data and enforce sparsity of the expression. Moreover, we design multiple adjustments to the conventional MCTS by: (1) replacing the expected reward in UCT score with maximum reward to better fit the equation discovery objective, (2) employing an adaptive scaling in policy evaluation which would eliminate the uncertainty of the reward value range owing to the unknown error of the system state derivatives, and (3) transplanting modules with high returns to the subsequent search as a single leaf node. With these adjustments, the SPL machine is capable of efficiently uncovering the best path to formulate the complex governing equations of the target dynamical system. 2 BACKGROUND: In this section, we expand and explain the background concepts brought up in the introduction to the SPL architecture, including the expression tree (parse tree) and the MCTS algorithm. Expression tree. Any mathematical expression can be represented by a combinatorial set of symbols and mathematical operations and further expressed by a parse tree structure, (Hopcroft et al., 2006; Kusner et al., 2017), which is empowered by a context-free grammar (CFG). A CFG is a formal grammar characterized by a tuple comprised of 4 elements G = (V,\u03a3, R, S), where V denotes a finite set of non-terminal nodes, \u03a3 a finite set of terminal nodes, R a finite set of production rules, each interpreted as a mapping from a single non-terminal symbol in V to one or multiple terminal/non-terminal nodes in (V \u222a\u03a3)\u2217 where \u2217 represents the Kleene star operation, and S a single non-terminal node standing for a start symbol. In our work, equations are symbolized into parse trees: we define the start node as equation symbol f , terminal symbols (leaf nodes) corresponding to the independent variables from the equation (e.g, x, y), and a placeholder symbol C for identifiable constant coefficients that stick to specific production rules. The non-terminal nodes between root and leaf nodes are represented by some symbols distinct from the start and terminal nodes (i.e., M ). The production rules denote the commonly seen mathematical operators: unary rules (one non-terminal node mapping to one node) for operators like cos(\u00b7), exp(\u00b7), log(| \u00b7 |), and binary rules (one non-terminal node mapping to two nodes) for operators such as +, \u2212, \u00d7, \u00f7. A parse tree is then generated via a pre-order traversal of production rules rooted at f and terminates when all leaf nodes are entirely filled with terminal symbols. Each mathematical expression can be denoted as such a traversal set of production rules. Monte Carlo tree search. Monte Carlo tree search (MCTS) (Coulom, 2006) is an algorithm for searching optimal decisions in large combinatorial spaces represented by search trees. This technique complies with the best-first search principle based on the evaluations of stochastic simulations. It has already been widely employed in and proved the spectacular success by various gaming artificial intelligence systems, including the famous AlphaGo and AlphaZero (Silver et al., 2017) for computer Go game. A basic MCTS algorithm can be regarded as an iterative process of four steps: 1. Selection. The MCTS agent, starting from the root node, moves through the visited nodes of the search tre and selects the next node according to a given selection policy until it reaches an expandable node or a leaf node. 2. Expansion. At an an expandable node, the MCTS agent expands the search tree by selecting one of its unvisited children. 3. Simulation. After expansion, if the current node is non-terminal, the agent performs one or multiple independent simulations starting from the current node until reaching the terminal state. In this process, actions are randomly selected. 4. Backpropagation. Statistics of nodes along the path from the current node to the root are updated with respect to search results (scores evaluated from the terminate states reached). To maintain a proper balance between the less-tested paths and the best policy identified so far, the MCTS agent stikcs to a trade-off between exploration and exploitation through selecting the action that maximizes the Upper Confidence Bounds applied for Trees (UCT), which is formulated as: UCT (s, a) = Q(s, a) + c \u221a ln[N(s)]/N(s, a) (1) where Q(s, a) denotes the average result/reward of playing action a in state s in the simulations performed in the history, encouraging the exploitation of current best child node; N(s) denotes number of times state s has been visited, N(s, a) the number of times action a has been selected at state s, and \u221a ln[N(s)]/N(s, a) consequently encourages the exploration of less-visited child nodes. Constant c controls the balance between exploration and exploitation and is usually empirically defined depend on the specific problem. 3 METHODS: It has been demonstrated that the MCTS agent continuously gains knowledge of the given discovery task via the expansion of the search tree and, based on the backpropagation of evaluation results (i.e., rewards and number of visits), render a proper selection policy on visited states to guide the upcoming searching. In the proposed SPL machine, this process is integrated with the symbolic reasoning of mathematical expressions to reproduce and evaluate valid mathematical expressions of the physics laws in nonlinear dynamics step-by-step, and then obtain a favorable selection policy pointing to the best solution. This algorithm is depicted in Figure 1 with an illustrative example and its overall training scheme is shown in Algorithm 1. Rewarding. To evaluate the mathematical expression f\u0303 projected from a parse tree, we define a numerical reward r \u2208 R \u2282 R based on this expression and input data D = {Y; Y\u0307i}, serving as the search result of the current expansion or simulation. It is formulated as r = \u03b7n 1 + \u221a 1 N \u2225\u2225Y\u0307i \u2212 f\u0303(Y)\u2225\u222522 (2) where Y = {y1,y2, ...,ym} \u2208 Rm\u00d7N is the m dimensional system state variables, Y\u0307i \u2208 R1\u00d7N the numerically estimated state derivative for ith dimension, and N the number of measurement data points. \u03b7 denotes a discount factor, assigned slightly smaller than 1; n is empirically defined as the total number of production rules in the parse tree. This numerator arrangement is designated to penalize non-parsimonious solutions. This rewarding formulation outputs a reasonable assessment to the distilled equations and encourages parsimonious solution by discounting the reward of a non-parsimonious one. The rooted mean square error (RMSE) in denominator evaluates the goodnessof-fit of the discovered equation w.r.t. the measurement data. Training scheme. A grammar G = (V,\u03a3, R, S) is defined with appropriate nodes and production rules to cover all possible forms of equations. To keep track of non-terminal nodes of the parsing tree, we apply a last-in-first-out (LIFO) strategy and denote the non-terminal node placed last on the stack NT as the current node. We define the action space A = R and the state space S as all possible traversals of complete/incomplete parse trees (i.e., production rules selected) in ordered sequences. At the current state st = [a1, a2, ...at] where t \u2208 N is the discrete traversal step-index of the upcoming production rule, the MCTS agent masks out the invalid production rules for current non-terminal node and on that basis selects a valid rule as action at+1 (i.e, the left-hand side of a valid production rule is the current non-terminal symbol). Consequently, the parse tree gains a new terminal/non-terminal branch in accordance with at+1, meanwhile the agent finds itself in a new state st+1 = [a1, a2, ...at, at+1]. The agent subsequently pops off the current non-terminal symbol from NT and pushes the non-terminal nodes, if there are any, on the right-hand side of the selected rule onto the stack. Once the agent attains an unvisited node, a certain amount of simulations are performed, where the agent starts to randomly select the next node until the parse tree is completed. Algorithm 1: Training the SPL machine for ith dimension governing equation discovery 1 Input: Grammar G = (V,\u03a3, R, S), measurement data D = {Y; Y\u0307i}; 2 Parameters: discount factor \u03b7, exploration rate c, tmax; 3 Output: Optimal governing equation f\u0303\u22c6; 4 for each episode do 5 Selection: Initialize s0 = \u2205, t = 0, NT = [S]; 6 while st expandable and t < tmax do 7 Choose at+1 = argmaxA UCT (st, a); 8 Take action at+1, observe s\u2032, NT ; 9 st+1 \u2190 s\u2032 note as visited, t\u2190 t+ 1; 10 end 11 Expansion: Randomly take an unvisited path with action a, observe s\u2032, NT ; 12 st+1 \u2190 s\u2032 note as visited, t\u2190 t+ 1; 13 if NT = \u2205 then 14 Project f\u0303 , Backpropagate rt+1 and visited count and finish the episode; 15 end 16 Simulation: Fix the starting point st, NT ; 17 for each simulation do 18 while st non-terminal and t < tmax do 19 Randomly take an action a, observe s\u2032, NT ; 20 st+1 \u2190 s\u2032, t\u2190 t+ 1; 21 end 22 if NT = \u2205 then 23 Project f\u0303 and calculate rt+1; 24 end 25 end 26 Backpropagate simulation results; 27 end The reward is calculated or the maximal size is exceeded, resulting in a zero reward. The best result from the attempts counts as the reward of the current simulation phase and backpropagates from the current unvisited node all the way to the root node. Greedy search. Different from the MCTS-based gaming AIs where the agents are inclined to pick the action with a high expected reward (average returns), the SPL machine seeks the unique optimal solution. In the proposed training framework, we apply a greedy search heuristic to encourage the agent to explore the branch which yields the best solution in the past: Q(s, a) is defined as the maximum reward of the state-action pair, and its value is backpropagated from the highest reward in the simulations upon the selection of the pair. Meanwhile, to overcome the local minima problems due to this greedy approach in policy search, we enforce a certain level of randomness by empirically adopting the \u03f5-greedy algorithm, a commonly seen approach in reinforcement learning models. Adaptive-scaled rewarding. Owing to the unknown level of error from the numerically estimated state derivatives, the range of the RMSE in the SPL reward function is unpredicTable This uncertainty affects the scale of rewarding values thus the balance between exploration and exploitation is presented in Eq. (1). Besides adding \u201c1\u201d to the denominator of Eq. (2) to avoid dramatically large numerical rewards, we also apply an adaptive scale of the reward that Q(s, a) = r\u2217(s, a) maxs\u2032\u2208S,a\u2032\u2208A Q(s\u2032, a\u2032) (3) where r\u2217 denotes the maximum reward of the state-action pair. It is scaled by the current maximum reward among all states S and actions A to reach an equilibrium that the Q-values are stretched to the scale [0, 1] at any time. This self-adaptive fashion yields a well-scaled calculation of UCT under different value ranges of rewards throughout the training. Module transplantation. A function can be decomposed into smaller modules where each is simpler than the original one (Udrescu et al., 2020). This modularity feature, as shown in Figure 2, helps us develop a divide-and-conquer heuristic for distilling some complicated functions: after every certain amount of MCTS iterations, the discovered parse trees with high rewards are picked out and thereupon A A A\u00d7 A A\u00d7 xx A A\u00d7 xx f A A \u00d7 A A\u00d7 xx f A x \ud835\udc5a\u2217: \ud835\udc53 \ud835\udc65 \ud835\udc54\u2217 \u2190 \ud835\udc5a\u2217 A A A + A A A \u2010 A A A \u00d7 A A A \u00f7 A A cos A A sin A A exp A x A 1 \ud835\udc5a\u2217 : \ud835\udc53 \ud835\udc65 A \ud835\udc65 Grammars A \ud835\udc65 \ud835\udc54\u2217 \u2190 \ud835\udc5a\u2217 Figure 2: A module transplantation process: A complete parse serves as a single production rule and is appended to the grammar pool. reckoned as individual production rules and appended to the set of production rules R; accordingly, these trees are \u201ctransplanted\u201d to the future ones as their modules (i.e, the leaves). To avoid early overfitting problem, we incrementally enlarge the sizes of such modules from a baseline length to the maximum allowed size of the parse tree throughout the iterations. The augmentation part of R is refreshed whenever new production rules are created, keeping only the ones engendering high rewards. This approach accelerates the policy search by capturing and locking some modules that likely contribute to, or appear as part of the optimal solution, especially in the cases of the mathematical expression containing \u201cdeep\u201d operations (e.g., high-order polynomials) whose structures are difficult for the MCTS agent to repeatedly obtain during the selection and expansion. 4 SYMBOLIC REGRESSION: FINDING MATHEMATICAL FORMULAS: 4.1 DATA NOISE & SCARCITY GP SPL Figure 3: The effect of data noise/scarcity on recovery rate. The heatmaps demonstrate the recovery rate of GP-based symbolic regressor and the SPL machine under different data conditions, summarized over 100 independent trials. Data scarcity and noise are commonly seen in measurement data and become one of the bottleneck issues for discovering the governing equations of nonlinear dynamics. Tackling the challenges in high-level data scarcity and noise situations is traditionally regarded as an essential robustness indicator for a nonlinear dynamics discovery model. Prior to this, we present an examination of the proposed SPL machine by an equation discovery task in the presence of multiple levels of data noise and volumes, comparing with a GP-based symbolic regressor (implemented with gplearn python package)1. The target equation is f(x) = 0.3x3 + 0.5x2 + 2x, and the independent variable X is uniformly sampled in the given range [\u221210, 10]. Gaussian white noise is added to the dependent variable Y with the noise level defined as the root-mean-square ratio between the noise and the exact values. For discovery, the two models are fed with equivalent search space: {+,\u2212,\u00d7,\u00f7, cost, x} as candidate mathematical operations and symbols. The hyperparameters of te SPL machine are set as \u03b7 = 0.99, tmax = 50, and 10,000 episodes of training is regarded as one trail. For the GP-based symbolic regressor, population of programs is set to as 2000, number of generations as 20, the range of constant values is [\u221210, 10]. For 16 different data noise and scarcity levels, each model performs 100 independent trails. The recovery rates are displayed as a 4\u00d7 4 mesh grid with different noise and scarcity levels in Figure 3. It is clearly observed that the SPL machine outperforms the GP-based symbolic regressor in all the cases. A T-test also proves that recovery rate of the SPL machine is significantly higher than that of the GP-based symbolic regressor (p-value = 1.06\u00d7 10\u22127). 4.2 NGUYEN\u2019S SYMBOLIC REGRESSION BENCHMARK: Nguyen\u2019s symbolic regression benchmark task (Uy et al., 2011) is widely used by the equation discovery work as an indicator of a model\u2019s robustness in symbolic regression problems. Given a set of allowed operators, a target equation, and data generated by this equation, the tested model is supposed to distill mathematical expression that is identical to the target equation, or equivalent to it (e.g., Nguyen-7 equation can be recovered as log(x3 + x2 + x+ 1), Nguyen-10 equation can 1All simulations are performed on a workstation with a NVIDIA GeForce RTX 2080Ti GPU. be recovered as sin(x + y), and Nguyen-11 equation can be recovered as exp(y log(x))). Some variants of Nguyen\u2019s benchmark equations are also considered in this experiment. Their discoveries require numerical estimation of constant values. Each equation generates two datasets: one for training and another for testing purposes. The discovered equation that perfectly fits the testing data is regarded as a successful discovery. The recovery rate is calculated based on 100 independent tests for each task. In these benchmark tasks, three algorithms are tested: GP-based symbolic regressor, the neural-guided GP (NGGP) (Mundhenk et al., 2021), and the proposed SPL machine. Note that NGGP is an improved approach over DSR (Petersen et al., 2021). They are given the same set of candidate operations: {+,\u2212,\u00d7,\u00f7, exp(\u00b7), cos(\u00b7), sin(\u00b7)} for all benchmarks and { \u221a \u00b7, ln(\u00b7)} are added to the 7, 8, 11 benchmarks. The hyperparameters of the GP-based symbolic regressor are the same as those mentioned in Section 4.1; configurations of the NGGP models are obtained from its source code2; detailed setting of the benchmark tasks and the SPL model is described in Appendix Section A. The success rates are shown in Table 1. It is observed that the SPL machine and the NGGP model both produce reliable results in Nguyen\u2019s benchmark problems and the SPL machine slightly outperformed the NGGP. This experiment betokens the capacity of the SPL machine in equation discoveries with divergent forms. Ablation Study: We consider three ablation studies by removing: (a) the adaptive scaling in reward calculation, (b) the discount factor \u03b7n that drives equation parsimony in Eq. (2), and (c) module transplantation in tree generation. The ablated models were tested on the above 17 Nguyen equations. Results show that the average recovery rates for these models are all below 60% (numbers are not listed due to space limit). Hence, these modules are critical to guarantee the proposed model efficacy. 5 PHYSICS LAW DISCOVERY: FREE FALLING BALLS WITH AIR RESISTANCE: Table 2: Baseline models (ci: unknown constants). Physics Model Derived model expression Model-1 H(t) = c0 + c1t+ c2t2 + c3t3 Model-2 H(t) = c0 + c1t+ c2ec3t Model-3 H(t) = c0 + c1 log(cosh(c2t)) It is well known that in 1589\u201392 Galileo dropped two objects of unequal mass from the Leaning Tower of Pisa and drew a conclusion that their velocities were not affected by the mass. This has been well recognized globally as the \u201ctextbook\u201d physics law for the vertical motion of a free-falling object: the 2NGGP source code: https://github.com/brendenpetersen/deep-symbolic-optimization/tree/master/dso/dso height of the object is formulated as H(t) = h0 + v0t\u2212 12gt 2, where h0 denotes initial height, v0 the initial velocity, and g the gravitational acceleration. However, this ideal situation is rarely reached in our daily life because air resistance serves as a significant damping factor that prevents the above physics law from occurring in real-life cases. Many efforts have been made to uncover the effect of the air resistance and derive mathematical models to describe the free-falling objects with air resistance (Clancy, 1975; Lindemuth, 1971; Greenwood et al., 1986). This section provides a data-driven discovery of the physics laws of relationships between height and time in the cases of free-falling objects with air resistance based on multiple experimental ball-drop datasets (de Silva et al., 2020), which contain the records of 11 different types of balls dropped from a bridge (see Appendix Figure B.1). For discovery, each dataset is split into a train set (records from the first 2 seconds) and a test set (records after 2 seconds). Three mathematically derived physics models are selected from the literature as baseline models3,4,5 for this experiment (see Table 2), and the unknown constant values are solved by Powell\u2019s conjugate direction method (Powell, 1964). Based on prior knowledge of the physics law that may appear in this case, this experiment uses {+,\u2212,\u00d7,\u00f7, exp(\u00b7), cosh(\u00b7), log(\u00b7)} as the candidate grammars of the SPL discovery, with terminal nodes {t, const}. The hyperparameters are set as \u03b7 = 0.9999, tmax = 20, and one single discovery is built upon 6,000 episodes of training. The physics laws distilled by SPL from training data are applied to the test data and compared with the ground truth. Their prediction errors, in terms of MSE, are presented in Table 3 (the SPL-discovered equations are shown in Appendix Table B.1). The full results can be found in Appendix Section B. It can be concluded that the data-driven discovery of physical laws leads to a better approximation of the free-falling objects with air resistance. 6 CHAOTIC DYNAMICS DISCOVERY: THE LORENZ SYSTEM: The first nonlinear dynamics discovery example is a 3-dimensional Lorenz system (Lorenz, 1963) whose dynamical behavior (x, y, z) is governed by x\u0307 = \u03c3(y\u2212 x), y\u0307 = x(\u03c1 \u2212 z) \u2212 y, z\u0307 = xy \u2212 \u03b2z with parameters \u03c3 = 10, \u03b2 = 8/3, and \u03c1 = 28, under which the Lorenz attractor has two lobes and the system, starting from anywhere, makes cycles around one lobe before switching to the other and iterates repeatedly. The resulting system exhibits strong chaos. The synthetic datasets are generated by solving the nonlinear differential equations using Matlab ode113 (Shampine, 1975; Shampine & Reichelt, 1997) function. 5% Gaussian white noise is added to the clean data to generate noisy measurement. The derivatives of the system states are estimated by central difference and smoothed by the Savitzky\u2013Golay filter (Savitzky & Golay, 1964) in order to reduce the noise effect. In this experiment, the proposed SPL machine will compare with three benchmark methods, Eureqa, pySINDy and NGGP. For Eureqa, NGGP, and the SPL machine, {+,\u2212,\u00d7,\u00f7} are used as candidate operations; the upper bound of complexity is set to be 50; for pySINDy, the candidate function library includes all polynomial basis of x, y, z from degree 1 to degree 4. Appendix Table C.1 3Model 1: https://faraday.physics.utoronto.ca/IYearLab/Intros/FreeFall/FreeFall.html 4Model 2: https://physics.csuchico.edu/kagan/204A/lecturenotes/Section15.pdf 5Model 3: https://en.wikipedia.org/wiki/Free_fall presents the distilled governing dynamics by each approach and Table 4 summarizes these results: the SPL machine uncovers the explicit form of equations accurately in the context of active terms, whereas Eureqa, pySINDy and NGGP yield several false-positive terms in the governing equations. In particular, although Eureqa and NGGP are capable of uncovering the correct terms, their performance is very sensitive to the measurement noise as indicated by the redundant terms (despite with small coefficients) shown in Appendix Table C.1. Overall, the baseline methods fail to handle the large noise effect, essentially limiting their applicability in nonlinear dynamics discovery. It is evident that the SPL machine is capable of distilling the concise symbolic combination of operators and variables to correctly formulate parsimonious mathematical expressions that govern the Lorenz system, outperforming the baseline methods of Eureqa, pySINDy and NGGP. 7 EXPERIMENTAL DYNAMICS DISCOVERY: DOUBLE PENDULUM: This section shows SPL-based discovery of a chaotic double pendulum system with experimental data (Asseman et al., 2018) as shown in Appendix Figure C.3. The governing equations can be derived by the Lagrange method, given by: \u03c9\u03071 = c1\u03c9\u03072 cos(\u2206\u03b8) + c2\u03c9 2 2 sin(\u2206\u03b8) + c3 sin(\u03b81) +R1(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072), \u03c9\u03072 = c1\u03c9\u03071 cos(\u2206\u03b8) + c2\u03c9 2 1 sin(\u2206\u03b8) + c3 sin(\u03b82) +R2(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072) (4) where \u03b81, \u03b82 denote the angular displacements; \u03c91 = \u03b8\u03071, \u03c92 = \u03b8\u03072 the velocities; \u03c9\u03071, \u03c9\u03072 the accelerations; R1 and R2 denote the unknown damping forces. Note that \u2206\u03b8 = \u03b81 \u2212 \u03b82. The data source contains multiple camera-sensed datasets. Here, 5,000 denoised random sub-samples from 5 datasets are used for training, and 2,000 random sub-samples from another 2 datasets for validation, and 1 dataset for testing. The derivatives of the system states are numerically estimated by the same approach discussed in the Lorenz case. Some physics are employed to guide the discovery: (1) \u03c9\u03072 cos(\u2206\u03b8) for \u03c9\u03071 and \u03c9\u03071 cos(\u2206\u03b8) are given; (2) the angles (\u03b81, \u03b82, \u2206\u03b8) are under the trigonometric functions cos(\u00b7) and sin(\u00b7); (3) directions of velocities/relative velocities may appear in damping. Production rules fulfilling the above prior knowledge are exhibited in Appendix Section C.2. The hyperparameters are set as \u03b7 = 1, tmax = 20, and 40,000 episodes of training is regarded as one trail. 5 independent trials are performed and the equations with the highest validation scores are selected as the final results. The uncovered equations are given as follows: \u03c9\u03071 = \u22120.0991\u03c9\u03072 cos(\u2206\u03b8)\u2212 0.103\u03c922 sin(\u2206\u03b8)\u2212 69.274 sin(\u03b81) + 0.515 cos(\u03b81), \u03c9\u03072 = \u22121.368\u03c9\u03071 cos(\u2206\u03b8) + 1.363\u03c921 sin(\u2206\u03b8)\u2212 92.913 sin(\u03b82) + 0.032\u03c91, (5) where the explicit expression of physics in an ideal double pendulum system, as displayed in Eq. (5), are successfully distilled and damping terms are estimated. This set of equation is validated through interpolation on the testing set and compared with the smoothed derivatives, as shown in Appendix Figure C.4. The solution appears felicitous as the governing equations of the testing responses. 8 CONCLUSION AND DISCUSSION: This paper introduces a Symbolic Physics Learner (SPL) machine to tackle the challenge of distilling the mathematical structure of equations and nonlinear dynamics with unknown forms of measurement data. This framework is built upon the expression tree interpretation of mathematical operations and variables and an MCTS agent that searches for the optimistic policy to reconstruct the target mathematical expression. With some remarkable adjustments to the MCTS algorithms, the SPL model straightforwardly accepts prior or domain knowledge, or any sorts of constraints of the tasks in the grammar design while leveraging great flexibility in expression formulation. The robustness of the proposed SPL for complex target expression discovery with large search space is indicated in Nguyen\u2019s symbolic regression benchmark problems, where the SPL machine outperforms state-of-the-art symbolic regression methods. Moreover, encouraging results are obtained in the physics law and nonlinear dynamics discovery tasks that are based on synthetic or experimental datasets. While the proposed SPL framework shows huge potential in both symbolic regression and physics/nonlinear dynamics discovery tasks, there are still some imperfections that can be improved: (i) the computational cost is high for constant value estimation, (ii) graph modularity is underexamined, and (iii) robustness against extreme data noise and scarcity is not optimal. These limitations are further explained in Appendix Section D. A NGUYEN\u2019S BENCHMARK PROBLEMS: This section provides more detailed experiment settings for Nguyen\u2019s benchmark tasks that are described in the Section 4 of the main context and then exhibits the training hyperparameters for the SPL machine in these equation discovery experiments: Table A.1 presents the candidate mathematical operations allowed for three tested models and Table A.2 displays training hyperparameters for the SPL machine in the Nguyen\u2019s benchmark tasks. Moreover, the utilization of CFG in the SPL machine facilitates the flexibility of applying some prior knowledge including the universal mathematical rules and constraints. This feature empirically turns out to be an accessible and scalable approach for avoiding meaningless mathematical expressions. In the Nguyen\u2019s benchmark tasks, one or multiple mathematical constraints are given to the SPL machine. These constraints include 1. Only variables and constant values allowed in trigonometric functions. 2. Variables in trigonometric functions, logarithms and roots are up to the polynomial of 3. 3. Trigonometric functions, logarithms and roots are not allowed to form unreasonable composite functions with each other, such as sin(cos(...)). 4. Some small integers (e.g. 1, 2) are used directly as leaves. They can be easily implemented into the SPL machine by defining adjusting non-terminal nodes or production rules in the customized CFG. Constraints adopted by each task is shown in Table A.3. B FREE FALLING BALLS WITH AIR RESISTANCE: This appendix section reveals more details in the data-driven discovery of the physics laws of relationships between height and time in the cases of free-falling objects with air resistance based on multiple experimental ball-drop datasets (de Silva et al., 2020). The datasets contain the records of 11 different types of balls, as shown in Figure B.1, dropped from a bridge with a 30 Hz sampling rate. The time between dropping and landing varies in each case, which is due to the fact that air resistance has different effects on these free-dropping balls and induces divergent physics laws. Consequently, we consider each ball as an individual experiment and discover physics laws for each of them. The measurement dataset of a free-dropping ball is split into a training set (records from the first 2 seconds, 60 measurement) and a testing set (records after 2 seconds). The physics laws distilled by the three mathematically derived physics models displayed in the main text and the SPL machine from training data are exhibited in Table B.1. These discovered physics laws are then applied to forecast the height of the balls at the time slots in testing dataset. These predictions, in comparison with the ground truth trajectory recorded, are shown in Figure B.2. Prediction error is shown in the Table 3 of the main context. C NONLINEAR DYNAMICS DISCOVERY: This appendix section expands the two governing equation discovery experiments presented in the main context, including the datasets and full results. C.1 LORENZ SYSTEM The 3-dimensional Lorenz system is governed by x\u0307 = \u03c3(y \u2212 x) y\u0307 = x(\u03c1\u2212 z)\u2212 y z\u0307 = xy \u2212 \u03b2z (6) with parameters \u03c3 = 10, \u03b2 = 8/3, and \u03c1 = 28, under which the Lorenz attractor has two lobes and the system, starting from anywhere, makes cycles around one lobe before switching to the other and iterates repeatedly. The measurement data of Lorenz system in this experiment contains a clean signal with 5% Gaussian white noise. The derivatives of Lorenz\u2019s state variables are numerically estimated and smoothed by the Savitzky\u2013Golay filter. The noisy synthetic measurement and numerically obtained derivatives are shown in Figure C.1, Table C.1 presents the distilled governing equations of the Lorenz system by 4 tested models. It is observed that the SPL uncover the explicit form of equations accurately in the context of active terms, whereas Eureqa, pySINDy and NGGP yield several false-positive terms in governing equations. 5-second predicted system responses (starting from a different initial condition) simulated from these uncovered equations are shown in Figure C.2. Though it is hard to reproduce the most accurate coefficients due to the tremendous errors due to numerical differentiation of noisy measurement as depicted in Figure C.1, the SPL machine is still capable of distilling the most concise symbolic combination of operators and variables to correctly formulate parsimonious mathematical expressions that govern the Lorenz system. The predicted responses from the governing equations unearthed by the SPL machine simulates the system in a decent manner. C.2 MOUNTED DOUBLE PENDULUM SYSTEM The second nonlinear dynamics discovery experiment is on a camera-measured chaotic double pendulum system (Asseman et al., 2018). The sensed data is in form of videos of the chaotic motion of a double pendulum on the device shown in Figure C.3A filmed with a high-speed camera. The positional data is converted into angular form by using the model shown in Figure C.3C. The governing equations for a mounted pendulum system can be derived with Euler\u2013Lagrange method: (m1 +m2)l1\u03b8\u03081 +m2l2\u03b8\u03082 cos(\u03b81 \u2212 \u03b82) +m2l2\u03c922 sin(\u03b81 \u2212 \u03b82) + (m1 +m2)g sin(\u03b81) = F1, m2l2\u03b8\u03082 +m2l1\u03b8\u03081 cos(\u03b81 \u2212 \u03b82)\u2212m2l1\u03c921 sin(\u03b81 \u2212 \u03b82) +m2g sin(\u03b82) = F2, (7) which, by denoting \u03c9 as the velocity, can be converted to the form of \u03b8\u03071 = \u03c91, \u03b8\u03072 = \u03c92, \u03c9\u03071 = c1\u03c9\u03072 cos(\u2206\u03b8) + c2\u03c9 2 2 sin(\u2206\u03b8) + c3 sin(\u03b81) +R1(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072), \u03c9\u03072 = c1\u03c9\u03071 cos(\u2206\u03b8) + c2\u03c9 2 1 sin(\u2206\u03b8) + c3 sin(\u03b82) +R2(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072) (8) where \u2206\u03b8 = \u03b81 \u2212 \u03b82, and R1(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072) and R2(\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072) denote the damping terms for the last two differential equations. The data source contains multiple camera-sensed datasets. For this discovery, 5,000 denoised random sub-samples from 5 datasets are used for training purposes, and 2,000 random sub-samples from another 2 datasets for validation, and 1 dataset for testing. Some prior knowledge guiding this the discovery includes: 1. \u03c9\u03072 cos(\u2206\u03b8) for \u03c9\u03071 and \u03c9\u03071 cos(\u2206\u03b8) for \u03c9\u03072 are easily derived. Both terms are given. 2. the remaining of the formulas are potentially comprised of the free combination of \u03c9\u03071, \u03c9\u03072, \u03c91, \u03c92, as well as the angles (\u03b81, \u03b82, \u2206\u03b8) under the trigonometric functions cos(\u00b7) and sin(\u00b7). 3. velocities and relative velocities of two masses, as well as their directions (sign function) might contribute to the damping. Based on these information, the candidate production rules for governing differential equations \u03c9\u03071 and \u03c9\u03072 are shown as below, where non-terminal nodes are V = {A,W, T, S} and C denotes the placeholder symbol for constant values. A \u2192 A+A, A \u2192 A\u00d7A, A \u2192 C, A \u2192 A+A, A \u2192 W , W \u2192 W \u00d7W , W \u2192 \u03c91, W \u2192 \u03c92, W \u2192 \u03c9\u03071, W \u2192 \u03c9\u03072, A \u2192 cos(T ), A \u2192 sin(T ), T \u2192 T + T , T \u2192 T \u2212 T , T \u2192 \u03b81, T \u2192 \u03b82, A \u2192 sign(S), S \u2192 S + S, S \u2192 S \u2212 S, S \u2192 \u03c91, S \u2192 \u03c92, S \u2192 \u03c9\u03071, S \u2192 \u03c9\u03072 A \u2192 \u03c9\u03071 cos(\u03b81 \u2212 \u03b82), A \u2192 \u03c9\u03072 cos(\u03b81 \u2212 \u03b82) The hyperparameters are set as \u03b7 = 1, tmax = 20, and 40,000 episodes of training is regarded as one trail. 5 independent trials are performed and the equations with the highest validation scores are selected as the final results. The uncovered equations are shown in Table C.2. They are validated through interpolation on the testing set and compared with the smoothed derivatives, as shown in Figure C.4. The solution appears felicitous as the governing equations of the testing responses. D DISCUSSION AND FUTURE DIRECTIONS: While the proposed SPL framework shows huge potential in both symbolic regression and physics law/governing equation discovery tasks, there are still some imperfections to be improved. In this appendix section, a few bottlenecks and their potential solutions are presented: 1. Computational cost. Computational cost for this framework is one of the major issues, especially when constant estimation is required. Evaluating the solution in the simulation phase happens very frequently for the MCTS algorithm where the policy selection relies heavily on a large number of historical rewards. However, constant value estimation, which can be slow, is required for evaluation purposes. The SPL machine is not the only symbolic regressor suffering from the computational cost in constant value estimation. In fact, the state-of-the-art symbolic regression model, the neural-guided GP (NGGP) (Mundhenk et al., 2021), becomes much slower in the Nguyen\u2019s benchmark variant tasks (see Table C.3). The current implementation of the SPL machine tries to empirically avoid this issue by limiting the number of placeholders in a discovered expression and simplifying the expression before evaluating, but still cannot reach a great efficiency. This bottleneck might be mitigated if parallel computing is introduced to the MCTS simulation phase. 2. Graph modularity underexamined. The current design of the SPL training scheme does not leverage the full graph modularity: modules are reached by transforming a complete parse tree into a grammar. However, in some cases, there might be some influential modules appearing frequently as part of the tree. This type of graph modularity is described in the AI-Feynman method (Udrescu et al., 2020). Deploying a more comprehensive graph modularity into the SPL machine will boost its efficacy in complex equation and nonlinear dynamics discovery tasks. 3. Robustness against extreme data noise and scarcity. Though it is observed that this reinforcement learning-based method is able to unearth the parsimonious solution to the governing equations from synthetic or measurement data with a moderate level of noise and scarcity. It is not effective when the data condition is too extreme, or if there are missing values that make it challenging to numerically calculate the state derivatives. It is reasonable to investigate the integration between the SPL framework with a physics-guided surrogate model that are built upon neural networks (Long et al., 2018; Chen et al., 2021) or spline learning (Sun et al., 2021) for further robustness in nonlinear dynamics discovery tasks."}, {"role": "assistant", "content": "Okay, I will review the paper \"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search\" for ICLR 2023. I will create 3 reviewer agents with specialized expertise to evaluate the paper from multiple perspectives.\n\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={}, name='GetBudget'), function_response=None, inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'directory': '.'}, name='ListFiles'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Budget retrieved successfully\",\n  \"output\": {\n    \"total_resource_budget\": 100,\n    \"current_resource_usage\": 0,\n    \"current_remaining_resource_budget\": 100,\n    \"total_expense_budget\": 10000,\n    \"current_expense\": 0.0010145,\n    \"current_remaining_expense_budget\": 9999.9989855\n  }\n}\n```\n", "metadata": {"title": "Invoking `GetBudget` with \n```json\n{}\n```\n", "id": 0, "status": "done"}}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Files listed successfully\",\n  \"error\": null,\n  \"output\": [\n    \"favicon.ico\",\n    \"requirements.txt\",\n    \"HASHIRU_LOGO.png\",\n    \"HASHIRU_ARCH.png\",\n    \"deleteAgents.py\",\n    \"CITATION.cff\",\n    \"tests\",\n    \"awae.py\",\n    \"__pycache__\",\n    \"start.py\",\n    \"README.md\",\n    \"results\",\n    \"HASHIRU.png\",\n    \".gitignore\",\n    \".env\",\n    \"static\",\n    \".gitattributes\",\n    \"app.py\",\n    \"HASHIRU_2.png\",\n    \".git\",\n    \"paper_review_hashiru_20250627_201357.jsonl\",\n    \"src\"\n  ]\n}\n```\n", "metadata": {"title": "Invoking `ListFiles` with \n```json\n{\n  \"directory\": \".\"\n}\n```\n", "id": 1, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='GetBudget', response={'result': {'status': 'success', 'message': 'Budget retrieved successfully', 'output': {'total_resource_budget': 100, 'current_resource_usage': 0, 'current_remaining_resource_budget': 100, 'total_expense_budget': 10000, 'current_expense': 0.0010145, 'current_remaining_expense_budget': 9999.9989855}}}), inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='ListFiles', response={'result': {'status': 'success', 'message': 'Files listed successfully', 'error': None, 'output': ['favicon.ico', 'requirements.txt', 'HASHIRU_LOGO.png', 'HASHIRU_ARCH.png', 'deleteAgents.py', 'CITATION.cff', 'tests', 'awae.py', '__pycache__', 'start.py', 'README.md', 'results', 'HASHIRU.png', '.gitignore', '.env', 'static', '.gitattributes', 'app.py', 'HASHIRU_2.png', '.git', 'paper_review_hashiru_20250627_201357.jsonl', 'src']}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'query': 'ICLR 2023 review criteria', 'website': 'iclr.cc'}, name='GoogleSearchTool'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Search completed successfully\",\n  \"output\": [\n    \"https://iclr.cc/Conferences/2023/ReviewerGuide\",\n    \"https://blog.iclr.cc/2023/04/12/ethics-review-process-for-iclr-2023/\",\n    \"https://blog.iclr.cc/category/iclr-2023/\",\n    \"https://blog.iclr.cc/tag/reviewing/\",\n    \"https://blog.iclr.cc/tag/awards/\",\n    \"https://blog.iclr.cc/2023/04/05/announcing-notable-reviewers-and-area-chairs-at-iclr-2023/\",\n    \"https://iclr.cc/Conferences/2022/ReviewerGuide\",\n    \"https://iclr.cc/Conferences/2025/FAQ\",\n    \"https://iclr.cc/Conferences/2023/CallForTinyPapers\",\n    \"https://iclr.cc/Conferences/2019/Reviewer_Guidelines\"\n  ]\n}\n```\n", "metadata": {"title": "Invoking `GoogleSearchTool` with \n```json\n{\n  \"query\": \"ICLR 2023 review criteria\",\n  \"website\": \"iclr.cc\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='GoogleSearchTool', response={'result': {'status': 'success', 'message': 'Search completed successfully', 'output': ['https://iclr.cc/Conferences/2023/ReviewerGuide', 'https://blog.iclr.cc/2023/04/12/ethics-review-process-for-iclr-2023/', 'https://blog.iclr.cc/category/iclr-2023/', 'https://blog.iclr.cc/tag/reviewing/', 'https://blog.iclr.cc/tag/awards/', 'https://blog.iclr.cc/2023/04/05/announcing-notable-reviewers-and-area-chairs-at-iclr-2023/', 'https://iclr.cc/Conferences/2022/ReviewerGuide', 'https://iclr.cc/Conferences/2025/FAQ', 'https://iclr.cc/Conferences/2023/CallForTinyPapers', 'https://iclr.cc/Conferences/2019/Reviewer_Guidelines']}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'url': 'https://iclr.cc/Conferences/2023/ReviewerGuide', 'output_type': 'full_text'}, name='GetWebsite'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Search completed successfully\",\n  \"output\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nICLR 2022 Reviewer Instructions\\n\\n\\n\\n\\n\\nSkip to yearly menu bar\\nSkip to main content\\n\\nMain Navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            ICLR\\n        \\n\\n\\n\\n\\n                        Help/FAQ\\n                    \\n\\n\\n\\n\\n\\n\\n                        Contact ICLR\\n                    \\n\\n\\n\\n\\n\\n\\n                        Downloads\\n                    \\n\\n\\n\\n\\n\\n\\n                        ICLR Blog\\n                    \\n\\n\\n\\n\\n\\n\\n                        Code of Conduct\\n                    \\n\\n\\n\\n\\n\\n\\n                        Privacy Policy\\n                    \\n\\n\\n\\n\\n\\n\\n                        Create Profile\\n                    \\n\\n\\n\\n\\n\\n\\n                        Reset Password\\n                    \\n\\n\\n\\n\\n\\n\\n                        Journal To Conference Track\\n                    \\n\\n\\n\\n\\n\\n\\n                        Diversity & Inclusion\\n                    \\n\\n\\n\\n\\n\\n\\n                        Proceedings at OpenReview\\n                    \\n\\n\\n\\n\\n\\n\\n                        Future Meetings\\n                    \\n\\n\\n\\n\\n\\n\\n                        Press\\n                    \\n\\n\\n\\n\\n\\n\\n                        Exhibitor Information\\n                    \\n\\n\\n\\n\\n\\n\\n                        ICLR Twitter\\n                    \\n\\n\\n\\n\\n\\n\\n                        About ICLR\\n                    \\n\\n\\n\\n\\n\\n\\n\\n                        My Stuff\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Login\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Select Year: (2023)\\n        \\n\\n\\n2026\\n                \\n\\n\\n\\n2025\\n                \\n\\n\\n\\n2024\\n                \\n\\n\\n\\n2023\\n                \\n\\n\\n\\n2022\\n                \\n\\n\\n\\n2021\\n                \\n\\n\\n\\n2020\\n                \\n\\n\\n\\n2019\\n                \\n\\n\\n\\n2018\\n                \\n\\n\\n\\n2017\\n                \\n\\n\\n\\n2016\\n                \\n\\n\\n\\n2015\\n                \\n\\n\\n\\n2014\\n                \\n\\n\\n\\n2013\\n                \\n\\n\\n\\n\\n\\n\\n                        Dates\\n                    \\n\\n\\n\\n\\n            Calls\\n        \\n\\n\\n\\n\\n                        Call for Papers\\n                    \\n\\n\\n\\n\\n\\n\\n                        Call for Tiny Papers\\n                    \\n\\n\\n\\n\\n\\n\\n                        Call for Workshops\\n                    \\n\\n\\n\\n\\n\\n\\n                        Call for Blog Posts\\n                    \\n\\n\\n\\n\\n\\n\\n                        Call for Socials\\n                    \\n\\n\\n\\n\\n\\n\\n            Guides\\n        \\n\\n\\n\\n\\n                        Author Guide\\n                    \\n\\n\\n\\n\\n\\n\\n                        Reviewer Guide\\n                    \\n\\n\\n\\n\\n\\n\\n                        Area Chair Guide\\n                    \\n\\n\\n\\n\\n\\n\\n            Attend\\n        \\n\\n\\n\\n\\n                        Register\\n                    \\n\\n\\n\\n\\n\\n\\n                        Visa and Travel  Information\\n                    \\n\\n\\n\\n\\n\\n\\n                        Hotels\\n                    \\n\\n\\n\\n\\n\\n\\n                        Child Care\\n                    \\n\\n\\n\\n\\n\\n\\n                        Visiting Kigali\\n                    \\n\\n\\n\\n\\n\\n\\n                        Code of Conduct\\n                    \\n\\n\\n\\n\\n\\n\\n            Organization\\n        \\n\\n\\n\\n\\n                        ICLR Board\\n                    \\n\\n\\n\\n\\n\\n\\n                        Organizing Committee\\n                    \\n\\n\\n\\n\\n\\n\\n                        Program Committee\\n                    \\n\\n\\n\\n\\n\\n\\n                        Reviewers\\n                    \\n\\n\\n\\n\\n\\n\\n                        Ethics Committee\\n                    \\n\\n\\n\\n\\n\\n\\n                        About ICLR\\n                    \\n\\n\\n\\n\\n\\n\\n\\n                        Conference Site\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\nICLR 2023 Reviewer Guide\\nThank you for agreeing to serve as an ICLR 2023 reviewer. Your contribution as a reviewer is paramount to creating an exciting and high-quality program. We ask that:\\n\\nYour reviews are timely and substantive.\\nYou follow the reviewing guidelines below.\u00a0\\nYou adhere to our Code of Ethics in your role as a reviewer. You must also adhere to our Code of Conduct.\\n\\nThis guide is intended to help you understand the ICLR 2023 decision process and your role within it. It contains:\\n\\nAn outline of the main reviewer tasks\\nStep-by-step reviewing instructions (especially relevant for reviewers that are new to ICLR)\\nReview examples\\nAn FAQ.\\n\\n\u00a0\\n\\n\\nWe\u2019re counting on you\\nAs a reviewer you are central to the program creation process for ICLR 2023. Your Area Chairs (ACs), Senior Area Chairs (SACs) and the Program Chairs (PCs) will rely greatly on your expertise and your diligent and thorough reviews to make decisions on each paper. Therefore, your role as a reviewer is critical to ensuring a strong program for ICLR 2023.\\nHigh-quality reviews are also very valuable for helping authors improve their work, whether it is eventually accepted by ICLR 2023, or not. Therefore it is important to treat each valid ICLR 2023 submission with equal care.\\nAs a token of our appreciation for your essential work, top reviewers will be acknowledged permanently on the ICLR 2023 website. Furthermore, top and high quality reviewers will receive special acknowledgement during the opening ceremony and free registration to ICLR 2023.\\n\u00a0\\n\\nMain reviewer tasks\\nThe main reviewer tasks and dates are as follows:\\n\\nCreate or update your OpenReview profile (September 30 2022)\\nBid on papers (September 30 2022 - October 06 2022)\\nWrite a constructive, thorough and timely review (October 12 2022 - October 24 2022)\\nInitial paper reviews released (November 4 2022)\\nDiscuss with authors and other reviewers to clarify and improve the paper (November 4 2022 - November 18 2022)\\nFlag any potential CoE violations and/or concerns (by November 18 2022)\\nProvide a recommendation to the area chair assigned to the paper (by November 18 2022)\\nVirtual Meeting with AC if paper you reviewed falls into borderline papers (November 18 2022 - December 12 2022)\\nProvide a final recommendation to the area chair assigned to the paper (after Virtual Meeting)\\n\\n\u00a0\\n\\n\\n\u00a0\\nCode of Ethics\\nAll ICLR participants, including reviewers, are required to adhere to the ICLR Code of Ethics (https://iclr.cc/public/CodeOfEthics). All reviewers are required to read the Code of Ethics and adhere to it. The Code of Ethics applies to all conference participation, including paper submission, reviewing, and paper discussion.\u00a0\\nAs part of the review process, reviewers are asked to raise potential violations of the ICLR Code of Ethics. Note that authors are encouraged to discuss questions and potential issues regarding the Code of Ethics as part of their submission. This discussion is not counted against the maximum page limit of the paper and should be included as a separate section.\\n\u00a0\\n\\n\u00a0\\nReviewing a submission: step-by-step\\nSummarized in one sentence, a review aims to determine whether a submission will bring sufficient value to the community and contribute new knowledge. The process can be broken down into the following main reviewer tasks:\\n\u00a0\\n\\n\\nRead the paper: It\u2019s important to carefully read through the entire paper, and to look up any related work and citations that will help you comprehensively evaluate it. Be sure to give yourself sufficient time for this step.\\nWhile reading, consider the following:\\n\\nObjective of the work: What is the goal of the paper? Is it to better address a known application or problem, draw attention to a new application or problem, or to introduce and/or explain a new theoretical finding? A combination of these? Different objectives will require different considerations as to potential value and impact.\\nStrong points: is the submission clear, technically correct, experimentally rigorous, reproducible, does it present novel findings (e.g. theoretically, algorithmically, etc.)?\\nWeak points: is it weak in any of the aspects listed in b.?\\nBe mindful of potential biases and try to be open-minded about the value and interest a paper can hold for the entire ICLR community, even if it may not be very interesting for you.\\n\\n\\nAnswer four key questions for yourself, to make a recommendation to Accept or Reject:\\n\\nWhat is the specific question and/or problem tackled by the paper?\\nIs the approach well motivated, including being well-placed in the literature?\\nDoes the paper support the claims? This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous.\\nWhat is the significance of the work? Does it contribute new knowledge and sufficient value to the community? Note, this does not necessarily require state-of-the-art results. Submissions bring value to the ICLR community when they convincingly demonstrate new, relevant, impactful knowledge (incl., empirical, theoretical, for practitioners, etc).\\n\\n\\nWrite and submit your initial review, organizing it as follows:\u00a0\\n\\nSummarize what the paper claims to contribute. Be positive and constructive.\\nList strong and weak points of the paper. Be as comprehensive as possible.\\nClearly state your initial recommendation (accept or reject) with one or two key reasons for this choice.\\nProvide supporting arguments for your recommendation.\\nAsk questions you would like answered by the authors to help you clarify your understanding of the paper and provide the additional evidence you need to be confident in your assessment.\u00a0\\nProvide additional feedback with the aim to improve the paper. Make it clear that these points are here to help, and not necessarily part of your decision assessment.\\n\\n\\nComplete the CoE report: ICLR has adopted the following Code of Ethics (CoE). When submitting your review, you\u2019ll be asked to complete a CoE report for the paper. The report is a simple form with two questions. The first asks whether there is a potential violation of the CoE. The second is relevant only if there is a potential violation and asks the reviewer to explain why there may be a potential violation. In order to answer these questions, it is therefore important that you read the CoE before starting your reviews. \\n\\t\u00a0\\nEngage in discussion: The discussion phase at ICLR is different from most conferences in the AI/ML community. During this phase, reviewers, authors and area chairs engage in asynchronous discussion and authors are allowed to revise their submissions to address concerns that arise. It is crucial that you are actively engaged during this phase. Maintain a spirit of openness to changing your initial recommendation (either to a more positive or more negative) rating.\\nBorderline paper meeting: This year, we are introducing a new program for ACs to (virtually) meet and discuss with reviewers only for borderline cases. ACs will reach out to schedule this meeting. This is to ensure active discussions among reviewers, and well-thought-out decisions. ACs will schedule the meeting and facilitate the discussion. For a productive discussion, it is important to familiarize yourself with other reviewers' feedback prior to the meeting. Please note that we will be leveraging information for reviewers who failed to attend this meeting (excluding emergencies).\u00a0\\nProvide final recommendation: Update your review, taking into account the new information collected during the discussion phase, and any revisions to the submission. State your reasoning and what did/didn\u2019t change your recommendation throughout the discussion phase.\\n\\n\u00a0\\n\\n\u00a0\\nFor great in-depth resources on reviewing, see these resources:\\n\\nDaniel Dennet, Criticising with Kindness.\\nComprehensive advice: Mistakes Reviewers Make\\nViews from multiple reviewers: Last minute reviewing advice\\nPerspective from instructions to Area Chairs: Dear ACs.\\n\\n\u00a0\\n\\n\u00a0\\nReview Examples\\nHere are two sample reviews from previous conferences that give an example of what we consider a good review for the case of leaning-to-accept and leaning-to-reject.\\nReview for a Paper where Leaning-to-Accept\\nThis paper proposes a method, Dual-AC, for optimizing the actor (policy) and critic (value function) simultaneously which takes the form of a zero-sum game resulting in a principled method for using the critic to optimize the actor. In order to achieve that, they take the linear programming approach of solving the Bellman optimality equations, outline the deficiencies of this approach, and propose solutions to mitigate those problems. The discussion on the deficiencies of the naive LP approach is mostly well done. Their main contribution is extending the single step LP formulation to a multi-step dual form that reduces the bias and makes the connection between policy and value function optimization much clearer without losing convexity by applying a regularization. They perform an empirical study in the Inverted Double Pendulum domain to conclude that their extended algorithm outperforms the naive linear programming approach without the improvements. Lastly, there are empirical experiments done to conclude the superior performance of Dual-AC in contrast to other actor-critic algorithms.\u00a0\\nOverall, this paper could be a significant algorithmic contribution, with the caveat for some clarifications on the theory and experiments. Given these clarifications in an author response, I would be willing to increase the score.\u00a0\\nFor the theory, there are a few steps that need clarification and further clarification on novelty. For novelty, it is unclear if Theorem 2 and Theorem 3 are both being stated as novel results. It looks like Theorem 2 has already been shown in \\\"Randomized Linear Programming Solves the Discounted Markov Decision Problem in Nearly-Linear Running Time\u201d. There is a statement that \u201cChen & Wang (2016); Wang (2017) apply stochastic first-order algorithms (Nemirovski et al., 2009) for the one-step Lagrangian of the LP problem in reinforcement learning setting. However, as we discussed in Section 3, their algorithm is restricted to tabular parametrization\u201d. Is your Theorem 2 somehow an extension? Is Theorem 3 completely new?\\nThis is particularly called into question due to the lack of assumptions about the function class for value functions. It seems like the value function is required to be able to represent the true value function, which can be almost as restrictive as requiring tabular parameterizations (which can represent the true value function). This assumption seems to be used right at the bottom of Page 17, where U^{pi*} = V^*. Further, eta_v must be chosen to ensure that it does not affect (constrain) the optimal solution, which implies it might need to be very small. More about conditions on eta_v would be illuminating.\u00a0\\nThere is also one step in the theorem that I cannot verify. On Page 18, how is the squared removed for difference between U and Upi? The transition from the second line of the proof to the third line is not clear. It would also be good to more clearly state on page 14 how you get the first inequality, for || V^* ||_{2,mu}^2.\u00a0\\n\u00a0\\n\\nFor the experiments, the following should be addressed.\\n1. It would have been better to also show the performance graphs with and without the improvements for multiple domains.\\n2. The central contribution is extending the single step LP to a multi-step formulation. It would be beneficial to empirically demonstrate how increasing k (the multi-step parameter) affects the performance gains.\\n3. Increasing k also comes at a computational cost. I would like to see some discussions on this and how long dual-AC takes to converge in comparison to the other algorithms tested (PPO and TRPO).\\n4. The authors concluded the presence of local convexity based on hessian inspection due to the use of path regularization. It was also mentioned that increasing the regularization parameter size increases the convergence rate. Empirically, how does changing the regularization parameter affect the performance in terms of reward maximization? In the experimental section of the appendix, it is mentioned that multiple regularization settings were tried but their performance is not mentioned. Also, for the regularization parameters that were tried, based on hessian inspection, did they all result in local convexity? A bit more discussion on these choices would be helpful.\u00a0\\n\u00a0\\n\\nMinor comments:\\n1. Page 2: In equation 5, there should not be a 'ds' in the dual variable constraint\\n\u00a0\\n\\n\u00a0\\nReview for a Paper where Leaning-to-Reject\\nThis paper introduces a variation on temporal difference learning for the function approximation case that attempts to resolve the issue of over-generalization across temporally-successive states. The new approach is applied to both linear and non-linear function approximation, and for prediction and control problems. The algorithmic contribution is demonstrated with a suite of experiments in classic benchmark control domains (Mountain Car and Acrobot), and in Pong.\\nThis paper should be rejected because (1) the algorithm is not well justified either by theory or practice, (2) the paper never clearly demonstrates the existence of problem they are trying to solve (nor differentiates it from the usual problem of generalizing well), (3) the experiments are difficult to understand, missing many details, and generally do not support a significant contribution, and (4) the paper is imprecise and unpolished.\\nMain argument\\nThe paper does not do a great job of demonstrating that the problem it is trying to solve is a real thing. There is no experiment in this paper that clearly shows how this temporal generalization problem is different from the need to generalize well with function approximation. The paper points to references to establish the existence of the problem, but for example the Durugkar and Stone paper is a workshop paper and the conference version of that paper was rejected from ICLR 2018 and the reviewers highlighted serious issues with the paper\u2014that is not work to build upon. Further the paper under review here claims this problem is most pressing in the non-linear case, but the analysis in section 4.1 is for the linear case.\u00a0\\nThe resultant algorithm does not seem well justified, and has a different fixed point than TD, but there is no discussion of this other than section 4.4, which does not make clear statements about the correctness of the algorithm or what it converges to. Can you provide a proof or any kind of evidence that the proposed approach is sound, or how it\u2019s fixed point relates to TD?\\nThe experiments do not provide convincing evidence of the correctness of the proposed approach or its utility compared to existing approaches. There are so many missing details it is difficult to draw many conclusions:\\n\\nWhat was the policy used in exp1 for policy evaluation in MC?\\nWhy Fourier basis features?\\nIn MC with DQN how did you adjust the parameters and architecture for the MC task?\\nWas the reward in MC and Acrobot -1 per step or something else\\nHow did you tune the parameters in the MC and Acrobot experiments?\\nWhy so few runs in MC, none of the results presented are significant?\\nWhy is the performance so bad in MC?\\nDid you evaluate online learning or do tests with the greedy policy?\\nHow did you initialize the value functions and weights?\\nWhy did you use experience replay for the linear experiments?\\nIN MC and Acrobot why only a one layer MLP?\\n\\nIgnoring all that, the results are not convincing. Most of the results in the paper are not statistically significant. The policy evaluation results in MC show little difference to regular TD. The Pong results show DQN is actually better. This makes the reader wonder if the result with DQN on MC and Acrobot are only worse because you did not properly tune DQN for those domains, whereas the default DQN architecture is well tuned for Atari and that is why you method is competitive in the smaller domains.\u00a0\\nThe differences in the \u201caverage change in value plots\u201d are very small if the rewards are -1 per step. Can you provide some context to understand the significance of this difference? In the last experiment linear FA and MC, the step-size is set equal for all methods\u2014this is not a valid comparison. Your method may just work better with alpha = 0.1.\u00a0\\n\u00a0\\n\\nThe paper has many imprecise parts, here are a few:\\n\\nThe definition of the value function would be approximate not equals unless you specify some properties of the function approximation architecture. Same for the Bellman equation\\nequation 1 of section 2.1 is neither an algorithm or a loss function\\nTD does not minimize the squared TD. Saying that is the objective function of TD learning in not true\\nend of section 2.1 says \u201cIt is computed as\u201d but the following equation just gives a form for the partial derivative\\nequation 2, x is not bounded\u00a0\\nYou state TC-loss has an unclear solution property, I don\u2019t know what that means and I don\u2019t think your approach is well justified either\\nSection 4.1 assumes linear FA, but its implied up until paragraph 2 that it has not assumed linear\\ntreatment of n_t in alg differs from appendix (t is no time episode number)\\nYour method has a n_t parameter that is adapted according to a schedule seemingly giving it an unfair advantage over DQN.\\nOver-claim not supported by the results: \u201cwe see that HR-TD is able to find a representation that is better at keeping the target value separate than TC is \u201c. The results do not show this.\\nSection 4.4 does not seem to go anywhere or produce and tangible conclusions\\n\\n\u00a0\\n\\nThings to improve the paper that did not impact the score:\\n\\nIt\u2019s hard to follow how the prox operator is used in the development of the alg, this could use some higher level explanation\\nIntro p2 is about bootstrapping, use that term and remove the equations\\nIt\u2019s not clear why you are talking about stochastic vs deterministic in P3\\nPerhaps you should compare against a MC method in the experiments to demonstrate the problem with TD methods and generalization\\nSection 2: \u201ccan often be a regularization term\u201d >> can or must be?\\nupdate law is an odd term\\n\u00a0tends to alleviate\u201d >> odd phrase\\nsection 4 should come before section 3\\nAlg 1 in not helpful because it just references an equation\\nsection 4.4 is very confusing, I cannot follow the logic of the statements\u00a0\\nQ learning >> Q-learning\\nNot sure what you mean with the last sentence of p2 section 5\\nwhere are the results for Acrobot linear function approximation\\nappendix Q-learning with linear FA is not DQN (table 2)\\n\\n\u00a0\\n\\nFAQ for Reviewers\\nQ. The review I just submitted is not appearing! Did it go thru?\\nA. There seems to be some delay in the system for you to see your reviews. Just give a bit of time and refresh again.\\n\u00a0\\nQ. What is the borderline paper meeting between AC and reviewers about?\\nA. This year we require ACs to meet with reviewers for all borderline papers (defined and announced by PCs once all reviews are received). There will be one meeting per borderline paper. Once we receive all reviews, we will let ACs know which papers fall into this bucket. ACs will then schedule and run the meetings with the reviewers of the papers in question.\\n\u00a0\\n\\nQ: What if I can not attend the meeting?\\nA: Please work with your AC to find a meeting schedule that works for everyone. Note that the discussion phase is roughly 1 month long, and overlaps with the NeurIPS conference, in case in-person meeting is preferred. All reviewers agreed to participate in review meetings when they accepted the reviewer invitations. An AC has right to\u00a0 downweight the review of reviewers who refuse to attend the meeting.\\n\u00a0\\n\\nQ: How should I use supplementary material?\\nA: It is not necessary to read supplementary material but such material can often answer questions that arise while reading the main paper, so consider looking there before asking authors.\\n\u00a0\\n\\nQ: How should I handle a policy violation?\\nA: To flag a CoE violation related to a submission, please indicate it when submitting the CoE report for that paper. The AC will work with the PC and the ethics board to resolve the case. To discuss other violations (e.g. plagiarism, double submission, paper length, formatting, etc.), please contact either the AC/SAC or the PC as appropriate. You can do this by sending a confidential comment with the appropriate readership restrictions.\\n\u00a0\\n\\nQ: Am I allowed to ask for additional experiments?\\nA: You can ask for additional experiments. New experiments should not significantly change the content of the submission. Rather, they should be limited in scope and serve to more thoroughly validate existing results from the submission.\\n\u00a0\\n\\nQ: If a submission does not achieve state-of-the-art results, is that grounds for rejection?\\nA: No, a lack of state-of-the-art results does not by itself constitute grounds for rejection. Submissions bring value to the ICLR community when they convincingly demonstrate new, relevant, impactful knowledge. Submissions can achieve this without achieving state-of-the-art results.\\nQ: Are authors expected to cite and compare with very recent work? What about non peer-reviewed (e.g., ArXiv) papers? (updated on 7 November 2022)\\nA: We consider papers contemporaneous if they are published (available in online proceedings) within the last four months. That means, since our full paper deadline is September 28, if a paper was published (i.e., at a peer-reviewed venue) on or after May 28, 2022, authors are not required to compare their own work to that paper. Authors are encouraged to cite and discuss all relevant papers, but they may be excused for not knowing about papers not published in peer-reviewed conference proceedings or journals, which includes papers exclusively available on arXiv. Reviewers are encouraged to use their own good judgement and, if in doubt, discuss with their area chair.\u00a0\\n\u00a0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuccessful Page Load\\n\\n\\n\\n\\n\\n\\n\\n                        ICLR uses cookies for essential functions only. We do not sell your personal\\n                        information.\\n                        Our Privacy Policy \u00bb\u00a0\\n\\n\\nAccept\\n                            Cookies\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                            The ICLR Logo above may be used on presentations. Right-click and choose\\n                            download. It is a vector graphic and may be used at any scale.\\n                        \\n\\n\\n\\n\\n\\n                            Useful links\\n                        \\n\\n\\nSponsor / Exhibitor Information\\nPress\\n\\n\\n\\n\\n\\n\\n\\nContact\\n\\n 2710 E Corridor Dr, Appleton WI 54913\\n                            \\n\\n Email\\n\\n Phone: +1-920-268-4789\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nICLR Proceedings at OpenReview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"\n}\n```\n", "metadata": {"title": "Invoking `GetWebsite` with \n```json\n{\n  \"url\": \"https://iclr.cc/Conferences/2023/ReviewerGuide\",\n  \"output_type\": \"full_text\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='GetWebsite', response={'result': {'status': 'success', 'message': 'Search completed successfully', 'output': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nICLR 2022 Reviewer Instructions\\n\\n\\n\\n\\n\\nSkip to yearly menu bar\\nSkip to main content\\n\\nMain Navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            ICLR\\n        \\n\\n\\n\\n\\n                        Help/FAQ\\n                    \\n\\n\\n\\n\\n\\n\\n                        Contact ICLR\\n                    \\n\\n\\n\\n\\n\\n\\n                        Downloads\\n                    \\n\\n\\n\\n\\n\\n\\n                        ICLR Blog\\n                    \\n\\n\\n\\n\\n\\n\\n                        Code of Conduct\\n                    \\n\\n\\n\\n\\n\\n\\n                        Privacy Policy\\n                    \\n\\n\\n\\n\\n\\n\\n                        Create Profile\\n                    \\n\\n\\n\\n\\n\\n\\n                        Reset Password\\n                    \\n\\n\\n\\n\\n\\n\\n                        Journal To Conference Track\\n                    \\n\\n\\n\\n\\n\\n\\n                        Diversity & Inclusion\\n                    \\n\\n\\n\\n\\n\\n\\n                        Proceedings at OpenReview\\n                    \\n\\n\\n\\n\\n\\n\\n                        Future Meetings\\n                    \\n\\n\\n\\n\\n\\n\\n                        Press\\n                    \\n\\n\\n\\n\\n\\n\\n                        Exhibitor Information\\n                    \\n\\n\\n\\n\\n\\n\\n                        ICLR Twitter\\n                    \\n\\n\\n\\n\\n\\n\\n                        About ICLR\\n                    \\n\\n\\n\\n\\n\\n\\n\\n                        My Stuff\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Login\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Select Year: (2023)\\n        \\n\\n\\n2026\\n                \\n\\n\\n\\n2025\\n                \\n\\n\\n\\n2024\\n                \\n\\n\\n\\n2023\\n                \\n\\n\\n\\n2022\\n                \\n\\n\\n\\n2021\\n                \\n\\n\\n\\n2020\\n                \\n\\n\\n\\n2019\\n                \\n\\n\\n\\n2018\\n                \\n\\n\\n\\n2017\\n                \\n\\n\\n\\n2016\\n                \\n\\n\\n\\n2015\\n                \\n\\n\\n\\n2014\\n                \\n\\n\\n\\n2013\\n                \\n\\n\\n\\n\\n\\n\\n                        Dates\\n                    \\n\\n\\n\\n\\n            Calls\\n        \\n\\n\\n\\n\\n                        Call for Papers\\n                    \\n\\n\\n\\n\\n\\n\\n                        Call for Tiny Papers\\n                    \\n\\n\\n\\n\\n\\n\\n                        Call for Workshops\\n                    \\n\\n\\n\\n\\n\\n\\n                        Call for Blog Posts\\n                    \\n\\n\\n\\n\\n\\n\\n                        Call for Socials\\n                    \\n\\n\\n\\n\\n\\n\\n            Guides\\n        \\n\\n\\n\\n\\n                        Author Guide\\n                    \\n\\n\\n\\n\\n\\n\\n                        Reviewer Guide\\n                    \\n\\n\\n\\n\\n\\n\\n                        Area Chair Guide\\n                    \\n\\n\\n\\n\\n\\n\\n            Attend\\n        \\n\\n\\n\\n\\n                        Register\\n                    \\n\\n\\n\\n\\n\\n\\n                        Visa and Travel  Information\\n                    \\n\\n\\n\\n\\n\\n\\n                        Hotels\\n                    \\n\\n\\n\\n\\n\\n\\n                        Child Care\\n                    \\n\\n\\n\\n\\n\\n\\n                        Visiting Kigali\\n                    \\n\\n\\n\\n\\n\\n\\n                        Code of Conduct\\n                    \\n\\n\\n\\n\\n\\n\\n            Organization\\n        \\n\\n\\n\\n\\n                        ICLR Board\\n                    \\n\\n\\n\\n\\n\\n\\n                        Organizing Committee\\n                    \\n\\n\\n\\n\\n\\n\\n                        Program Committee\\n                    \\n\\n\\n\\n\\n\\n\\n                        Reviewers\\n                    \\n\\n\\n\\n\\n\\n\\n                        Ethics Committee\\n                    \\n\\n\\n\\n\\n\\n\\n                        About ICLR\\n                    \\n\\n\\n\\n\\n\\n\\n\\n                        Conference Site\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\nICLR 2023 Reviewer Guide\\nThank you for agreeing to serve as an ICLR 2023 reviewer. Your contribution as a reviewer is paramount to creating an exciting and high-quality program. We ask that:\\n\\nYour reviews are timely and substantive.\\nYou follow the reviewing guidelines below.\\xa0\\nYou adhere to our Code of Ethics in your role as a reviewer. You must also adhere to our Code of Conduct.\\n\\nThis guide is intended to help you understand the ICLR 2023 decision process and your role within it. It contains:\\n\\nAn outline of the main reviewer tasks\\nStep-by-step reviewing instructions (especially relevant for reviewers that are new to ICLR)\\nReview examples\\nAn FAQ.\\n\\n\\xa0\\n\\n\\nWe\u2019re counting on you\\nAs a reviewer you are central to the program creation process for ICLR 2023. Your Area Chairs (ACs), Senior Area Chairs (SACs) and the Program Chairs (PCs) will rely greatly on your expertise and your diligent and thorough reviews to make decisions on each paper. Therefore, your role as a reviewer is critical to ensuring a strong program for ICLR 2023.\\nHigh-quality reviews are also very valuable for helping authors improve their work, whether it is eventually accepted by ICLR 2023, or not. Therefore it is important to treat each valid ICLR 2023 submission with equal care.\\nAs a token of our appreciation for your essential work, top reviewers will be acknowledged permanently on the ICLR 2023 website. Furthermore, top and high quality reviewers will receive special acknowledgement during the opening ceremony and free registration to ICLR 2023.\\n\\xa0\\n\\nMain reviewer tasks\\nThe main reviewer tasks and dates are as follows:\\n\\nCreate or update your OpenReview profile (September 30 2022)\\nBid on papers (September 30 2022 - October 06 2022)\\nWrite a constructive, thorough and timely review (October 12 2022 - October 24 2022)\\nInitial paper reviews released (November 4 2022)\\nDiscuss with authors and other reviewers to clarify and improve the paper (November 4 2022 - November 18 2022)\\nFlag any potential CoE violations and/or concerns (by November 18 2022)\\nProvide a recommendation to the area chair assigned to the paper (by November 18 2022)\\nVirtual Meeting with AC if paper you reviewed falls into borderline papers (November 18 2022 - December 12 2022)\\nProvide a final recommendation to the area chair assigned to the paper (after Virtual Meeting)\\n\\n\\xa0\\n\\n\\n\\xa0\\nCode of Ethics\\nAll ICLR participants, including reviewers, are required to adhere to the ICLR Code of Ethics (https://iclr.cc/public/CodeOfEthics). All reviewers are required to read the Code of Ethics and adhere to it. The Code of Ethics applies to all conference participation, including paper submission, reviewing, and paper discussion.\\xa0\\nAs part of the review process, reviewers are asked to raise potential violations of the ICLR Code of Ethics. Note that authors are encouraged to discuss questions and potential issues regarding the Code of Ethics as part of their submission. This discussion is not counted against the maximum page limit of the paper and should be included as a separate section.\\n\\xa0\\n\\n\\xa0\\nReviewing a submission: step-by-step\\nSummarized in one sentence, a review aims to determine whether a submission will bring sufficient value to the community and contribute new knowledge. The process can be broken down into the following main reviewer tasks:\\n\\xa0\\n\\n\\nRead the paper: It\u2019s important to carefully read through the entire paper, and to look up any related work and citations that will help you comprehensively evaluate it. Be sure to give yourself sufficient time for this step.\\nWhile reading, consider the following:\\n\\nObjective of the work: What is the goal of the paper? Is it to better address a known application or problem, draw attention to a new application or problem, or to introduce and/or explain a new theoretical finding? A combination of these? Different objectives will require different considerations as to potential value and impact.\\nStrong points: is the submission clear, technically correct, experimentally rigorous, reproducible, does it present novel findings (e.g. theoretically, algorithmically, etc.)?\\nWeak points: is it weak in any of the aspects listed in b.?\\nBe mindful of potential biases and try to be open-minded about the value and interest a paper can hold for the entire ICLR community, even if it may not be very interesting for you.\\n\\n\\nAnswer four key questions for yourself, to make a recommendation to Accept or Reject:\\n\\nWhat is the specific question and/or problem tackled by the paper?\\nIs the approach well motivated, including being well-placed in the literature?\\nDoes the paper support the claims? This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous.\\nWhat is the significance of the work? Does it contribute new knowledge and sufficient value to the community? Note, this does not necessarily require state-of-the-art results. Submissions bring value to the ICLR community when they convincingly demonstrate new, relevant, impactful knowledge (incl., empirical, theoretical, for practitioners, etc).\\n\\n\\nWrite and submit your initial review, organizing it as follows:\\xa0\\n\\nSummarize what the paper claims to contribute. Be positive and constructive.\\nList strong and weak points of the paper. Be as comprehensive as possible.\\nClearly state your initial recommendation (accept or reject) with one or two key reasons for this choice.\\nProvide supporting arguments for your recommendation.\\nAsk questions you would like answered by the authors to help you clarify your understanding of the paper and provide the additional evidence you need to be confident in your assessment.\\xa0\\nProvide additional feedback with the aim to improve the paper. Make it clear that these points are here to help, and not necessarily part of your decision assessment.\\n\\n\\nComplete the CoE report: ICLR has adopted the following Code of Ethics (CoE). When submitting your review, you\u2019ll be asked to complete a CoE report for the paper. The report is a simple form with two questions. The first asks whether there is a potential violation of the CoE. The second is relevant only if there is a potential violation and asks the reviewer to explain why there may be a potential violation. In order to answer these questions, it is therefore important that you read the CoE before starting your reviews. \\n\\t\\xa0\\nEngage in discussion: The discussion phase at ICLR is different from most conferences in the AI/ML community. During this phase, reviewers, authors and area chairs engage in asynchronous discussion and authors are allowed to revise their submissions to address concerns that arise. It is crucial that you are actively engaged during this phase. Maintain a spirit of openness to changing your initial recommendation (either to a more positive or more negative) rating.\\nBorderline paper meeting: This year, we are introducing a new program for ACs to (virtually) meet and discuss with reviewers only for borderline cases. ACs will reach out to schedule this meeting. This is to ensure active discussions among reviewers, and well-thought-out decisions. ACs will schedule the meeting and facilitate the discussion. For a productive discussion, it is important to familiarize yourself with other reviewers\\' feedback prior to the meeting. Please note that we will be leveraging information for reviewers who failed to attend this meeting (excluding emergencies).\\xa0\\nProvide final recommendation: Update your review, taking into account the new information collected during the discussion phase, and any revisions to the submission. State your reasoning and what did/didn\u2019t change your recommendation throughout the discussion phase.\\n\\n\\xa0\\n\\n\\xa0\\nFor great in-depth resources on reviewing, see these resources:\\n\\nDaniel Dennet, Criticising with Kindness.\\nComprehensive advice: Mistakes Reviewers Make\\nViews from multiple reviewers: Last minute reviewing advice\\nPerspective from instructions to Area Chairs: Dear ACs.\\n\\n\\xa0\\n\\n\\xa0\\nReview Examples\\nHere are two sample reviews from previous conferences that give an example of what we consider a good review for the case of leaning-to-accept and leaning-to-reject.\\nReview for a Paper where Leaning-to-Accept\\nThis paper proposes a method, Dual-AC, for optimizing the actor (policy) and critic (value function) simultaneously which takes the form of a zero-sum game resulting in a principled method for using the critic to optimize the actor. In order to achieve that, they take the linear programming approach of solving the Bellman optimality equations, outline the deficiencies of this approach, and propose solutions to mitigate those problems. The discussion on the deficiencies of the naive LP approach is mostly well done. Their main contribution is extending the single step LP formulation to a multi-step dual form that reduces the bias and makes the connection between policy and value function optimization much clearer without losing convexity by applying a regularization. They perform an empirical study in the Inverted Double Pendulum domain to conclude that their extended algorithm outperforms the naive linear programming approach without the improvements. Lastly, there are empirical experiments done to conclude the superior performance of Dual-AC in contrast to other actor-critic algorithms.\\xa0\\nOverall, this paper could be a significant algorithmic contribution, with the caveat for some clarifications on the theory and experiments. Given these clarifications in an author response, I would be willing to increase the score.\\xa0\\nFor the theory, there are a few steps that need clarification and further clarification on novelty. For novelty, it is unclear if Theorem 2 and Theorem 3 are both being stated as novel results. It looks like Theorem 2 has already been shown in \"Randomized Linear Programming Solves the Discounted Markov Decision Problem in Nearly-Linear Running Time\u201d. There is a statement that \u201cChen & Wang (2016); Wang (2017) apply stochastic first-order algorithms (Nemirovski et al., 2009) for the one-step Lagrangian of the LP problem in reinforcement learning setting. However, as we discussed in Section 3, their algorithm is restricted to tabular parametrization\u201d. Is your Theorem 2 somehow an extension? Is Theorem 3 completely new?\\nThis is particularly called into question due to the lack of assumptions about the function class for value functions. It seems like the value function is required to be able to represent the true value function, which can be almost as restrictive as requiring tabular parameterizations (which can represent the true value function). This assumption seems to be used right at the bottom of Page 17, where U^{pi*} = V^*. Further, eta_v must be chosen to ensure that it does not affect (constrain) the optimal solution, which implies it might need to be very small. More about conditions on eta_v would be illuminating.\\xa0\\nThere is also one step in the theorem that I cannot verify. On Page 18, how is the squared removed for difference between U and Upi? The transition from the second line of the proof to the third line is not clear. It would also be good to more clearly state on page 14 how you get the first inequality, for || V^* ||_{2,mu}^2.\\xa0\\n\\xa0\\n\\nFor the experiments, the following should be addressed.\\n1. It would have been better to also show the performance graphs with and without the improvements for multiple domains.\\n2. The central contribution is extending the single step LP to a multi-step formulation. It would be beneficial to empirically demonstrate how increasing k (the multi-step parameter) affects the performance gains.\\n3. Increasing k also comes at a computational cost. I would like to see some discussions on this and how long dual-AC takes to converge in comparison to the other algorithms tested (PPO and TRPO).\\n4. The authors concluded the presence of local convexity based on hessian inspection due to the use of path regularization. It was also mentioned that increasing the regularization parameter size increases the convergence rate. Empirically, how does changing the regularization parameter affect the performance in terms of reward maximization? In the experimental section of the appendix, it is mentioned that multiple regularization settings were tried but their performance is not mentioned. Also, for the regularization parameters that were tried, based on hessian inspection, did they all result in local convexity? A bit more discussion on these choices would be helpful.\\xa0\\n\\xa0\\n\\nMinor comments:\\n1. Page 2: In equation 5, there should not be a \\'ds\\' in the dual variable constraint\\n\\xa0\\n\\n\\xa0\\nReview for a Paper where Leaning-to-Reject\\nThis paper introduces a variation on temporal difference learning for the function approximation case that attempts to resolve the issue of over-generalization across temporally-successive states. The new approach is applied to both linear and non-linear function approximation, and for prediction and control problems. The algorithmic contribution is demonstrated with a suite of experiments in classic benchmark control domains (Mountain Car and Acrobot), and in Pong.\\nThis paper should be rejected because (1) the algorithm is not well justified either by theory or practice, (2) the paper never clearly demonstrates the existence of problem they are trying to solve (nor differentiates it from the usual problem of generalizing well), (3) the experiments are difficult to understand, missing many details, and generally do not support a significant contribution, and (4) the paper is imprecise and unpolished.\\nMain argument\\nThe paper does not do a great job of demonstrating that the problem it is trying to solve is a real thing. There is no experiment in this paper that clearly shows how this temporal generalization problem is different from the need to generalize well with function approximation. The paper points to references to establish the existence of the problem, but for example the Durugkar and Stone paper is a workshop paper and the conference version of that paper was rejected from ICLR 2018 and the reviewers highlighted serious issues with the paper\u2014that is not work to build upon. Further the paper under review here claims this problem is most pressing in the non-linear case, but the analysis in section 4.1 is for the linear case.\\xa0\\nThe resultant algorithm does not seem well justified, and has a different fixed point than TD, but there is no discussion of this other than section 4.4, which does not make clear statements about the correctness of the algorithm or what it converges to. Can you provide a proof or any kind of evidence that the proposed approach is sound, or how it\u2019s fixed point relates to TD?\\nThe experiments do not provide convincing evidence of the correctness of the proposed approach or its utility compared to existing approaches. There are so many missing details it is difficult to draw many conclusions:\\n\\nWhat was the policy used in exp1 for policy evaluation in MC?\\nWhy Fourier basis features?\\nIn MC with DQN how did you adjust the parameters and architecture for the MC task?\\nWas the reward in MC and Acrobot -1 per step or something else\\nHow did you tune the parameters in the MC and Acrobot experiments?\\nWhy so few runs in MC, none of the results presented are significant?\\nWhy is the performance so bad in MC?\\nDid you evaluate online learning or do tests with the greedy policy?\\nHow did you initialize the value functions and weights?\\nWhy did you use experience replay for the linear experiments?\\nIN MC and Acrobot why only a one layer MLP?\\n\\nIgnoring all that, the results are not convincing. Most of the results in the paper are not statistically significant. The policy evaluation results in MC show little difference to regular TD. The Pong results show DQN is actually better. This makes the reader wonder if the result with DQN on MC and Acrobot are only worse because you did not properly tune DQN for those domains, whereas the default DQN architecture is well tuned for Atari and that is why you method is competitive in the smaller domains.\\xa0\\nThe differences in the \u201caverage change in value plots\u201d are very small if the rewards are -1 per step. Can you provide some context to understand the significance of this difference? In the last experiment linear FA and MC, the step-size is set equal for all methods\u2014this is not a valid comparison. Your method may just work better with alpha = 0.1.\\xa0\\n\\xa0\\n\\nThe paper has many imprecise parts, here are a few:\\n\\nThe definition of the value function would be approximate not equals unless you specify some properties of the function approximation architecture. Same for the Bellman equation\\nequation 1 of section 2.1 is neither an algorithm or a loss function\\nTD does not minimize the squared TD. Saying that is the objective function of TD learning in not true\\nend of section 2.1 says \u201cIt is computed as\u201d but the following equation just gives a form for the partial derivative\\nequation 2, x is not bounded\\xa0\\nYou state TC-loss has an unclear solution property, I don\u2019t know what that means and I don\u2019t think your approach is well justified either\\nSection 4.1 assumes linear FA, but its implied up until paragraph 2 that it has not assumed linear\\ntreatment of n_t in alg differs from appendix (t is no time episode number)\\nYour method has a n_t parameter that is adapted according to a schedule seemingly giving it an unfair advantage over DQN.\\nOver-claim not supported by the results: \u201cwe see that HR-TD is able to find a representation that is better at keeping the target value separate than TC is \u201c. The results do not show this.\\nSection 4.4 does not seem to go anywhere or produce and tangible conclusions\\n\\n\\xa0\\n\\nThings to improve the paper that did not impact the score:\\n\\nIt\u2019s hard to follow how the prox operator is used in the development of the alg, this could use some higher level explanation\\nIntro p2 is about bootstrapping, use that term and remove the equations\\nIt\u2019s not clear why you are talking about stochastic vs deterministic in P3\\nPerhaps you should compare against a MC method in the experiments to demonstrate the problem with TD methods and generalization\\nSection 2: \u201ccan often be a regularization term\u201d >> can or must be?\\nupdate law is an odd term\\n\\xa0tends to alleviate\u201d >> odd phrase\\nsection 4 should come before section 3\\nAlg 1 in not helpful because it just references an equation\\nsection 4.4 is very confusing, I cannot follow the logic of the statements\\xa0\\nQ learning >> Q-learning\\nNot sure what you mean with the last sentence of p2 section 5\\nwhere are the results for Acrobot linear function approximation\\nappendix Q-learning with linear FA is not DQN (table 2)\\n\\n\\xa0\\n\\nFAQ for Reviewers\\nQ. The review I just submitted is not appearing! Did it go thru?\\nA. There seems to be some delay in the system for you to see your reviews. Just give a bit of time and refresh again.\\n\\xa0\\nQ. What is the borderline paper meeting between AC and reviewers about?\\nA. This year we require ACs to meet with reviewers for all borderline papers (defined and announced by PCs once all reviews are received). There will be one meeting per borderline paper. Once we receive all reviews, we will let ACs know which papers fall into this bucket. ACs will then schedule and run the meetings with the reviewers of the papers in question.\\n\\xa0\\n\\nQ: What if I can not attend the meeting?\\nA: Please work with your AC to find a meeting schedule that works for everyone. Note that the discussion phase is roughly 1 month long, and overlaps with the NeurIPS conference, in case in-person meeting is preferred. All reviewers agreed to participate in review meetings when they accepted the reviewer invitations. An AC has right to\\xa0 downweight the review of reviewers who refuse to attend the meeting.\\n\\xa0\\n\\nQ: How should I use supplementary material?\\nA: It is not necessary to read supplementary material but such material can often answer questions that arise while reading the main paper, so consider looking there before asking authors.\\n\\xa0\\n\\nQ: How should I handle a policy violation?\\nA: To flag a CoE violation related to a submission, please indicate it when submitting the CoE report for that paper. The AC will work with the PC and the ethics board to resolve the case. To discuss other violations (e.g. plagiarism, double submission, paper length, formatting, etc.), please contact either the AC/SAC or the PC as appropriate. You can do this by sending a confidential comment with the appropriate readership restrictions.\\n\\xa0\\n\\nQ: Am I allowed to ask for additional experiments?\\nA: You can ask for additional experiments. New experiments should not significantly change the content of the submission. Rather, they should be limited in scope and serve to more thoroughly validate existing results from the submission.\\n\\xa0\\n\\nQ: If a submission does not achieve state-of-the-art results, is that grounds for rejection?\\nA: No, a lack of state-of-the-art results does not by itself constitute grounds for rejection. Submissions bring value to the ICLR community when they convincingly demonstrate new, relevant, impactful knowledge. Submissions can achieve this without achieving state-of-the-art results.\\nQ: Are authors expected to cite and compare with very recent work? What about non peer-reviewed (e.g., ArXiv) papers? (updated on 7 November 2022)\\nA: We consider papers contemporaneous if they are published (available in online proceedings) within the last four months. That means, since our full paper deadline is September 28, if a paper was published (i.e., at a peer-reviewed venue) on or after May 28, 2022, authors are not required to compare their own work to that paper. Authors are encouraged to cite and discuss all relevant papers, but they may be excused for not knowing about papers not published in peer-reviewed conference proceedings or journals, which includes papers exclusively available on arXiv. Reviewers are encouraged to use their own good judgement and, if in doubt, discuss with their area chair.\\xa0\\n\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuccessful Page Load\\n\\n\\n\\n\\n\\n\\n\\n                        ICLR uses cookies for essential functions only. We do not sell your personal\\n                        information.\\n                        Our Privacy Policy \u00bb\\xa0\\n\\n\\nAccept\\n                            Cookies\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                            The ICLR Logo above may be used on presentations. Right-click and choose\\n                            download. It is a vector graphic and may be used at any scale.\\n                        \\n\\n\\n\\n\\n\\n                            Useful links\\n                        \\n\\n\\nSponsor / Exhibitor Information\\nPress\\n\\n\\n\\n\\n\\n\\n\\nContact\\n\\n 2710 E Corridor Dr, Appleton WI 54913\\n                            \\n\\n Email\\n\\n Phone: +1-920-268-4789\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nICLR Proceedings at OpenReview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "Based on the ICLR 2023 Reviewer Guide and the paper content, I will create three reviewer agents with the following specializations:\n\n1.  **Methodology Rigor Expert (MRE):** Focuses on the soundness and novelty of the proposed MCTS-based approach, the appropriateness of the reward function, and the validity of the experimental setup. This agent will assess the technical contributions and identify potential weaknesses in the methodology.\n2.  **Nonlinear Dynamics Specialist (NDS):** Evaluates the paper's contribution to the field of nonlinear dynamics discovery. This agent will assess the significance of the problems addressed, the relevance of the benchmark datasets, and the practical applicability of the proposed method.\n3.  **Symbolic Regression Benchmarking Analyst (SBA):** Critically examines the experimental results, focusing on the comparison with existing symbolic regression techniques (SINDy, GP, NGGP, Eureqa). This agent will assess the validity of the claims regarding improved performance and robustness.\n\nNow, I will create these agents.\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={}, name='AgentCostManager'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Cost of creating and invoking an agent\",\n  \"output\": {\n    \"gemini-2.5-flash-preview-05-20\": {\n      \"description\": \"Avg Accuracy: 75.8%, 82.8% on LegalBench, 81.6% on multi-task understanding, 91.6% on Math\",\n      \"create_expense_cost\": 0,\n      \"invoke_expense_cost\": 0.15,\n      \"output_expense_cost\": 0.6\n    }\n  }\n}\n```\n", "metadata": {"title": "Invoking `AgentCostManager` with \n```json\n{}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AgentCostManager', response={'result': {'status': 'success', 'message': 'Cost of creating and invoking an agent', 'output': {'gemini-2.5-flash-preview-05-20': {'description': 'Avg Accuracy: 75.8%, 82.8% on LegalBench, 81.6% on multi-task understanding, 91.6% on Math', 'create_expense_cost': 0, 'invoke_expense_cost': 0.15, 'output_expense_cost': 0.6}}}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'system_prompt': 'You are a meticulous researcher specializing in machine learning methodologies. You rigorously evaluate the technical soundness, novelty, and limitations of proposed methods. Pay close attention to the mathematical formulations, algorithmic implementation, and experimental design. Provide detailed critiques and suggestions for improvement.', 'agent_name': 'MethodologyRigorExpert', 'description': 'Expert in evaluating the methodological rigor of machine learning papers, focusing on the soundness and novelty of the approach.', 'base_model': 'gemini-2.5-flash-preview-05-20'}, name='AgentCreator'), function_response=None, inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'system_prompt': 'You are an expert in nonlinear dynamics and equation discovery. You evaluate the significance of research problems, the relevance of benchmark datasets, and the practical applicability of proposed methods. Assess the contribution of the work to the field and identify potential real-world applications.', 'agent_name': 'NonlinearDynamicsSpecialist', 'base_model': 'gemini-2.5-flash-preview-05-20', 'description': 'Specialist in nonlinear dynamics and equation discovery, assessing the significance of the problems addressed and the applicability of the proposed method.'}, name='AgentCreator'), function_response=None, inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'system_prompt': 'You are an experienced analyst specializing in symbolic regression benchmarking. You critically examine experimental results, focusing on comparisons with existing techniques. Assess the validity of claims regarding improved performance and robustness, and identify potential biases or limitations in the experimental setup.', 'description': 'Analyst specializing in symbolic regression benchmarking, critically examining experimental results and comparing them with existing techniques.', 'agent_name': 'SymbolicRegressionAnalyst', 'base_model': 'gemini-2.5-flash-preview-05-20'}, name='AgentCreator'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent successfully created\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.9933454\n}\n```\n", "metadata": {"title": "Invoking `AgentCreator` with \n```json\n{\n  \"system_prompt\": \"You are a meticulous researcher specializing in machine learning methodologies. You rigorously evaluate the technical soundness, novelty, and limitations of proposed methods. Pay close attention to the mathematical formulations, algorithmic implementation, and experimental design. Provide detailed critiques and suggestions for improvement.\",\n  \"agent_name\": \"MethodologyRigorExpert\",\n  \"description\": \"Expert in evaluating the methodological rigor of machine learning papers, focusing on the soundness and novelty of the approach.\",\n  \"base_model\": \"gemini-2.5-flash-preview-05-20\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent successfully created\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.9933454\n}\n```\n", "metadata": {"title": "Invoking `AgentCreator` with \n```json\n{\n  \"system_prompt\": \"You are an expert in nonlinear dynamics and equation discovery. You evaluate the significance of research problems, the relevance of benchmark datasets, and the practical applicability of proposed methods. Assess the contribution of the work to the field and identify potential real-world applications.\",\n  \"agent_name\": \"NonlinearDynamicsSpecialist\",\n  \"base_model\": \"gemini-2.5-flash-preview-05-20\",\n  \"description\": \"Specialist in nonlinear dynamics and equation discovery, assessing the significance of the problems addressed and the applicability of the proposed method.\"\n}\n```\n", "id": 1, "status": "done"}}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent successfully created\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.9933454\n}\n```\n", "metadata": {"title": "Invoking `AgentCreator` with \n```json\n{\n  \"system_prompt\": \"You are an experienced analyst specializing in symbolic regression benchmarking. You critically examine experimental results, focusing on comparisons with existing techniques. Assess the validity of claims regarding improved performance and robustness, and identify potential biases or limitations in the experimental setup.\",\n  \"description\": \"Analyst specializing in symbolic regression benchmarking, critically examining experimental results and comparing them with existing techniques.\",\n  \"agent_name\": \"SymbolicRegressionAnalyst\",\n  \"base_model\": \"gemini-2.5-flash-preview-05-20\"\n}\n```\n", "id": 2, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AgentCreator', response={'result': {'status': 'success', 'message': 'Agent successfully created', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.9933454}}), inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AgentCreator', response={'result': {'status': 'success', 'message': 'Agent successfully created', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.9933454}}), inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AgentCreator', response={'result': {'status': 'success', 'message': 'Agent successfully created', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.9933454}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "Now that the agents are created, I will instruct them to review the paper and provide their assessments.\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'prompt': \"Please provide a detailed review of the methodology used in the paper 'Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search'. Focus on the MCTS algorithm adjustments, the reward function design, and the training scheme. Assess the technical soundness and novelty of the approach, and identify any potential weaknesses or limitations.\", 'agent_name': 'MethodologyRigorExpert'}, name='AskAgent'), function_response=None, inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'prompt': \"Evaluate the contribution of the paper 'Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search' to the field of nonlinear dynamics discovery. Assess the significance of the problems addressed, the relevance of the benchmark datasets (Lorenz system, double pendulum), and the practical applicability of the proposed method. Identify potential real-world applications and limitations.\", 'agent_name': 'NonlinearDynamicsSpecialist'}, name='AskAgent'), function_response=None, inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'agent_name': 'SymbolicRegressionAnalyst', 'prompt': \"Critically examine the experimental results presented in the paper 'Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search'. Focus on the comparison with existing symbolic regression techniques (GP, NGGP, Eureqa, pySINDy). Assess the validity of the claims regarding improved performance and robustness on Nguyen's benchmark and the free-falling ball experiment. Identify potential biases or limitations in the experimental setup and suggest improvements.\"}, name='AskAgent'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent has replied to the given prompt\",\n  \"output\": \"The paper \\\"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search\\\" proposes an interesting and novel application of Monte Carlo Tree Search (MCTS) to the problem of symbolic regression for physical equation discovery. Here's a detailed review focusing on the requested aspects:\\n\\n## Overall Approach and Context\\n\\nThe paper frames the problem of discovering governing equations from data as a search problem over the space of mathematical expressions. Unlike traditional symbolic regression methods like Genetic Programming (GP) which rely on evolutionary algorithms, this work leverages MCTS, a tree-search algorithm often used in game AI, to intelligently explore the vast search space of symbolic expressions. The core idea is to build expressions incrementally, node by node, representing them as Abstract Syntax Trees (ASTs).\\n\\n## 1. MCTS Algorithm Adjustments for Symbolic Regression\\n\\nThe adaptation of MCTS for symbolic regression is arguably the most novel aspect of this paper.\\n\\n*   **State Representation:** Each node in the MCTS tree represents a *partial* or *complete* Abstract Syntax Tree (AST). The root node represents an empty expression. As the search progresses down the tree, new nodes (operators or terminals) are added, gradually completing the expression.\\n    *   **Critique:** This is a natural and sound representation for symbolic expression generation. It directly maps the search problem to AST construction.\\n*   **Actions:** Actions from a given node consist of adding a valid operator (e.g., `+`, `-`, `*`, `/`, `sin`, `exp`, `pow`) or a terminal (variables, constants) as a child.\\n    *   **Critique:** The set of available operators and terminals needs to be pre-defined. This imposes a strong inductive bias on the search, limiting discoverable equations to combinations of these primitives. The handling of variable arity operators (e.g., unary `sin` vs. binary `+`) and type consistency (e.g., ensuring `sin` operates on a dimensionless quantity, or that division by zero is avoided) would typically be managed through action masking or a robust type system, which are crucial for physical equations but often not explicitly detailed in general symbolic regression MCTS papers.\\n*   **Selection Phase (Tree Policy):** The standard UCB1 (Upper Confidence Bound 1) formula is typically used to balance exploration and exploitation: $UCB = \\\\frac{Q(s,a)}{N(s,a)} + C \\\\sqrt{\\\\frac{\\\\ln N(s)}{N(s,a)}}$, where $Q(s,a)$ is the total reward for taking action $a$ from state $s$, $N(s,a)$ is the number of times action $a$ has been taken from state $s$, $N(s)$ is the total visits to state $s$, and $C$ is an exploration constant.\\n    *   **Critique:** UCB1 is a standard and robust choice. The exploration constant $C$ is a critical hyperparameter that influences the trade-off between exploring novel expression structures and exploiting promising ones. Its optimal value is problem-dependent and can significantly impact performance.\\n*   **Expansion Phase:** When a promising node is selected that has unvisited children (i.e., unattempted actions from that partial expression), one unvisited child (representing a new operator or terminal) is added to the MCTS tree.\\n    *   **Critique:** Standard MCTS practice. The choice of *which* unvisited child to expand (if there are multiple) can be random or follow a predefined heuristic, though usually random for simplicity.\\n*   **Simulation Phase (Rollout/Default Policy):** From the newly expanded node (or any node during exploration), the MCTS performs a \\\"rollout\\\" by randomly (or semi-randomly) completing the partial expression until it forms a valid, complete equation. This completed equation is then evaluated.\\n    *   **Critique:** This is a critical component. The quality of the \\\"random\\\" rollout policy significantly impacts the efficiency of MCTS. A purely random policy can be very inefficient in large search spaces, often generating malformed or nonsensical equations. More sophisticated \\\"default policies\\\" (e.g., guided by heuristics like prioritizing terminals to complete expressions quickly, or favoring operators seen in simpler known physics equations) could drastically improve performance. The computational cost here is high, as each rollout requires fitting coefficients and evaluating the equation's fitness against the data.\\n*   **Backpropagation Phase:** The reward obtained from the simulation is propagated back up the tree, updating the visit counts and total rewards for all nodes along the path from the selected node to the root.\\n    *   **Critique:** Standard MCTS practice. This ensures that information learned from promising (or unpromising) rollouts influences future selections.\\n\\n**Technical Soundness:** The MCTS framework is technically sound for search problems, and its adaptation for AST generation is conceptually strong. The challenge lies in effectively managing the immense search space and the computational cost of evaluating expressions during rollouts.\\n\\n**Novelty:** The application of MCTS to symbolic regression, particularly with the explicit AST construction and evaluation within the MCTS loop, was a significant contribution at the time. While other search algorithms (like GP) were prevalent, MCTS offered a different paradigm for exploration-exploitation balance.\\n\\n## 2. Reward Function Design\\n\\nThe reward function is central to guiding the MCTS towards desired equations. It typically combines two key objectives: **accuracy/fit** to the data and **simplicity/parsimony** of the equation.\\n\\n*   **Common Form:** A common form for the reward function in symbolic regression is:\\n    `Reward = Fit_Score - \u03bb * Complexity_Score`\\n    where `\u03bb` (lambda) is a weighting hyperparameter.\\n\\n*   **Fit Score:**\\n    *   **Typical Metrics:** R-squared ($R^2$), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), or a custom fit metric. For maximization, RMSE/MAE would be negated, or $R^2$ (which ranges from $-\\\\infty$ to 1) is used directly.\\n    *   **Implementation:** The discovered equation, once fully formed, needs its coefficients determined (e.g., via linear least squares if the equation is linear in its coefficients, or non-linear optimization for other cases) before its fit can be evaluated against the training data. This coefficient fitting step is a critical part of the reward calculation.\\n    *   **Critique:** Using $R^2$ is standard and provides a normalized measure of fit. The assumption of linearity in coefficients for fitting (common in many symbolic regression works) can be a limitation, as many physical equations are non-linear in their parameters (e.g., $A \\\\sin(Bx + C)$). If non-linear least squares is used, it adds significant computational burden and can suffer from local optima.\\n*   **Complexity Score:**\\n    *   **Typical Metrics:** Number of nodes in the AST, depth of the AST, number of operators, number of variables, or a weighted sum of operator costs.\\n    *   **Critique:** Simple node count is a common and straightforward measure. It embodies Occam's Razor, penalizing overly complex expressions. The specific definition of complexity can influence the types of equations discovered.\\n*   **Hyperparameter `\u03bb`:**\\n    *   **Role:** `\u03bb` controls the trade-off between accuracy and simplicity. A high `\u03bb` encourages simpler equations, potentially sacrificing some fit, while a low `\u03bb` prioritizes fit, potentially leading to overfitting or overly complex equations.\\n    *   **Critique:** `\u03bb` is a crucial hyperparameter that needs careful tuning. Its optimal value is domain-specific and problem-specific. Finding a good `\u03bb` often requires cross-validation or manual experimentation, which can be time-consuming. Different physical domains might prioritize simplicity differently.\\n\\n**Technical Soundness:** The reward function design is conceptually sound, representing the standard trade-off between model complexity and data fit. The specific choices for fit and complexity metrics are also standard.\\n\\n**Novelty:** The fundamental idea of balancing fit and complexity is not novel; it's a cornerstone of statistical modeling and machine learning. However, its specific integration into the MCTS reward structure for symbolic regression is well-executed within the proposed framework.\\n\\n## 3. Training Scheme (Search Process)\\n\\nThe \\\"training scheme\\\" in this context refers to how the MCTS search is executed and how the final equations are identified.\\n\\n*   **Iterative Search:** The MCTS algorithm typically runs for a predefined number of iterations (e.g., 1000s or 10,000s). Each iteration involves one complete cycle of Selection, Expansion, Simulation, and Backpropagation.\\n*   **Data Usage:** The entire dataset is used for evaluating the fit of equations during the simulation phase.\\n*   **Candidate Equation Storage:** During the MCTS run, various complete equations are generated during the simulation (rollout) phase. Often, the MCTS maintains a record of the \\\"best\\\" equations found so far, based on their reward score.\\n*   **Final Output:** After all MCTS iterations are completed, the algorithm returns the equation(s) with the highest reward(s) found during the entire search. Sometimes, a \\\"Pareto front\\\" of equations (optimizing for both simplicity and accuracy) is presented to the user.\\n*   **No \\\"Training\\\" in the Neural Network Sense:** It's important to clarify that this isn't \\\"training\\\" a model with learnable weights that generalize over different datasets. It's a search process that finds a specific equation for a given dataset. Each new dataset would require a new MCTS search.\\n\\n**Technical Soundness:** The search process is a direct application of MCTS. The number of iterations is the main hyperparameter controlling the search budget.\\n\\n**Novelty:** The search process itself is standard for MCTS. The novelty lies in *what* is being searched for (symbolic equations) and *how* the MCTS is configured for this purpose.\\n\\n## Potential Weaknesses and Limitations\\n\\n1.  **Computational Cost:** This is arguably the biggest limitation.\\n    *   Each MCTS simulation requires constructing a complete expression and then fitting its coefficients to the data. For large datasets or complex equations, this can be computationally very expensive, especially if non-linear optimization is needed for coefficients.\\n    *   The search space grows exponentially with the number of variables, operators, and target complexity, making MCTS potentially slow for very complex physical systems.\\n2.  **Hyperparameter Sensitivity:**\\n    *   The `\u03bb` in the reward function is critical and needs careful tuning. A suboptimal `\u03bb` can lead to either overly complex or underfitting equations.\\n    *   The UCB exploration constant `C` also needs tuning.\\n    *   The number of MCTS iterations directly impacts the search quality and runtime. Optimal values are problem-dependent.\\n3.  **Pre-defined Operator Set:** The approach is limited to discovering equations composed solely of the predefined operators and variables. It cannot discover entirely new mathematical functions or relationships not present in its library.\\n4.  **Coefficient Fitting Limitations:** If only linear least squares is used for fitting coefficients, it restricts the forms of equations that can be discovered or accurately evaluated (e.g., $A \\\\sin(Bx + C)$ would require $B$ and $C$ to be found via non-linear means). If non-linear optimization is used, it introduces its own set of challenges (local minima, increased computation).\\n5.  **Robustness to Noise and Outliers:** The chosen fit metric (e.g., R-squared based on MSE) might be sensitive to noise and outliers in the data. Robust regression techniques are typically needed for real-world physical data.\\n6.  **Scalability to High Dimensionality:** As the number of input variables increases, the branching factor in the AST construction grows rapidly, making the search much harder.\\n7.  **Lack of Inductive Biases from Physics:** While the method discovers *mathematical* equations, it doesn't inherently encode deeper physical principles like unit consistency, dimensional analysis, conservation laws, or symmetries, which are crucial for physical plausibility. Incorporating these would require adding specific constraints or penalty terms.\\n8.  **Redundant Expressions:** MCTS might explore semantically equivalent but syntactically different expressions (e.g., `x+y` vs. `y+x`). Strategies to prune or identify these might be needed.\\n9.  **No \\\"Learning\\\" in the Traditional Sense:** The system performs a search for a specific equation, rather than learning general rules or representations that could transfer to new, unseen physics problems without re-running the entire search.\\n\\n## Suggestions for Improvement\\n\\n1.  **Guided Rollouts/Heuristic Default Policies:** Instead of purely random rollouts, employ heuristics based on successful partial expressions, operator statistics, or domain knowledge (e.g., favoring simple structures, ensuring dimensional consistency) to guide the simulation phase. This could significantly improve efficiency.\\n2.  **Adaptive Hyperparameter Tuning:** Explore methods for adaptively adjusting `\u03bb` and `C` during the search, perhaps based on the diversity of equations found or the search progress.\\n3.  **Hybrid Approaches:** Combine MCTS with other optimization techniques. For example, use MCTS to find promising symbolic structures, and then use Genetic Algorithms or gradient-based methods for fine-tuning coefficients or even small structural modifications.\\n4.  **Incorporating Domain Knowledge/Physics Priors:**\\n    *   **Dimensional Analysis:** Implement a type system that tracks units and enforces dimensional consistency during expression construction (action masking) and penalizes inconsistent expressions in the reward.\\n    *   **Conservation Laws/Symmetries:** Define specific patterns or properties that valid physical equations should exhibit and integrate them into the reward or search constraints.\\n5.  **Robustness to Noise:** Utilize robust loss functions (e.g., Huber loss, Tukey's biweight) for the fit score to make the discovery process less sensitive to outliers. Employ data sampling techniques (e.g., RANSAC-like) during simulations.\\n6.  **Parallelization:** MCTS is highly parallelizable, especially the simulation phase. Leveraging multi-core CPUs or GPUs could significantly reduce computation time.\\n7.  **Semantic Equivalence Pruning:** Implement a mechanism to detect and prune semantically equivalent expressions to reduce redundant search effort.\\n8.  **Curriculum Learning/Iterative Refinement:** Start with a simpler search space or less data, discover simpler equations, and then iteratively expand the search space or refine equations on more complex data.\\n9.  **Library Learning:** Instead of just pre-defined primitives, allow the system to store and reuse frequently discovered or highly useful sub-expressions as new \\\"primitives\\\" for future searches.\\n\\n## Conclusion\\n\\nThe Symbolic Physics Learner using MCTS represents a technically sound and novel approach to symbolic regression for equation discovery. Its strength lies in leveraging the exploration-exploitation balance of MCTS to navigate the complex space of mathematical expressions. However, its practical application is significantly challenged by computational cost, hyperparameter sensitivity, and the inherent limitations of relying solely on a predefined operator set. Future work should focus on integrating domain-specific knowledge, improving computational efficiency through smarter rollouts and parallelization, and enhancing robustness to noisy real-world data to make it a more powerful tool for scientific discovery.\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.99019385\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"prompt\": \"Please provide a detailed review of the methodology used in the paper 'Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search'. Focus on the MCTS algorithm adjustments, the reward function design, and the training scheme. Assess the technical soundness and novelty of the approach, and identify any potential weaknesses or limitations.\",\n  \"agent_name\": \"MethodologyRigorExpert\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent has replied to the given prompt\",\n  \"output\": \"The paper \\\"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search\\\" proposes an interesting and novel application of Monte Carlo Tree Search (MCTS) to the long-standing problem of discovering symbolic governing equations from time series data. As an expert in nonlinear dynamics and equation discovery, I assess its contribution as significant, though with the inherent limitations of the broader field.\\n\\nHere's a detailed evaluation:\\n\\n## Contribution to the Field of Nonlinear Dynamics Discovery\\n\\nThe core contribution of this work lies in applying **Monte Carlo Tree Search (MCTS)** as the primary search strategy for symbolic regression in the context of physics discovery. This is a novel approach compared to more traditional methods like genetic programming (GP), sparse regression (e.g., SINDy), or various optimization-based symbolic regression algorithms (e.g., Eureqa).\\n\\n1.  **Novel Search Strategy:** MCTS is well-known for its success in exploring vast, complex search spaces (e.g., game playing like Go). Its strength lies in balancing exploration and exploitation, which is crucial for symbolic regression where the \\\"correct\\\" functional form is unknown, and the search space of possible equations is combinatorially explosive. This systematic, tree-based exploration potentially offers a more robust and less susceptible-to-local-optima approach than purely greedy or random search methods.\\n2.  **Addressing Interpretability:** In an era increasingly dominated by black-box machine learning models, symbolic regression methods like this one are vital for providing *interpretable* and *mechanistic* insights into complex systems. Discovered equations offer not just predictions but also a deeper understanding of the underlying physics, which is the ultimate goal of scientific discovery.\\n3.  **Parsimony and Generalization:** Symbolic equations, when accurate and parsimonious, tend to generalize better outside the training data range than highly parameterized, non-interpretable models. MCTS, with a well-designed reward function, can inherently promote simpler solutions if parsimony is incentivized.\\n\\n## Significance of Problems Addressed\\n\\nThe problem of discovering governing equations from data is **highly significant** and is arguably one of the grand challenges in scientific machine learning and data-driven science.\\n\\n*   **Bridging Data and Theory:** It aims to bridge the gap between ever-increasing amounts of observational data and the development of fundamental theoretical models.\\n*   **Reverse Engineering Nature:** For complex systems where first-principles derivation is intractable or unknown (e.g., biological systems, climate dynamics), this approach offers a way to reverse-engineer their fundamental dynamics.\\n*   **Predictive Power and Control:** Once a governing equation is found, it enables high-fidelity prediction, system control, and targeted interventions.\\n*   **Understanding Chaos and Nonlinearity:** Nonlinear dynamics are inherently complex, exhibiting phenomena like chaos, bifurcations, and multi-stability. Discovering their underlying equations allows for a precise characterization and understanding of these complex behaviors.\\n\\n## Relevance of Benchmark Datasets\\n\\nThe chosen benchmark datasets\u2014the **Lorenz system** and the **double pendulum**\u2014are highly relevant and canonical choices for validating equation discovery methods in nonlinear dynamics.\\n\\n1.  **Lorenz System:**\\n    *   **Relevance:** It is the quintessential example of a low-dimensional chaotic system. Its quadratic nonlinearities make it a good test for methods capable of handling polynomial terms. It's a standard benchmark that allows for direct comparison with numerous other equation discovery algorithms (SINDy, GP, various deep learning approaches).\\n    *   **Significance:** Successfully discovering the Lorenz equations demonstrates the method's ability to identify chaotic dynamics from time series data, a fundamental challenge.\\n\\n2.  **Double Pendulum:**\\n    *   **Relevance:** This is another classic chaotic system, but crucially, it's a *mechanical system* where the governing equations are typically derived from Lagrangian or Hamiltonian mechanics. This tests the method's ability to discover equations that reflect underlying physical conservation laws (like energy), even if not explicitly encoded. It also involves trigonometric terms (sines and cosines of angles), which are often more challenging for symbolic regressors than simple polynomials.\\n    *   **Significance:** Success here shows applicability beyond abstract ODEs, hinting at the potential to discover the dynamics of real-world mechanical or physical systems.\\n\\n**Overall on Benchmarks:** While these are excellent and standard choices for initial validation, it's important to note they are **low-dimensional, deterministic (typically simulated without significant measurement noise), and have known, relatively simple analytical forms.** This simplifies the problem considerably compared to real-world datasets.\\n\\n## Practical Applicability of the Proposed Method\\n\\nThe practical applicability of the Symbolic Physics Learner, while promising, comes with inherent challenges common to most symbolic regression approaches:\\n\\n**Strengths for Practical Application:**\\n\\n*   **Interpretability:** The primary output is a symbolic equation, which is directly interpretable by scientists and engineers, fostering mechanistic understanding.\\n*   **Principled Search:** MCTS offers a structured way to explore the equation space, potentially leading to more robust discovery than purely heuristic methods. This could make it less prone to getting stuck in poor local minima.\\n*   **Flexibility:** The choice of basis functions (polynomials, trigonometric terms, exponentials, etc.) and the fitness function (e.g., RMSE, AIC/BIC for parsimony, physical constraints) can be adapted, allowing customization for specific domains.\\n*   **Potential for Integration:** The MCTS framework could potentially integrate prior knowledge or domain-specific constraints more naturally through modifications to its search or reward mechanisms.\\n\\n**Challenges and Limitations for Practical Application:**\\n\\n*   **Computational Cost & Scalability:** MCTS can be computationally expensive, especially as the number of variables, the complexity of the true equations, or the size of the function basis increases. Scaling to high-dimensional systems (e.g., dozens or hundreds of variables) or systems requiring PDE discovery would be extremely challenging.\\n*   **Basis Function Dependence:** Like all symbolic regression methods, the method can only discover equations whose terms are present in the provided library of basis functions. If the true underlying physics involves terms not included (e.g., a novel interaction, a specific non-analytic function), the method will fail to find it. This often necessitates some prior domain knowledge.\\n*   **Noise Sensitivity:** Real-world data is inherently noisy. While the paper might demonstrate robustness to some noise levels, high levels of noise or outliers can significantly degrade performance. The error metric in MCTS's reward function needs to be robust to noise.\\n*   **Hidden Variables & Implicit Equations:** The method, as described, is likely limited to discovering explicit ODEs. Discovering systems with hidden (unmeasured) variables or implicit relationships (e.g., algebraic constraints within an ODE system) remains a significant challenge.\\n*   **Overfitting vs. Parsimony:** Balancing model fit with parsimony (simplicity) is crucial. While MCTS can be guided, ensuring it doesn't find overly complex equations that fit noise is a continuous challenge.\\n\\n## Potential Real-World Applications\\n\\nGiven the strengths and limitations, Symbolic Physics Learner (and symbolic regression in general) has potential in various real-world applications where interpretable models are paramount:\\n\\n1.  **System Identification in Engineering:**\\n    *   **Aerodynamics:** Discovering equations for aerodynamic forces on complex shapes from wind tunnel data or CFD simulations.\\n    *   **Structural Dynamics:** Identifying governing equations for vibrations in structures, leading to better fault detection and predictive maintenance.\\n    *   **Robotics:** Learning the dynamics of robot manipulators from sensor data for improved control and path planning.\\n2.  **Biophysics and Computational Biology:**\\n    *   **Gene Regulatory Networks:** Unraveling the nonlinear interactions between genes from gene expression data.\\n    *   **Population Dynamics:** Discovering models for predator-prey interactions, disease spread (epidemiology), or cell growth in a culture.\\n    *   **Neuroscience:** Identifying simplified models of neuronal firing patterns or network dynamics from electrophysiological data.\\n3.  **Chemical Reaction Networks:** Inferring reaction rate equations and underlying mechanisms from concentration time series data.\\n4.  **Climate Science & Earth Systems:** Discovering empirical relationships between various climate variables (e.g., temperature, CO2, ocean currents) from observational data, to build more interpretable climate models.\\n5.  **Materials Science:** Identifying constitutive laws for novel materials from experimental stress-strain data.\\n\\n## Conclusion\\n\\nThe Symbolic Physics Learner represents a valuable addition to the toolkit for equation discovery in nonlinear dynamics. Its novel application of MCTS offers a principled and potentially more robust search strategy compared to existing methods. The problems addressed (discovering chaotic and mechanical system dynamics) are highly significant, and the chosen benchmarks are appropriate for initial validation.\\n\\nWhile promising, its practical applicability to truly complex, high-dimensional, noisy, and potentially multi-scale real-world systems remains subject to the inherent limitations of symbolic regression (computational cost, basis function dependence, noise sensitivity, hidden variables). Future work would likely focus on improving scalability, robustness to noise, and incorporating more sophisticated domain-specific constraints or multi-fidelity data integration within the MCTS framework. Nevertheless, it marks a positive step towards more intelligent and data-driven scientific discovery.\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.9893744\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"prompt\": \"Evaluate the contribution of the paper 'Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search' to the field of nonlinear dynamics discovery. Assess the significance of the problems addressed, the relevance of the benchmark datasets (Lorenz system, double pendulum), and the practical applicability of the proposed method. Identify potential real-world applications and limitations.\",\n  \"agent_name\": \"NonlinearDynamicsSpecialist\"\n}\n```\n", "id": 1, "status": "done"}}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent has replied to the given prompt\",\n  \"output\": \"The paper \\\"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search\\\" introduces a novel approach for symbolic regression, leveraging Monte Carlo Tree Search (MCTS). This is an interesting direction, as MCTS has proven effective in complex search spaces (e.g., game playing, planning). My assessment will critically examine the experimental claims and setup, focusing on the requested points.\\n\\n## Critical Examination of Experimental Results: Symbolic Physics Learner\\n\\n### I. General Assessment of the Approach\\n\\n**Strengths of SPL's Core Idea:**\\n*   **Novelty:** Applying MCTS to symbolic regression is a genuinely novel contribution. MCTS's strengths in balancing exploration and exploitation could be highly beneficial in the discrete, combinatorial search space of symbolic expressions, potentially overcoming local optima issues common in simpler greedy or evolutionary approaches.\\n*   **Structured Search:** Unlike purely stochastic methods (like vanilla GP mutation/crossover) or gradient-based methods, MCTS builds a decision tree of potential operations, allowing for a more informed and potentially guided search.\\n\\n**Potential Advantages Claimed/Inferred:**\\n*   Improved discovery rate (finding the exact underlying equation).\\n*   Better handling of complex relationships.\\n*   Robustness to noise.\\n\\n### II. Comparison with Existing Symbolic Regression Techniques\\n\\nThe paper compares SPL against Genetic Programming (GP), Next Generation Genetic Programming (NGGP), Eureqa, and pySINDy.\\n\\n**A. Baseline Selection Critique:**\\n\\n1.  **GP & NGGP:** These are reasonable baselines for traditional symbolic regression. GP is the archetypal method, and NGGP represents an advanced GP variant.\\n2.  **Eureqa:** This is a powerful, commercial, and often highly effective symbolic regression tool. However, it's closed-source, making direct comparison challenging. **Major Concern:** It's often unclear if Eureqa's reported performance (especially if from their own papers) is under identical computational budgets or search constraints as the new method. Replicating Eureqa's exact hyperparameter tuning and internal heuristics is impossible.\\n3.  **pySINDy:** This is a fantastic tool for discovering sparse differential equations, especially effective when the underlying dynamics are linear in a chosen basis set (i.e., identifying terms in the right-hand side of an ODE like `dx/dt = f(x)`). **Concern:**\\n    *   **Mismatch in Problem Scope:** pySINDy is inherently designed for systems of ODEs/PDEs where sparsity in a library of candidate functions is key. It's less directly comparable for \\\"pure\\\" symbolic regression problems like the Nguyen benchmark (which are explicit algebraic equations, not differential equations). For the free-falling ball, SINDy would likely find `dv/dt = g` or `d^2x/dt^2 = g`, whereas SPL aims for the explicit `x(t) = ...` form. This isn't an apples-to-apples comparison unless SINDy is adapted to find explicit forms (e.g., by fitting a polynomial, which isn't its primary strength).\\n    *   **Input Data:** SINDy typically benefits greatly from *derivative information* (either provided or numerically estimated). If SPL only gets `(x, y)` pairs while SINDy is given `(x, y, dy/dx)`, this creates an unfair advantage for SINDy. If SINDy has to *estimate* derivatives from noisy data, it can suffer significantly. The experimental setup needs to clarify this.\\n\\n**B. Experimental Setup and Validity of Claims:**\\n\\n**1. Hyperparameter Tuning and Computational Budget:**\\n*   **Potential Bias:** The most common criticism in novel algorithm papers is that the new method is exhaustively tuned, while baselines are run with default or sub-optimal parameters, or given significantly less computational budget (e.g., fewer generations for GP, shorter run times).\\n*   **Validation Check:** Does the paper explicitly state:\\n    *   How many runs were performed for each experiment (to account for stochasticity)?\\n    *   The total wall-clock time or CPU time allowed for each method per run?\\n    *   The specific hyperparameters used for GP, NGGP, and pySINDy? Were these optimized for *each* problem, or fixed?\\n    *   How Eureqa's results were obtained (re-run by authors vs. quoted from literature)?\\n*   **Claim Validity:** Claims of \\\"improved performance\\\" are only valid if all methods operated under a truly equitable computational and tuning regime. If SPL's MCTS search inherently requires more computation to find solutions, this should be transparently reported alongside performance gains.\\n\\n**2. Nguyen's Benchmark:**\\n*   **Claims:** SPL likely claims higher success rates (discovery of exact formula) and/or lower RMSE with reasonable complexity.\\n*   **Validity Check:**\\n    *   **Function Set:** Are all methods given the same set of primitive functions (e.g., `+, -, *, /, sin, cos, exp, log, constants`)? If SPL has a more constrained or more appropriate set for Nguyen's equations, that's an advantage that needs acknowledging.\\n    *   **Data Generation:** Consistent number of data points, range of input values, and noise levels across all methods?\\n    *   **Complexity Control/Parsimony:** Does SPL explicitly control equation complexity (e.g., by penalizing longer expressions)? How does this compare to GP's parsimony pressure or Eureqa's multi-objective optimization? A method might find the \\\"true\\\" solution but then struggle to simplify it, or find a simpler, highly accurate approximation.\\n*   **Robustness on Nguyen:** Claims of robustness usually relate to performance under varying noise levels or limited data.\\n    *   **Validation Check:** Were multiple noise levels tested? How gracefully do the baselines degrade compared to SPL? Is the noise model realistic?\\n\\n**3. Free-Falling Ball Experiment:**\\n*   **Equation:** `d = 0.5 * g * t^2 + v0 * t + d0` (or `d(t) = at^2 + bt + c`). This is a relatively simple quadratic equation.\\n*   **Claims:** SPL will likely claim it discovers the correct form and coefficients accurately.\\n*   **Validity Check:**\\n    *   **Simplicity of Problem:** This is a very common benchmark. If SPL struggles, it's a major concern. If it performs well, it's expected. The key is how it compares to baselines.\\n    *   **Comparison to pySINDy:** This is critical here. As discussed, if pySINDy is given derivative information, it has a significant advantage. If it has to numerically differentiate noisy position data, it might perform poorly, which wouldn't be a fair reflection of its capabilities. If SPL finds the explicit form `d(t) = ...` while SINDy finds `d^2d/dt^2 = g`, both are \\\"correct\\\" but represent different levels of information and problem formulation.\\n    *   **Generalizability:** While good for demonstrating basic capabilities, success on this problem alone doesn't prove robustness for complex physical systems (e.g., multi-body, non-linear, higher-order derivatives, partial differential equations).\\n\\n### III. Identified Biases and Limitations in Experimental Setup\\n\\n1.  **Hyperparameter Imbalance:** The most persistent bias in SR benchmarking. Without explicit, detailed reporting of hyperparameter search spaces and methods for all competitors, it's hard to rule out that SPL simply benefited from more extensive tuning.\\n2.  **Computational Budget Disparity:** A lack of clear, consistent time limits or evaluation counts across all methods can lead to misleading results. If SPL runs for hours while GP is cut off after minutes (or fixed generations), the comparison is invalid.\\n3.  **Black-Box Baselines (Eureqa):** Relying on Eureqa's reported performance from external sources (or internal defaults) makes true reproducibility and fair comparison impossible.\\n4.  **Inappropriate Baseline for Problem Type (pySINDy for Nguyen):** While pySINDy is cutting-edge for ODE discovery, its application to purely algebraic symbolic regression problems can be ill-suited, potentially making it appear weaker than it is in its intended domain. Its performance depends heavily on the input (raw data vs. data + derivatives).\\n5.  **Limited Problem Set:** Nguyen's benchmark is standard but purely mathematical. The free-falling ball is a simple physical system. The claims of \\\"Physics Learner\\\" would be stronger with more diverse and complex physics problems (e.g., pendulum, chaotic systems, multi-variable expressions, implicit relationships).\\n6.  **Lack of Ablation Studies:** A good paper often includes ablation studies to show the specific contributions of different components of the proposed method (e.g., how different MCTS selection strategies, simulation policies, or value functions impact performance). This helps validate *why* MCTS is effective.\\n7.  **Overemphasis on \\\"Exact Discovery\\\":** While desirable, for many real-world problems, finding a highly accurate and parsimonious approximation is often sufficient or even preferred over a slightly inaccurate \\\"exact\\\" form. The trade-off between accuracy and complexity (parsimony) should be clearly shown.\\n\\n### IV. Suggestions for Improvement\\n\\n1.  **Standardized Benchmarking Framework:** Utilize established symbolic regression benchmark suites (e.g., SRBench or common problems from other papers) where data, noise models, and metrics are consistent. This improves comparability and reproducibility.\\n2.  **Rigorously Equalized Computational Resources:** Explicitly state and enforce the computational budget for *all* methods (e.g., fixed wall-clock time, fixed number of function evaluations, or fixed number of generations for EAs). If methods have different inherent costs, this needs to be part of the performance analysis (e.g., \\\"SPL finds solution X in Y hours, while GP finds Z in W minutes\\\").\\n3.  **Transparent Hyperparameter Tuning:** Detail the hyperparameter search process for *all* algorithms, ensuring that baselines receive comparable tuning effort to SPL. Ideally, release the configuration files.\\n4.  **Diverse and Domain-Appropriate Baselines:**\\n    *   Include other state-of-the-art open-source GP implementations (e.g., from `gplearn` or `DEAP`).\\n    *   Consider other non-GP symbolic regression methods (e.g., neural symbolic regressors if applicable, or more advanced search heuristics).\\n    *   For physics problems, if comparing to SINDy, explicitly state if derivatives were provided or estimated, and justify the comparison. Consider comparing to methods that explicitly incorporate physical priors or conservation laws.\\n5.  **Ablation Studies:** Systematically analyze the impact of different MCTS components on SPL's performance (e.g., node selection strategy, simulation rollout depth, reward function, constant handling). This strengthens the methodological contribution.\\n6.  **Scalability Analysis:** Investigate SPL's performance on problems with higher dimensionality, more complex underlying expressions, or larger datasets. Analyze the scaling of computational time with problem size.\\n7.  **Code Availability:** Make the source code for SPL (and the experimental setup for baselines) publicly available. This is crucial for reproducibility, verification of claims, and fostering future research.\\n8.  **Broader Physics Benchmarks:** To truly validate the \\\"Physics Learner\\\" claim, include more challenging physics problems, potentially involving:\\n    *   Systems of coupled equations.\\n    *   Differential equations that are not easily integrated into explicit forms.\\n    *   Problems with latent variables or hidden states.\\n    *   Real-world experimental data with higher noise and uncertainty.\\n9.  **Detailed Error and Complexity Analysis:** Beyond just RMSE or exact discovery, provide insights into the *types* of equations discovered. Are they parsimonious? Do they have good extrapolation capabilities? What kinds of errors are made when the exact solution isn't found? (e.g., off by a constant, missing a term, wrong exponent).\\n\\nBy addressing these points, the paper can significantly strengthen the validity of its claims regarding SPL's improved performance and robustness, providing a more rigorous and convincing evaluation of its capabilities.\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.9883556\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"agent_name\": \"SymbolicRegressionAnalyst\",\n  \"prompt\": \"Critically examine the experimental results presented in the paper 'Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search'. Focus on the comparison with existing symbolic regression techniques (GP, NGGP, Eureqa, pySINDy). Assess the validity of the claims regarding improved performance and robustness on Nguyen's benchmark and the free-falling ball experiment. Identify potential biases or limitations in the experimental setup and suggest improvements.\"\n}\n```\n", "id": 2, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'success', 'message': 'Agent has replied to the given prompt', 'output': 'The paper \"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search\" proposes an interesting and novel application of Monte Carlo Tree Search (MCTS) to the problem of symbolic regression for physical equation discovery. Here\\'s a detailed review focusing on the requested aspects:\\n\\n## Overall Approach and Context\\n\\nThe paper frames the problem of discovering governing equations from data as a search problem over the space of mathematical expressions. Unlike traditional symbolic regression methods like Genetic Programming (GP) which rely on evolutionary algorithms, this work leverages MCTS, a tree-search algorithm often used in game AI, to intelligently explore the vast search space of symbolic expressions. The core idea is to build expressions incrementally, node by node, representing them as Abstract Syntax Trees (ASTs).\\n\\n## 1. MCTS Algorithm Adjustments for Symbolic Regression\\n\\nThe adaptation of MCTS for symbolic regression is arguably the most novel aspect of this paper.\\n\\n*   **State Representation:** Each node in the MCTS tree represents a *partial* or *complete* Abstract Syntax Tree (AST). The root node represents an empty expression. As the search progresses down the tree, new nodes (operators or terminals) are added, gradually completing the expression.\\n    *   **Critique:** This is a natural and sound representation for symbolic expression generation. It directly maps the search problem to AST construction.\\n*   **Actions:** Actions from a given node consist of adding a valid operator (e.g., `+`, `-`, `*`, `/`, `sin`, `exp`, `pow`) or a terminal (variables, constants) as a child.\\n    *   **Critique:** The set of available operators and terminals needs to be pre-defined. This imposes a strong inductive bias on the search, limiting discoverable equations to combinations of these primitives. The handling of variable arity operators (e.g., unary `sin` vs. binary `+`) and type consistency (e.g., ensuring `sin` operates on a dimensionless quantity, or that division by zero is avoided) would typically be managed through action masking or a robust type system, which are crucial for physical equations but often not explicitly detailed in general symbolic regression MCTS papers.\\n*   **Selection Phase (Tree Policy):** The standard UCB1 (Upper Confidence Bound 1) formula is typically used to balance exploration and exploitation: $UCB = \\\\frac{Q(s,a)}{N(s,a)} + C \\\\sqrt{\\\\frac{\\\\ln N(s)}{N(s,a)}}$, where $Q(s,a)$ is the total reward for taking action $a$ from state $s$, $N(s,a)$ is the number of times action $a$ has been taken from state $s$, $N(s)$ is the total visits to state $s$, and $C$ is an exploration constant.\\n    *   **Critique:** UCB1 is a standard and robust choice. The exploration constant $C$ is a critical hyperparameter that influences the trade-off between exploring novel expression structures and exploiting promising ones. Its optimal value is problem-dependent and can significantly impact performance.\\n*   **Expansion Phase:** When a promising node is selected that has unvisited children (i.e., unattempted actions from that partial expression), one unvisited child (representing a new operator or terminal) is added to the MCTS tree.\\n    *   **Critique:** Standard MCTS practice. The choice of *which* unvisited child to expand (if there are multiple) can be random or follow a predefined heuristic, though usually random for simplicity.\\n*   **Simulation Phase (Rollout/Default Policy):** From the newly expanded node (or any node during exploration), the MCTS performs a \"rollout\" by randomly (or semi-randomly) completing the partial expression until it forms a valid, complete equation. This completed equation is then evaluated.\\n    *   **Critique:** This is a critical component. The quality of the \"random\" rollout policy significantly impacts the efficiency of MCTS. A purely random policy can be very inefficient in large search spaces, often generating malformed or nonsensical equations. More sophisticated \"default policies\" (e.g., guided by heuristics like prioritizing terminals to complete expressions quickly, or favoring operators seen in simpler known physics equations) could drastically improve performance. The computational cost here is high, as each rollout requires fitting coefficients and evaluating the equation\\'s fitness against the data.\\n*   **Backpropagation Phase:** The reward obtained from the simulation is propagated back up the tree, updating the visit counts and total rewards for all nodes along the path from the selected node to the root.\\n    *   **Critique:** Standard MCTS practice. This ensures that information learned from promising (or unpromising) rollouts influences future selections.\\n\\n**Technical Soundness:** The MCTS framework is technically sound for search problems, and its adaptation for AST generation is conceptually strong. The challenge lies in effectively managing the immense search space and the computational cost of evaluating expressions during rollouts.\\n\\n**Novelty:** The application of MCTS to symbolic regression, particularly with the explicit AST construction and evaluation within the MCTS loop, was a significant contribution at the time. While other search algorithms (like GP) were prevalent, MCTS offered a different paradigm for exploration-exploitation balance.\\n\\n## 2. Reward Function Design\\n\\nThe reward function is central to guiding the MCTS towards desired equations. It typically combines two key objectives: **accuracy/fit** to the data and **simplicity/parsimony** of the equation.\\n\\n*   **Common Form:** A common form for the reward function in symbolic regression is:\\n    `Reward = Fit_Score - \u03bb * Complexity_Score`\\n    where `\u03bb` (lambda) is a weighting hyperparameter.\\n\\n*   **Fit Score:**\\n    *   **Typical Metrics:** R-squared ($R^2$), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), or a custom fit metric. For maximization, RMSE/MAE would be negated, or $R^2$ (which ranges from $-\\\\infty$ to 1) is used directly.\\n    *   **Implementation:** The discovered equation, once fully formed, needs its coefficients determined (e.g., via linear least squares if the equation is linear in its coefficients, or non-linear optimization for other cases) before its fit can be evaluated against the training data. This coefficient fitting step is a critical part of the reward calculation.\\n    *   **Critique:** Using $R^2$ is standard and provides a normalized measure of fit. The assumption of linearity in coefficients for fitting (common in many symbolic regression works) can be a limitation, as many physical equations are non-linear in their parameters (e.g., $A \\\\sin(Bx + C)$). If non-linear least squares is used, it adds significant computational burden and can suffer from local optima.\\n*   **Complexity Score:**\\n    *   **Typical Metrics:** Number of nodes in the AST, depth of the AST, number of operators, number of variables, or a weighted sum of operator costs.\\n    *   **Critique:** Simple node count is a common and straightforward measure. It embodies Occam\\'s Razor, penalizing overly complex expressions. The specific definition of complexity can influence the types of equations discovered.\\n*   **Hyperparameter `\u03bb`:**\\n    *   **Role:** `\u03bb` controls the trade-off between accuracy and simplicity. A high `\u03bb` encourages simpler equations, potentially sacrificing some fit, while a low `\u03bb` prioritizes fit, potentially leading to overfitting or overly complex equations.\\n    *   **Critique:** `\u03bb` is a crucial hyperparameter that needs careful tuning. Its optimal value is domain-specific and problem-specific. Finding a good `\u03bb` often requires cross-validation or manual experimentation, which can be time-consuming. Different physical domains might prioritize simplicity differently.\\n\\n**Technical Soundness:** The reward function design is conceptually sound, representing the standard trade-off between model complexity and data fit. The specific choices for fit and complexity metrics are also standard.\\n\\n**Novelty:** The fundamental idea of balancing fit and complexity is not novel; it\\'s a cornerstone of statistical modeling and machine learning. However, its specific integration into the MCTS reward structure for symbolic regression is well-executed within the proposed framework.\\n\\n## 3. Training Scheme (Search Process)\\n\\nThe \"training scheme\" in this context refers to how the MCTS search is executed and how the final equations are identified.\\n\\n*   **Iterative Search:** The MCTS algorithm typically runs for a predefined number of iterations (e.g., 1000s or 10,000s). Each iteration involves one complete cycle of Selection, Expansion, Simulation, and Backpropagation.\\n*   **Data Usage:** The entire dataset is used for evaluating the fit of equations during the simulation phase.\\n*   **Candidate Equation Storage:** During the MCTS run, various complete equations are generated during the simulation (rollout) phase. Often, the MCTS maintains a record of the \"best\" equations found so far, based on their reward score.\\n*   **Final Output:** After all MCTS iterations are completed, the algorithm returns the equation(s) with the highest reward(s) found during the entire search. Sometimes, a \"Pareto front\" of equations (optimizing for both simplicity and accuracy) is presented to the user.\\n*   **No \"Training\" in the Neural Network Sense:** It\\'s important to clarify that this isn\\'t \"training\" a model with learnable weights that generalize over different datasets. It\\'s a search process that finds a specific equation for a given dataset. Each new dataset would require a new MCTS search.\\n\\n**Technical Soundness:** The search process is a direct application of MCTS. The number of iterations is the main hyperparameter controlling the search budget.\\n\\n**Novelty:** The search process itself is standard for MCTS. The novelty lies in *what* is being searched for (symbolic equations) and *how* the MCTS is configured for this purpose.\\n\\n## Potential Weaknesses and Limitations\\n\\n1.  **Computational Cost:** This is arguably the biggest limitation.\\n    *   Each MCTS simulation requires constructing a complete expression and then fitting its coefficients to the data. For large datasets or complex equations, this can be computationally very expensive, especially if non-linear optimization is needed for coefficients.\\n    *   The search space grows exponentially with the number of variables, operators, and target complexity, making MCTS potentially slow for very complex physical systems.\\n2.  **Hyperparameter Sensitivity:**\\n    *   The `\u03bb` in the reward function is critical and needs careful tuning. A suboptimal `\u03bb` can lead to either overly complex or underfitting equations.\\n    *   The UCB exploration constant `C` also needs tuning.\\n    *   The number of MCTS iterations directly impacts the search quality and runtime. Optimal values are problem-dependent.\\n3.  **Pre-defined Operator Set:** The approach is limited to discovering equations composed solely of the predefined operators and variables. It cannot discover entirely new mathematical functions or relationships not present in its library.\\n4.  **Coefficient Fitting Limitations:** If only linear least squares is used for fitting coefficients, it restricts the forms of equations that can be discovered or accurately evaluated (e.g., $A \\\\sin(Bx + C)$ would require $B$ and $C$ to be found via non-linear means). If non-linear optimization is used, it introduces its own set of challenges (local minima, increased computation).\\n5.  **Robustness to Noise and Outliers:** The chosen fit metric (e.g., R-squared based on MSE) might be sensitive to noise and outliers in the data. Robust regression techniques are typically needed for real-world physical data.\\n6.  **Scalability to High Dimensionality:** As the number of input variables increases, the branching factor in the AST construction grows rapidly, making the search much harder.\\n7.  **Lack of Inductive Biases from Physics:** While the method discovers *mathematical* equations, it doesn\\'t inherently encode deeper physical principles like unit consistency, dimensional analysis, conservation laws, or symmetries, which are crucial for physical plausibility. Incorporating these would require adding specific constraints or penalty terms.\\n8.  **Redundant Expressions:** MCTS might explore semantically equivalent but syntactically different expressions (e.g., `x+y` vs. `y+x`). Strategies to prune or identify these might be needed.\\n9.  **No \"Learning\" in the Traditional Sense:** The system performs a search for a specific equation, rather than learning general rules or representations that could transfer to new, unseen physics problems without re-running the entire search.\\n\\n## Suggestions for Improvement\\n\\n1.  **Guided Rollouts/Heuristic Default Policies:** Instead of purely random rollouts, employ heuristics based on successful partial expressions, operator statistics, or domain knowledge (e.g., favoring simple structures, ensuring dimensional consistency) to guide the simulation phase. This could significantly improve efficiency.\\n2.  **Adaptive Hyperparameter Tuning:** Explore methods for adaptively adjusting `\u03bb` and `C` during the search, perhaps based on the diversity of equations found or the search progress.\\n3.  **Hybrid Approaches:** Combine MCTS with other optimization techniques. For example, use MCTS to find promising symbolic structures, and then use Genetic Algorithms or gradient-based methods for fine-tuning coefficients or even small structural modifications.\\n4.  **Incorporating Domain Knowledge/Physics Priors:**\\n    *   **Dimensional Analysis:** Implement a type system that tracks units and enforces dimensional consistency during expression construction (action masking) and penalizes inconsistent expressions in the reward.\\n    *   **Conservation Laws/Symmetries:** Define specific patterns or properties that valid physical equations should exhibit and integrate them into the reward or search constraints.\\n5.  **Robustness to Noise:** Utilize robust loss functions (e.g., Huber loss, Tukey\\'s biweight) for the fit score to make the discovery process less sensitive to outliers. Employ data sampling techniques (e.g., RANSAC-like) during simulations.\\n6.  **Parallelization:** MCTS is highly parallelizable, especially the simulation phase. Leveraging multi-core CPUs or GPUs could significantly reduce computation time.\\n7.  **Semantic Equivalence Pruning:** Implement a mechanism to detect and prune semantically equivalent expressions to reduce redundant search effort.\\n8.  **Curriculum Learning/Iterative Refinement:** Start with a simpler search space or less data, discover simpler equations, and then iteratively expand the search space or refine equations on more complex data.\\n9.  **Library Learning:** Instead of just pre-defined primitives, allow the system to store and reuse frequently discovered or highly useful sub-expressions as new \"primitives\" for future searches.\\n\\n## Conclusion\\n\\nThe Symbolic Physics Learner using MCTS represents a technically sound and novel approach to symbolic regression for equation discovery. Its strength lies in leveraging the exploration-exploitation balance of MCTS to navigate the complex space of mathematical expressions. However, its practical application is significantly challenged by computational cost, hyperparameter sensitivity, and the inherent limitations of relying solely on a predefined operator set. Future work should focus on integrating domain-specific knowledge, improving computational efficiency through smarter rollouts and parallelization, and enhancing robustness to noisy real-world data to make it a more powerful tool for scientific discovery.', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.99019385}}), inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'success', 'message': 'Agent has replied to the given prompt', 'output': 'The paper \"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search\" proposes an interesting and novel application of Monte Carlo Tree Search (MCTS) to the long-standing problem of discovering symbolic governing equations from time series data. As an expert in nonlinear dynamics and equation discovery, I assess its contribution as significant, though with the inherent limitations of the broader field.\\n\\nHere\\'s a detailed evaluation:\\n\\n## Contribution to the Field of Nonlinear Dynamics Discovery\\n\\nThe core contribution of this work lies in applying **Monte Carlo Tree Search (MCTS)** as the primary search strategy for symbolic regression in the context of physics discovery. This is a novel approach compared to more traditional methods like genetic programming (GP), sparse regression (e.g., SINDy), or various optimization-based symbolic regression algorithms (e.g., Eureqa).\\n\\n1.  **Novel Search Strategy:** MCTS is well-known for its success in exploring vast, complex search spaces (e.g., game playing like Go). Its strength lies in balancing exploration and exploitation, which is crucial for symbolic regression where the \"correct\" functional form is unknown, and the search space of possible equations is combinatorially explosive. This systematic, tree-based exploration potentially offers a more robust and less susceptible-to-local-optima approach than purely greedy or random search methods.\\n2.  **Addressing Interpretability:** In an era increasingly dominated by black-box machine learning models, symbolic regression methods like this one are vital for providing *interpretable* and *mechanistic* insights into complex systems. Discovered equations offer not just predictions but also a deeper understanding of the underlying physics, which is the ultimate goal of scientific discovery.\\n3.  **Parsimony and Generalization:** Symbolic equations, when accurate and parsimonious, tend to generalize better outside the training data range than highly parameterized, non-interpretable models. MCTS, with a well-designed reward function, can inherently promote simpler solutions if parsimony is incentivized.\\n\\n## Significance of Problems Addressed\\n\\nThe problem of discovering governing equations from data is **highly significant** and is arguably one of the grand challenges in scientific machine learning and data-driven science.\\n\\n*   **Bridging Data and Theory:** It aims to bridge the gap between ever-increasing amounts of observational data and the development of fundamental theoretical models.\\n*   **Reverse Engineering Nature:** For complex systems where first-principles derivation is intractable or unknown (e.g., biological systems, climate dynamics), this approach offers a way to reverse-engineer their fundamental dynamics.\\n*   **Predictive Power and Control:** Once a governing equation is found, it enables high-fidelity prediction, system control, and targeted interventions.\\n*   **Understanding Chaos and Nonlinearity:** Nonlinear dynamics are inherently complex, exhibiting phenomena like chaos, bifurcations, and multi-stability. Discovering their underlying equations allows for a precise characterization and understanding of these complex behaviors.\\n\\n## Relevance of Benchmark Datasets\\n\\nThe chosen benchmark datasets\u2014the **Lorenz system** and the **double pendulum**\u2014are highly relevant and canonical choices for validating equation discovery methods in nonlinear dynamics.\\n\\n1.  **Lorenz System:**\\n    *   **Relevance:** It is the quintessential example of a low-dimensional chaotic system. Its quadratic nonlinearities make it a good test for methods capable of handling polynomial terms. It\\'s a standard benchmark that allows for direct comparison with numerous other equation discovery algorithms (SINDy, GP, various deep learning approaches).\\n    *   **Significance:** Successfully discovering the Lorenz equations demonstrates the method\\'s ability to identify chaotic dynamics from time series data, a fundamental challenge.\\n\\n2.  **Double Pendulum:**\\n    *   **Relevance:** This is another classic chaotic system, but crucially, it\\'s a *mechanical system* where the governing equations are typically derived from Lagrangian or Hamiltonian mechanics. This tests the method\\'s ability to discover equations that reflect underlying physical conservation laws (like energy), even if not explicitly encoded. It also involves trigonometric terms (sines and cosines of angles), which are often more challenging for symbolic regressors than simple polynomials.\\n    *   **Significance:** Success here shows applicability beyond abstract ODEs, hinting at the potential to discover the dynamics of real-world mechanical or physical systems.\\n\\n**Overall on Benchmarks:** While these are excellent and standard choices for initial validation, it\\'s important to note they are **low-dimensional, deterministic (typically simulated without significant measurement noise), and have known, relatively simple analytical forms.** This simplifies the problem considerably compared to real-world datasets.\\n\\n## Practical Applicability of the Proposed Method\\n\\nThe practical applicability of the Symbolic Physics Learner, while promising, comes with inherent challenges common to most symbolic regression approaches:\\n\\n**Strengths for Practical Application:**\\n\\n*   **Interpretability:** The primary output is a symbolic equation, which is directly interpretable by scientists and engineers, fostering mechanistic understanding.\\n*   **Principled Search:** MCTS offers a structured way to explore the equation space, potentially leading to more robust discovery than purely heuristic methods. This could make it less prone to getting stuck in poor local minima.\\n*   **Flexibility:** The choice of basis functions (polynomials, trigonometric terms, exponentials, etc.) and the fitness function (e.g., RMSE, AIC/BIC for parsimony, physical constraints) can be adapted, allowing customization for specific domains.\\n*   **Potential for Integration:** The MCTS framework could potentially integrate prior knowledge or domain-specific constraints more naturally through modifications to its search or reward mechanisms.\\n\\n**Challenges and Limitations for Practical Application:**\\n\\n*   **Computational Cost & Scalability:** MCTS can be computationally expensive, especially as the number of variables, the complexity of the true equations, or the size of the function basis increases. Scaling to high-dimensional systems (e.g., dozens or hundreds of variables) or systems requiring PDE discovery would be extremely challenging.\\n*   **Basis Function Dependence:** Like all symbolic regression methods, the method can only discover equations whose terms are present in the provided library of basis functions. If the true underlying physics involves terms not included (e.g., a novel interaction, a specific non-analytic function), the method will fail to find it. This often necessitates some prior domain knowledge.\\n*   **Noise Sensitivity:** Real-world data is inherently noisy. While the paper might demonstrate robustness to some noise levels, high levels of noise or outliers can significantly degrade performance. The error metric in MCTS\\'s reward function needs to be robust to noise.\\n*   **Hidden Variables & Implicit Equations:** The method, as described, is likely limited to discovering explicit ODEs. Discovering systems with hidden (unmeasured) variables or implicit relationships (e.g., algebraic constraints within an ODE system) remains a significant challenge.\\n*   **Overfitting vs. Parsimony:** Balancing model fit with parsimony (simplicity) is crucial. While MCTS can be guided, ensuring it doesn\\'t find overly complex equations that fit noise is a continuous challenge.\\n\\n## Potential Real-World Applications\\n\\nGiven the strengths and limitations, Symbolic Physics Learner (and symbolic regression in general) has potential in various real-world applications where interpretable models are paramount:\\n\\n1.  **System Identification in Engineering:**\\n    *   **Aerodynamics:** Discovering equations for aerodynamic forces on complex shapes from wind tunnel data or CFD simulations.\\n    *   **Structural Dynamics:** Identifying governing equations for vibrations in structures, leading to better fault detection and predictive maintenance.\\n    *   **Robotics:** Learning the dynamics of robot manipulators from sensor data for improved control and path planning.\\n2.  **Biophysics and Computational Biology:**\\n    *   **Gene Regulatory Networks:** Unraveling the nonlinear interactions between genes from gene expression data.\\n    *   **Population Dynamics:** Discovering models for predator-prey interactions, disease spread (epidemiology), or cell growth in a culture.\\n    *   **Neuroscience:** Identifying simplified models of neuronal firing patterns or network dynamics from electrophysiological data.\\n3.  **Chemical Reaction Networks:** Inferring reaction rate equations and underlying mechanisms from concentration time series data.\\n4.  **Climate Science & Earth Systems:** Discovering empirical relationships between various climate variables (e.g., temperature, CO2, ocean currents) from observational data, to build more interpretable climate models.\\n5.  **Materials Science:** Identifying constitutive laws for novel materials from experimental stress-strain data.\\n\\n## Conclusion\\n\\nThe Symbolic Physics Learner represents a valuable addition to the toolkit for equation discovery in nonlinear dynamics. Its novel application of MCTS offers a principled and potentially more robust search strategy compared to existing methods. The problems addressed (discovering chaotic and mechanical system dynamics) are highly significant, and the chosen benchmarks are appropriate for initial validation.\\n\\nWhile promising, its practical applicability to truly complex, high-dimensional, noisy, and potentially multi-scale real-world systems remains subject to the inherent limitations of symbolic regression (computational cost, basis function dependence, noise sensitivity, hidden variables). Future work would likely focus on improving scalability, robustness to noise, and incorporating more sophisticated domain-specific constraints or multi-fidelity data integration within the MCTS framework. Nevertheless, it marks a positive step towards more intelligent and data-driven scientific discovery.', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.9893744}}), inline_data=None, text=None), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'success', 'message': 'Agent has replied to the given prompt', 'output': 'The paper \"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search\" introduces a novel approach for symbolic regression, leveraging Monte Carlo Tree Search (MCTS). This is an interesting direction, as MCTS has proven effective in complex search spaces (e.g., game playing, planning). My assessment will critically examine the experimental claims and setup, focusing on the requested points.\\n\\n## Critical Examination of Experimental Results: Symbolic Physics Learner\\n\\n### I. General Assessment of the Approach\\n\\n**Strengths of SPL\\'s Core Idea:**\\n*   **Novelty:** Applying MCTS to symbolic regression is a genuinely novel contribution. MCTS\\'s strengths in balancing exploration and exploitation could be highly beneficial in the discrete, combinatorial search space of symbolic expressions, potentially overcoming local optima issues common in simpler greedy or evolutionary approaches.\\n*   **Structured Search:** Unlike purely stochastic methods (like vanilla GP mutation/crossover) or gradient-based methods, MCTS builds a decision tree of potential operations, allowing for a more informed and potentially guided search.\\n\\n**Potential Advantages Claimed/Inferred:**\\n*   Improved discovery rate (finding the exact underlying equation).\\n*   Better handling of complex relationships.\\n*   Robustness to noise.\\n\\n### II. Comparison with Existing Symbolic Regression Techniques\\n\\nThe paper compares SPL against Genetic Programming (GP), Next Generation Genetic Programming (NGGP), Eureqa, and pySINDy.\\n\\n**A. Baseline Selection Critique:**\\n\\n1.  **GP & NGGP:** These are reasonable baselines for traditional symbolic regression. GP is the archetypal method, and NGGP represents an advanced GP variant.\\n2.  **Eureqa:** This is a powerful, commercial, and often highly effective symbolic regression tool. However, it\\'s closed-source, making direct comparison challenging. **Major Concern:** It\\'s often unclear if Eureqa\\'s reported performance (especially if from their own papers) is under identical computational budgets or search constraints as the new method. Replicating Eureqa\\'s exact hyperparameter tuning and internal heuristics is impossible.\\n3.  **pySINDy:** This is a fantastic tool for discovering sparse differential equations, especially effective when the underlying dynamics are linear in a chosen basis set (i.e., identifying terms in the right-hand side of an ODE like `dx/dt = f(x)`). **Concern:**\\n    *   **Mismatch in Problem Scope:** pySINDy is inherently designed for systems of ODEs/PDEs where sparsity in a library of candidate functions is key. It\\'s less directly comparable for \"pure\" symbolic regression problems like the Nguyen benchmark (which are explicit algebraic equations, not differential equations). For the free-falling ball, SINDy would likely find `dv/dt = g` or `d^2x/dt^2 = g`, whereas SPL aims for the explicit `x(t) = ...` form. This isn\\'t an apples-to-apples comparison unless SINDy is adapted to find explicit forms (e.g., by fitting a polynomial, which isn\\'t its primary strength).\\n    *   **Input Data:** SINDy typically benefits greatly from *derivative information* (either provided or numerically estimated). If SPL only gets `(x, y)` pairs while SINDy is given `(x, y, dy/dx)`, this creates an unfair advantage for SINDy. If SINDy has to *estimate* derivatives from noisy data, it can suffer significantly. The experimental setup needs to clarify this.\\n\\n**B. Experimental Setup and Validity of Claims:**\\n\\n**1. Hyperparameter Tuning and Computational Budget:**\\n*   **Potential Bias:** The most common criticism in novel algorithm papers is that the new method is exhaustively tuned, while baselines are run with default or sub-optimal parameters, or given significantly less computational budget (e.g., fewer generations for GP, shorter run times).\\n*   **Validation Check:** Does the paper explicitly state:\\n    *   How many runs were performed for each experiment (to account for stochasticity)?\\n    *   The total wall-clock time or CPU time allowed for each method per run?\\n    *   The specific hyperparameters used for GP, NGGP, and pySINDy? Were these optimized for *each* problem, or fixed?\\n    *   How Eureqa\\'s results were obtained (re-run by authors vs. quoted from literature)?\\n*   **Claim Validity:** Claims of \"improved performance\" are only valid if all methods operated under a truly equitable computational and tuning regime. If SPL\\'s MCTS search inherently requires more computation to find solutions, this should be transparently reported alongside performance gains.\\n\\n**2. Nguyen\\'s Benchmark:**\\n*   **Claims:** SPL likely claims higher success rates (discovery of exact formula) and/or lower RMSE with reasonable complexity.\\n*   **Validity Check:**\\n    *   **Function Set:** Are all methods given the same set of primitive functions (e.g., `+, -, *, /, sin, cos, exp, log, constants`)? If SPL has a more constrained or more appropriate set for Nguyen\\'s equations, that\\'s an advantage that needs acknowledging.\\n    *   **Data Generation:** Consistent number of data points, range of input values, and noise levels across all methods?\\n    *   **Complexity Control/Parsimony:** Does SPL explicitly control equation complexity (e.g., by penalizing longer expressions)? How does this compare to GP\\'s parsimony pressure or Eureqa\\'s multi-objective optimization? A method might find the \"true\" solution but then struggle to simplify it, or find a simpler, highly accurate approximation.\\n*   **Robustness on Nguyen:** Claims of robustness usually relate to performance under varying noise levels or limited data.\\n    *   **Validation Check:** Were multiple noise levels tested? How gracefully do the baselines degrade compared to SPL? Is the noise model realistic?\\n\\n**3. Free-Falling Ball Experiment:**\\n*   **Equation:** `d = 0.5 * g * t^2 + v0 * t + d0` (or `d(t) = at^2 + bt + c`). This is a relatively simple quadratic equation.\\n*   **Claims:** SPL will likely claim it discovers the correct form and coefficients accurately.\\n*   **Validity Check:**\\n    *   **Simplicity of Problem:** This is a very common benchmark. If SPL struggles, it\\'s a major concern. If it performs well, it\\'s expected. The key is how it compares to baselines.\\n    *   **Comparison to pySINDy:** This is critical here. As discussed, if pySINDy is given derivative information, it has a significant advantage. If it has to numerically differentiate noisy position data, it might perform poorly, which wouldn\\'t be a fair reflection of its capabilities. If SPL finds the explicit form `d(t) = ...` while SINDy finds `d^2d/dt^2 = g`, both are \"correct\" but represent different levels of information and problem formulation.\\n    *   **Generalizability:** While good for demonstrating basic capabilities, success on this problem alone doesn\\'t prove robustness for complex physical systems (e.g., multi-body, non-linear, higher-order derivatives, partial differential equations).\\n\\n### III. Identified Biases and Limitations in Experimental Setup\\n\\n1.  **Hyperparameter Imbalance:** The most persistent bias in SR benchmarking. Without explicit, detailed reporting of hyperparameter search spaces and methods for all competitors, it\\'s hard to rule out that SPL simply benefited from more extensive tuning.\\n2.  **Computational Budget Disparity:** A lack of clear, consistent time limits or evaluation counts across all methods can lead to misleading results. If SPL runs for hours while GP is cut off after minutes (or fixed generations), the comparison is invalid.\\n3.  **Black-Box Baselines (Eureqa):** Relying on Eureqa\\'s reported performance from external sources (or internal defaults) makes true reproducibility and fair comparison impossible.\\n4.  **Inappropriate Baseline for Problem Type (pySINDy for Nguyen):** While pySINDy is cutting-edge for ODE discovery, its application to purely algebraic symbolic regression problems can be ill-suited, potentially making it appear weaker than it is in its intended domain. Its performance depends heavily on the input (raw data vs. data + derivatives).\\n5.  **Limited Problem Set:** Nguyen\\'s benchmark is standard but purely mathematical. The free-falling ball is a simple physical system. The claims of \"Physics Learner\" would be stronger with more diverse and complex physics problems (e.g., pendulum, chaotic systems, multi-variable expressions, implicit relationships).\\n6.  **Lack of Ablation Studies:** A good paper often includes ablation studies to show the specific contributions of different components of the proposed method (e.g., how different MCTS selection strategies, simulation policies, or value functions impact performance). This helps validate *why* MCTS is effective.\\n7.  **Overemphasis on \"Exact Discovery\":** While desirable, for many real-world problems, finding a highly accurate and parsimonious approximation is often sufficient or even preferred over a slightly inaccurate \"exact\" form. The trade-off between accuracy and complexity (parsimony) should be clearly shown.\\n\\n### IV. Suggestions for Improvement\\n\\n1.  **Standardized Benchmarking Framework:** Utilize established symbolic regression benchmark suites (e.g., SRBench or common problems from other papers) where data, noise models, and metrics are consistent. This improves comparability and reproducibility.\\n2.  **Rigorously Equalized Computational Resources:** Explicitly state and enforce the computational budget for *all* methods (e.g., fixed wall-clock time, fixed number of function evaluations, or fixed number of generations for EAs). If methods have different inherent costs, this needs to be part of the performance analysis (e.g., \"SPL finds solution X in Y hours, while GP finds Z in W minutes\").\\n3.  **Transparent Hyperparameter Tuning:** Detail the hyperparameter search process for *all* algorithms, ensuring that baselines receive comparable tuning effort to SPL. Ideally, release the configuration files.\\n4.  **Diverse and Domain-Appropriate Baselines:**\\n    *   Include other state-of-the-art open-source GP implementations (e.g., from `gplearn` or `DEAP`).\\n    *   Consider other non-GP symbolic regression methods (e.g., neural symbolic regressors if applicable, or more advanced search heuristics).\\n    *   For physics problems, if comparing to SINDy, explicitly state if derivatives were provided or estimated, and justify the comparison. Consider comparing to methods that explicitly incorporate physical priors or conservation laws.\\n5.  **Ablation Studies:** Systematically analyze the impact of different MCTS components on SPL\\'s performance (e.g., node selection strategy, simulation rollout depth, reward function, constant handling). This strengthens the methodological contribution.\\n6.  **Scalability Analysis:** Investigate SPL\\'s performance on problems with higher dimensionality, more complex underlying expressions, or larger datasets. Analyze the scaling of computational time with problem size.\\n7.  **Code Availability:** Make the source code for SPL (and the experimental setup for baselines) publicly available. This is crucial for reproducibility, verification of claims, and fostering future research.\\n8.  **Broader Physics Benchmarks:** To truly validate the \"Physics Learner\" claim, include more challenging physics problems, potentially involving:\\n    *   Systems of coupled equations.\\n    *   Differential equations that are not easily integrated into explicit forms.\\n    *   Problems with latent variables or hidden states.\\n    *   Real-world experimental data with higher noise and uncertainty.\\n9.  **Detailed Error and Complexity Analysis:** Beyond just RMSE or exact discovery, provide insights into the *types* of equations discovered. Are they parsimonious? Do they have good extrapolation capabilities? What kinds of errors are made when the exact solution isn\\'t found? (e.g., off by a constant, missing a term, wrong exponent).\\n\\nBy addressing these points, the paper can significantly strengthen the validity of its claims regarding SPL\\'s improved performance and robustness, providing a more rigorous and convincing evaluation of its capabilities.', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.9883556}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "Now that I have the reviews from the three agents, I will synthesize them into a single, coherent review and provide a final recommendation.\n\n**Synthesis of Reviews:**\n\nThe three reviewers provide a comprehensive assessment of the paper \"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search.\"\n\n*   **Methodology Rigor Expert (MRE):** Applauds the novel application of MCTS to symbolic regression and the sound technical approach. However, MRE raises concerns about the computational cost, hyperparameter sensitivity, limitations of the pre-defined operator set, and the lack of incorporation of physics-based inductive biases. MRE suggests improvements such as guided rollouts, adaptive hyperparameter tuning, hybrid approaches, and the integration of domain knowledge.\n*   **Nonlinear Dynamics Specialist (NDS):** Highlights the significance of the problem addressed and the relevance of the benchmark datasets (Lorenz system, double pendulum). NDS acknowledges the potential of the method for interpretable model discovery but also points out the challenges related to computational cost, basis function dependence, noise sensitivity, and the handling of hidden variables. NDS suggests potential real-world applications in system identification, biophysics, and climate science.\n*   **Symbolic Regression Benchmarking Analyst (SBA):** Provides a critical examination of the experimental results, focusing on the comparison with existing symbolic regression techniques. SBA raises serious concerns about hyperparameter imbalance, computational budget disparity, the use of black-box baselines (Eureqa), and the appropriateness of baselines for specific problem types (pySINDy). SBA suggests improvements such as standardized benchmarking, rigorously equalized computational resources, transparent hyperparameter tuning, and more diverse benchmarks.\n\n**Overall Assessment:**\n\nThe paper presents a novel and technically sound approach to symbolic regression using MCTS. The application of MCTS to this problem is a significant contribution. The reviewers agree that the paper addresses an important problem and uses relevant benchmarks. However, there are significant concerns about the experimental evaluation and the validity of the claims regarding improved performance and robustness. The reviewers highlight the need for more rigorous benchmarking, transparent hyperparameter tuning, and a more comprehensive analysis of the method's limitations.\n\n**Recommendation:**\n\nThe paper has merit due to its novel approach and potential for advancing the field of symbolic regression. However, the concerns raised by the reviewers regarding the experimental evaluation are significant. The claims of improved performance and robustness are not sufficiently supported by the evidence presented.\n\n**FINAL DECISION: Reject**\n\nThe paper needs major revisions to address the reviewers' concerns about the experimental evaluation. Specifically, the authors should:\n\n1.  Conduct a more rigorous and transparent benchmarking study using standardized datasets and equalized computational resources.\n2.  Provide detailed information about hyperparameter tuning for all methods compared.\n3.  Justify the choice of baselines and ensure they are appropriate for the problem types considered.\n4.  Address the limitations of the method, such as computational cost and sensitivity to noise.\n5.  Incorporate more physics-based inductive biases to improve the method's ability to discover physically plausible equations.\n"}], "ground_truth": "Accept: notable-top-5%", "response_history": "Now that I have the reviews from the three agents, I will synthesize them into a single, coherent review and provide a final recommendation.\n\n**Synthesis of Reviews:**\n\nThe three reviewers provide a comprehensive assessment of the paper \"Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search.\"\n\n*   **Methodology Rigor Expert (MRE):** Applauds the novel application of MCTS to symbolic regression and the sound technical approach. However, MRE raises concerns about the computational cost, hyperparameter sensitivity, limitations of the pre-defined operator set, and the lack of incorporation of physics-based inductive biases. MRE suggests improvements such as guided rollouts, adaptive hyperparameter tuning, hybrid approaches, and the integration of domain knowledge.\n*   **Nonlinear Dynamics Specialist (NDS):** Highlights the significance of the problem addressed and the relevance of the benchmark datasets (Lorenz system, double pendulum). NDS acknowledges the potential of the method for interpretable model discovery but also points out the challenges related to computational cost, basis function dependence, noise sensitivity, and the handling of hidden variables. NDS suggests potential real-world applications in system identification, biophysics, and climate science.\n*   **Symbolic Regression Benchmarking Analyst (SBA):** Provides a critical examination of the experimental results, focusing on the comparison with existing symbolic regression techniques. SBA raises serious concerns about hyperparameter imbalance, computational budget disparity, the use of black-box baselines (Eureqa), and the appropriateness of baselines for specific problem types (pySINDy). SBA suggests improvements such as standardized benchmarking, rigorously equalized computational resources, transparent hyperparameter tuning, and more diverse benchmarks.\n\n**Overall Assessment:**\n\nThe paper presents a novel and technically sound approach to symbolic regression using MCTS. The application of MCTS to this problem is a significant contribution. The reviewers agree that the paper addresses an important problem and uses relevant benchmarks. However, there are significant concerns about the experimental evaluation and the validity of the claims regarding improved performance and robustness. The reviewers highlight the need for more rigorous benchmarking, transparent hyperparameter tuning, and a more comprehensive analysis of the method's limitations.\n\n**Recommendation:**\n\nThe paper has merit due to its novel approach and potential for advancing the field of symbolic regression. However, the concerns raised by the reviewers regarding the experimental evaluation are significant. The claims of improved performance and robustness are not sufficiently supported by the evidence presented.\n\n**FINAL DECISION: Reject**\n\nThe paper needs major revisions to address the reviewers' concerns about the experimental evaluation. Specifically, the authors should:\n\n1.  Conduct a more rigorous and transparent benchmarking study using standardized datasets and equalized computational resources.\n2.  Provide detailed information about hyperparameter tuning for all methods compared.\n3.  Justify the choice of baselines and ensure they are appropriate for the problem types considered.\n4.  Address the limitations of the method, such as computational cost and sensitivity to noise.\n5.  Incorporate more physics-based inductive biases to improve the method's ability to discover physically plausible equations.\n", "elapsed_time": 112.32518792152405, "reviewer_agents": {"MethodologyRigorExpert": {"base_model": "gemini-2.5-flash-preview-05-20", "description": "Expert in evaluating the methodological rigor of machine learning papers, focusing on the soundness and novelty of the approach.", "system_prompt": "You are a meticulous researcher specializing in machine learning methodologies. You rigorously evaluate the technical soundness, novelty, and limitations of proposed methods. Pay close attention to the mathematical formulations, algorithmic implementation, and experimental design. Provide detailed critiques and suggestions for improvement.", "create_resource_cost": 0, "invoke_resource_cost": 0, "create_expense_cost": 0, "invoke_expense_cost": 0.15, "output_expense_cost": 0.6}, "NonlinearDynamicsSpecialist": {"base_model": "gemini-2.5-flash-preview-05-20", "description": "Specialist in nonlinear dynamics and equation discovery, assessing the significance of the problems addressed and the applicability of the proposed method.", "system_prompt": "You are an expert in nonlinear dynamics and equation discovery. You evaluate the significance of research problems, the relevance of benchmark datasets, and the practical applicability of proposed methods. Assess the contribution of the work to the field and identify potential real-world applications.", "create_resource_cost": 0, "invoke_resource_cost": 0, "create_expense_cost": 0, "invoke_expense_cost": 0.15, "output_expense_cost": 0.6}, "SymbolicRegressionAnalyst": {"base_model": "gemini-2.5-flash-preview-05-20", "description": "Analyst specializing in symbolic regression benchmarking, critically examining experimental results and comparing them with existing techniques.", "system_prompt": "You are an experienced analyst specializing in symbolic regression benchmarking. You critically examine experimental results, focusing on comparisons with existing techniques. Assess the validity of claims regarding improved performance and robustness, and identify potential biases or limitations in the experimental setup.", "create_resource_cost": 0, "invoke_resource_cost": 0, "create_expense_cost": 0, "invoke_expense_cost": 0.15, "output_expense_cost": 0.6}}}
