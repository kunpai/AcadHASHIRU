{"paper_id": "9BXSGPfRhX", "prompt": "Review the following paper for International Conference on Learning Representations (ICLR) 2023. Remember you need to make 3 reviewer agents for each paper. GIVE A FINAL DECISION in the form of \"FINAL DECISION: <Accept/Reject>\". The paper title is: Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s\n\n1 INTRODUCTION: Most state-of-the-art object detectors follow a two-stage detection paradigm. A region proposal network (RPN) finds promising locations, and these are passed through a classifier to determine what, if any, object is present. In this architecture, if an RPN makes no proposal around an object, the object will not be detected. For a few-shot detector, one splits the classes into base and novel, then trains the RPN and classifier on base classes, fixes the RPN, and finally fine-tunes the classifier on novel classes using the RPN\u2019s predictions. Objects in large-scale object detection datasets (e.g. COCO Lin et al. (2014); LVIS Gupta et al. (2019)) have typical aspect ratio that varies somewhat from instance to instance, and often differs sharply from category to category. As a result, the few-shot training procedure has a built-in problem with distribution shift. Imagine all base classes are roughly square, and all novel classes are either short and wide, or tall and narrow. The RPN trained on the base classes should miss some novel class boxes. These boxes will have two effects: the training data the classifier sees will be biased against the correct box shape; and, at run time, the detector may miss objects because of RPN failures. We refer to this problem as unfairness (the RPN does not deal fairly with different aspect ratios). Unfairness occurs because the RPN sees few or no examples of the novel classes during training Kang et al. (2019); Wang et al. (2020); Yan et al. (2019). To date, unfairness has not been remarked on. This is an accident of dataset construction: the standard base/novel splits in standard datasets do not result in a distribution shift. But other base/novel splits do result in a distribution shift large enough to have notable effects, and Section 3 shows our evidence that this effect occurs in practice. In particular, we describe ARShift benchmarks that simulate the real-world scenario where the aspect ratio distribution shift is severe. RPNs in state-of-the-art few-shot detectors are heavily biased towards familiar aspect ratio distributions, and so have weaker than necessary performance on non-standard splits because their RPNs are unfair. Evaluation practice should focus on performance under hard splits. In few-shot detection applications, a more robust RPN will be more reliable, because applications typically offer no guarantees about the aspect ratio of novel classes. We show how to build a more robust RPN by training multiple RPN classifiers to be specialized but cooperative. Our CoRPN\u2019s can specialize (and a degree of specialization emerges naturally), but our cooperation constraints discourage individual RPN classifiers from overspecializing and so face generalization problems. CoRPN\u2019s are competitive with SOTA on widely used conventional benchmarks of few-shot detection, using conventional splits. But on our ARShift benchmarks with hard splits based on PASCAL VOC, MS-COCO, and LVIS Everingham et al. (2010); Lin et al. (2014); Kang et al. (2019); Wang et al. (2020), they beat SOTA, because they are more robust to shifts in aspect ratio distribution. Our contributions: (1) We show unfairness has severe effects on detector performance, and describe ARShift benchmarks that evaluate these effects. (2) We describe a general approach to improving RPN robustness to distribution shifts. Our CoRPN construction works with many types of few-shot detector. (3) We show that performance improvements resulting from CoRPN\u2019s results from improved fairness. (4) Our CoRPN\u2019s are competitive with SOTA on widely used conventional benchmarks. But on the hard splits in ARShift, they beat SOTA, because they are fair. 2 RELATED WORK: Object Detection with Abundant Data. There are two families of detector architecture, both relying on the fact that one can quite reliably tell whether an image region contains an object independent of category Endres & Hoiem (2010); van de Sande et al. (2011). In serial detection, a proposal process (RPN in what follows) offers the classifier a selection of locations likely to contain objects, and the classifier labels them. This family includes R-CNN and its variants Girshick (2015); Girshick et al. (2014); He et al. (2017); Ren et al. (2015) In parallel detection, there is no explicit proposal step; these methods can be faster but the accuracy may be lower. This family includes YOLO and its variants Bochkovskiy et al. (2020); Redmon & Farhadi (2017); Redmon et al. (2016); Redmon & Farhadi (2018), SSD Liu et al. (2016), point-based detectors such as CornerNet Law & Deng (2018) and ExtremeNet Zhou et al. (2019), and emerging transformer-based methods exemplified by DETR Carion et al. (2020)). This paper identifies an issue with the proposal process that can impede strong performance when there is very little training data (the few-shot case). The effect is described in the context of two-stage detection, but likely occurs in one-stage detection too. Few-Shot Object Detection. Few-shot detection involves detecting objects for which there are very few training examples Chen et al. (2018); Kang et al. (2019); Schwartz et al. (2019), and state-ofthe-art methods are usually serial Wang et al. (2019); Yan et al. (2019); Wang et al. (2020); Fan et al. (2020); Wu et al. (2020); Xiao & Marlet (2020); Yang et al. (2020); Li et al. (2021a); Hu et al. (2021); Zhang et al. (2021); Li et al. (2021b); Zhu et al. (2021). There is a rich few-shot classification literature (roots in Thrun (1998); Fei-Fei et al. (2006)). Dvornik et al. (2019) uses ensemble procedures for few-shot classification. As to detection, TFA Wang et al. (2020) shows that a simple two-stage fine-tuning approach outperforms other complex methods. Much work seeks improvements by applying different techniques, such as meta-learning Wang et al. (2019); Yan et al. (2019); Hu et al. (2021); Zhang et al. (2021), metric learning Han et al. (2021); Wu et al. (2021); Yang et al. (2020), refinement Wu et al. (2020); Li et al. (2021b), feature reweighting Kang et al. (2019), semantic relations Zhu et al. (2021), augmentation Li & Li (2021); Zhang & Wang (2021), and margin loss Li et al. (2021a). Other work (Fan et al. (2021)) alleviates forgetting of base classes. In particular, Qiao et al. (2021) achieves state-of-the-art performance by decoupling the gradient of the backbone and other components of the detector, as well as adding a prototypical calibration module. Here we focus on the two most representative methods \u2013 the state-of-the-art DeFRCN Qiao et al. (2021) and the widely used TFA Wang et al. (2020) \u2013 as our main baselines. Few-Shot Detection Benchmarks. The existing literature can be seen as variations on a standard detection framework, where one splits data into two sets of categories: base classes Cb (which have many training examples) and novel classes Cn (which have few). The RPN and classifier are trained with instances from the base classes, and then fine-tuned with the few-shot novel class data. While the choice of the split can be important in revealing different aspects of few-shot detection, existing benchmarks Kang et al. (2019); Wang et al. (2020) have only focused on a few fixed, rather arbitrary splits. However, we explore the scenario where there exists a notable distribution shift between base and novel classes, and investigate the behavior of RPNs accordingly. Proposal Process in Few-Shot Detection. Relatively little work adjusts the proposal process, which is usually seen as robust to few-shot issues because there are many base examples. Sun et al. (2021) introduces contrastive-aware object proposal encodings to facilitate classification. Attention mechanisms are also introduced that feed category-aware features instead of plain image features into the proposal process Hsieh et al. (2019); Fan et al. (2020); Xiao & Marlet (2020); Osokin et al. (2020), as well as re-ranking proposals based on similarity with query images Hsieh et al. (2019); Fan et al. (2020). Making the RPN category-aware improves the quality of novel class proposals, but at inference time the model suffers from catastrophic forgetting of base categories \u2013 current category-aware features cannot summarize the very large number of base class examples efficiently or accurately. An RPN that is generally well-behaved can still create serious trouble in the few-shot case by missing important proposals for the novel classes during fine-tuning. We show that the proposal process can be improved by a carefully constructed cooperating RPN\u2019s without substantial loss of performance for the base classes. 3 OUR APPROACH: We believe that improving the population of RPN boxes seen by the classifier in training will always tend to improve a detector, and so focus on finding and fixing the effect within a standard few-shot object detection framework. Our proposed strategy is general and can work with different types of few-shot detectors. Here we consider the two most representative methods: the state-of-the-art DeFRCN Qiao et al. (2021) and the widely used TFA Wang et al. (2020). We first observe the box aspect ratio distribution shift problem through our pilot study, and show that na\u0131\u0308ve ensemble of RPN experts does not sufficiently solve this problem on our hard ARShift splits. Then we introduce our CoRPN\u2019s that effectively tackles the aspect ratio distribution shift problem via the cooperation and diversity losses. 3.1 BACKGROUND: We use the few-shot detection setting introduced in Kang et al. (2019). We split the dataset into two sets of categories: base classes Cb and novel classes Cn. As shown in Figure 3, the training process is two-phase: (1) base classes training, and (2) fine-tuning with novel classes. In phase 1, the model is trained with base class instances which results in a |Cb|-way detector. After base classes training, weights for novel classes are randomly initialized, making the classifier a (|Cb| + |Cn|)way classifier. In phase 2, the model is fine-tuned using either a set of few novel class instances or a balanced dataset containing both novel and base classes. The classifier sees the ground truth box and RPN boxes; it is typically trained to regard RPN boxes with IoU\u22650.7 as positive, and with IoU<0.3 as negative. After the fine-tuning phase, we evaluate our model by average precision (AP) on novel and base categories. Although the focus of few-shot detection is the novel classes, since most test images contain instances from both base and novel classes, it is essential to maintain good performance on base classes. We adopt the widely-used Faster R-CNN Ren et al. (2015) as our base model. As shown in Figure 3, Faster R-CNN is a two-stage detector, which consists of a backbone image feature extractor, an RPN, followed by the region of interest (ROI) pooling layer, and a bounding box classifier and a bounding box regressor on top of the model. The RPN determines if a box is a foreground or a background box. Following the RPN is non-maximum suppression (NMS) which ranks and selects top proposal boxes. After passing the ROI pooling layer, the predictor\u2019s head classifies and localizes each box. In phase 1, the whole model is trained on many-shot base class instances. Phase 2 fine-tunes part of the model on novel class instances with other parts frozen. Specifically, for TFA Wang et al. (2020), only the top layer of the bounding box classifier and regressor are fine-tuned. For DeFRCN Qiao et al. (2021), the whole model is fine-tuned except for the convolutions in the bounding box classifier and regressor. 3.2 PILOT STUDY: BOX DISTRIBUTION SHIFT: In the real world, the bounding box distribution of these novel categories often differs from the base categories, resulting in unfair few-shot performances. Namely, the difference in the distribution of box scale, aspect ratio, and center location all inhibit a successful transfer. Previous work tries to alleviate the scale issues with multiscale features and the location issues with translation invariance of convolution. However, these approaches fail to solve all of these problems, especially when the distribution between base and novel class box aspect ratios has a significant shift. We simulate this scenario by proposing new splits: our ARShift benchmark, on the PASCAL VOC, COCO and LVIS datasets that emphasize this distribution shift and the fairness to different aspect ratio distributions. We manually select a set of classes that will likely have a different box distribution to the base categories. Figure 2 shows that our split has a more significant shift in the box aspect ratio distribution. As an na\u0131\u0308ve approach to alleviating this issue, we modified the RPN classifier to be an ensemble of expert RPN classifiers. Instead of using one RPN classifier for all proposals, we use 3 RPN classifiers for the anchors of 3 different aspect ratios (0.5, 1, and 2.0 respectively). The 3 RPN classifiers independently output their prediction for their respective anchors, which are combined as the final prediction. Tables 1, 2 and 3 show that compared to the baseline DeFRCN Qiao et al. (2021), this approach represented by \u2018DeFRCN Ensemble of Experts\u2019 performs comparably and thus cannot fully address the issue. Intuitively, in this ensemble of experts method, individual RPN classifiers might be overspecializing and so facing generalization problems. Instead, we propose a method where we do not explicitly enforce each RPN classifier to specialize in an aspect ratio, but let the specialization emerge in the learning process. This method, named CoRPN\u2019s, shows a large improvement over the baselines in Tables 1, 2 and 3. 3.3 LEARNING COOPERATING RPN\u2019S (CORPN\u2019S): We would like to alter the RPN to improve the population of boxes reported, especially on our ARShift benchmark where novel classes has a large box distribution shift. We expect that doing so affects mainly the few-shot case. We use multiple redundant RPN classifiers, but our goals imply that these RPN classifiers need to be trained to cooperate (i.e., they should not be a pure ensemble of experts). In what follows, we use the term RPN and RPN classifier interchangeably unless otherwise noted. In particular, we train and evaluate our RPN classifiers using an OR strategy \u2013 a box is classified with the label reported by the most confident RPN, which gets the gradient during training. This has two effects. First, the RPN\u2019s can specialize to a degree, though we do not allow the RPN\u2019s to drift too far apart. In turn, if one RPN misses a positive box, the other might find it. Second, the training strategy may improve the variation of proposals, which is especially essential when dealing with a different proposal box distribution in the few-shot case. Both effects may bring improvements to the model\u2019s fairness with respect to aspect ratio distribution. As Figure 3 shows, Faster R-CNN\u2019s RPN consists of a feature extractor, a binary classifier (which decides whether a box is foreground or background), and a bounding box regressor (which is not relevant to our current purpose). We do not intend for our RPN\u2019s to use distinct sets of features, since it would introduce a large number of additional parameters, so we construct redundant classifiers while keeping both the feature extractor and the bounding box regressor shared between all RPN\u2019s. An RPN with a single classifier is trained with a cross-entropy loss Lcls = LCE and produces a single prediction. In our case, we train N different binary classifiers simultaneously, and must determine (1) what prediction is made at test time and (2) what gradient goes to what classifier at training time. At test time, a given box gets the score from the most confident RPN. If the highest foreground probability is closer to one than the highest background probability, the box is predicted to be foreground; otherwise, it is predicted to be the background. In training time, merely taking the gradient of the best RPN score is not good enough, because the model may collapse to the trivial solution where one RPN scores all boxes, and the others do nothing interesting. For any foreground box, we want at least one RPN to have a very confident foreground prediction and all others to have good foreground scores too (so that no foreground box is missed). We use the following strategy. For a specific anchor box i, each RPN j (of the N RPN\u2019s) outputs a raw score rji , indicating if the box is a foreground box or not: ri = [r 1 i , r 2 i , . . . , r N i ]. After applying a sigmoid, the jth RPN produces the foreground probability f ji = \u03c3(r j i ) for anchor box i. We choose the score from the j\u2217th RPN such that j\u2217 = argminj min{f j i , 1\u2212 f j i }, (1) namely the most certain RPN which produces probability closest to the edge of the [0, 1] interval. At training time, only the chosen j\u2217th RPN gets the gradient from anchor box i. The RPN selection procedure is per-box, and even adjacent boxes can pass through different RPN\u2019s. Other than the standard cross-entropy loss, we use two additional loss terms: a diversity loss Ldiv encourages RPN\u2019s to be distinct, and a cooperation loss Lcoop encourages cooperation and suppresses foreground false negatives. The final loss is Lcls := Lj \u2217 CE + \u03bbdLdiv + \u03bbcLcoop, (2) where \u03bbd and \u03bbc are trade-off hyperparameters. 3.4 ENFORCING DIVERSITY: We do not want our RPN\u2019s to be too similar and prefer their specialization. For each positive anchor box, RPN responses should be different because we want different RPN\u2019s to cover different types of proposal boxes. To this end, we propose a loss function to enforce diversity among RPN\u2019s. Given a set of NA anchor boxes, the N RPN\u2019s produce an N by NA matrix of probabilities F = [f1, f2, . . . , fN ]T . The covariance matrix \u03a3(F) is \u03a3(F) = E[(f j \u2212 E[f j ])(fk \u2212 E[fk])T ]. (3) We define the diversity loss Ldiv by the log determinant loss Ldiv := \u2212 log(det(\u03a3(F))). (4) By the diversity loss, we encourage the probability matrix to have rank N , so each RPN is reacting differently on the collection of NA boxes. This procedure ensures each RPN to be the most certain RPN for some boxes, so that every RPN is being selected and trained. Omitting this loss can cause some RPN classifier to receive little training. 3.5 LEARNING TO COOPERATE: We also want the RPN\u2019s to cooperate so that they all agree to a certain extent for foreground boxes. We propose a cooperation loss to prevent any RPN from firmly rejecting any foreground box. For foreground box i, with the jth RPN, we define the cooperation loss Li,jcoop := max{0, \u03d5\u2212 f j i }, (5) where \u03d5 is a constant parameter (usually less than 0.5), acting as a lower bound for each RPN\u2019s probability assigning to a foreground box. If an RPN\u2019s response is below \u03d5, that RPN is going to be penalized. The final cooperation loss is an average of cooperation losses over all foreground boxes and all RPN\u2019s. 4 EXPERIMENTS: Benchmarks. We propose a new base/novel split on both the PASCAL VOC Everingham et al. (2010), MS-COCO Lin et al. (2014) and LVIS Gupta et al. (2019) datasets to simulate the realworld scenario, where the novel class box distribution deviates from the base class counterpart. Our proposed split VOC-ARShift is similar to the conventional few-shot detection VOC split Kang et al. (2019); Wang et al. (2020). We use the images and annotations of VOC (07 + 12) and select 15 classes as base classes, and leave the rest as novel classes. In our proposed COCO-ARShift split, we use the images and annotation of COCO 2014, select the 20 VOC classes as training, and select 10 out of the other 60 classes as novel classes. We select these classes to explicitly produce a distribution shift in the box aspect ratios, as shown in Figure 2. In our LVIS-ARShift benchmark, we use LVIS v0.5 and 10 shots following Wang et al. (2020). In each setting, the base classes are the 20 VOC classes in COCO, while the novel classes are 10 rare classes manually picked that have an aspect ratio distribution shift from the base classes. The detailed classes of our proposed splits are in Section H in the appendix. Apart from our proposed ARShift setting, we also evaluate on two widely-used few-shot detection benchmarks Kang et al. (2019); Wang et al. (2020) based on PASCAL VOC and COCO. For a fair comparison, we use the same train/test splits and novel class instances as in Kang et al. (2019); Wang et al. (2020) to train and evaluate all models. On COCO, we report base/novel classes AP, AP50, and AP75 under shots 1, 2, 3, 5, 10, and 30. On PASCAL VOC, we report AP50 for three different base/novel class splits under shots 1, 2, 3, 5, and 10. Following Wang et al. (2020) and Qiao et al. (2021), we use Faster R-CNN as our base model and use an ImageNet pre-trained Russakovsky et al. (2015) ResNet-101 as the backbone, unless otherwise noted. Training Procedure. Our training and fine-tuning procedures are consistent with previous work TFA Wang et al. (2020) and DeFRCN Qiao et al. (2021). On PASCAL VOC, at phase 1 base classes training, each model is trained on the union set of VOC 07+12 trainval data. Evaluation is on the VOC 07 test set. At the fine-tuning phase, each model is fine-tuned with a balanced few-shot dataset sampled from VOC 07+12 that contains both base classes and novel classes. On COCO, following Wang et al. (2020), the fine-tuning phase is two-stage: at stage 1, we fine-tune the model on novel classes; at stage 2, we then fine-tune the model with a balanced few-shot dataset containing both base and novel classes. Please refer to Section C of the appendix for our implementation details and hyperparameters. Baselines and Evaluation Procedure. We mainly focus on comparing against the state-of-the-art baseline DeFRCN Qiao et al. (2021), and a widely-used previous work TFA Wang et al. (2020). Our approach incorporates CoRPN\u2019s into the baseline models, while keeping other model components and design choices unchanged. In addition, we thoroughly compare with a variety of recent few-shot detectors, including FSOD Fan et al. (2020), MPSR Wu et al. (2020), FSDetView Xiao & Marlet (2020). These baselines address other aspects of few-shot detection which are different from us (Section 2), and their modifications are thus largely orthogonal to our effort here. Note that our evaluation follows the standard procedure in Wang et al. (2020). This standard procedure computes AP separately for novel and base categories for a detector that is engineered to detect both novel and base classes ((|Cb|+ |Cn|)-way). We focus on the novel class performance, and also report the base class performance in Table 4. For work Fan et al. (2020) with different evaluation procedures, we re-evaluate their methods with the standard procedure, so that results in Tables 4 can be different from the original reported results. 4.1 MAIN RESULTS: Our evaluation mainly focuses on our proposed ARShift splits, but also includes the conventional splits. Also, we focus on the extremely few-shot regime, which is the most challenging scenario for few-shot detection. Tables 1, 2 and 3 show the detection performance on our proposed ARShift splits where a bounding box aspect ratio distribution shift is present between base and novel classes. Table 4 summarize the detection results for base and novel classes in low shots on the conventional COCO benchmark, respectively. For completeness, the results for base and novel classes in higher shots on PASCAL VOC and COCO are summarized in Section B of the appendix, where our model also performs comparably. CoRPN\u2019s consistently outperform the baselines. Tables 1, 2 and 3 show that CoRPN\u2019s greatly outperform the baseline TFA Wang et al. (2020), DeFRCN Qiao et al. (2021) and an aspect ratio ensemble modified from the DeFRCN model, especially in very low shots. Especially, we provide the results on three additional base and novel class splits on the LVIS dataset Gupta et al. (2019) in Table 3. LVIS is a much more challenging long-tail recognition dataset, containing a large amount of rare classes, hence the fairness for aspect ratio is more crucial. We also provide the results on all rare classes in the LVIS test set as a reference. Our CoRPN\u2019s outperform the state-of-the-art DeFRCN baseline by large margins on all the splits with aspect ratio distribution shift, especially in AP75, suggesting that CoRPN\u2019s improve the quality of detection in such scenarios. CoRPN\u2019s also marginally outperform the DeFRCN baseline on the entire set of rare classes in mAP and AP75 on LVIS. On the conventional splits, as shown in Tables 4, CoRPN\u2019s consistently improve over TFA for all shots, and also marginally outperform DeFRCN on the challenging COCO dataset. The combination of both results shows a significant improvement in aspect ratio distribution fairness in our model. CoRPN\u2019s beat other state of the art. With our simple modification on RPN, we also outperform other sophisticated approaches in the very low-shot regime on the more challenging COCO dataset. In particular, we significantly outperform baselines that introduce attention mechanisms for adjusting proposal generation Hsieh et al. (2019); Fan et al. (2020) under the standard evaluation procedure. We believe CoRPN\u2019s could be combined with other approaches with improvements from different perspectives, such as exploiting better multi-scale representation Wu et al. (2020), incorporating metric learning Yang et al. (2020), or adding feature aggregation module Xiao & Marlet (2020) for further improvements. CoRPN\u2019s don\u2019t forget base classes. While improving detection on novel classes through finetuning, we maintain strong performance on base classes \u2013 there is no catastrophic forgetting (Table 4). By contrast, the base class performance of some state-of-the-art baselines dramatically drops, demonstrating that they cannot fairly detect novel and base classes. 4.2 ABLATION STUDY: We investigate how the proposals of CoRPN\u2019s change and conduct a series of ablations that evaluate the contribution of each loss component and different design choices. Specifically, we find that: (1) CoRPN\u2019s specialize in different aspect ratios without explicit supervision; (2) Our cooperation loss and diversity loss are both necessary for CoRPN\u2019s to improve fairness; (3) (in Section F of the appendix) CoRPN\u2019s outperform other baselines such as with larger RPN sub-networks, an existing cosine loss based diversity, and bootstrapping. Specialization for aspect ratios emerges in CoRPN\u2019s training. Table 5 shows that the boxes of three different aspect ratios are handled by different RPN classifiers in CoRPN\u2019s. Instead of explicitly training different RPN classifiers to handle different aspect ratios, CoRPN\u2019s learn a more flexible specialization, improving the performance. CoRPN\u2019s need both diversity and cooperation losses. Table 6 shows that after removing either loss, CoRPN\u2019s does not improve the performance over the baseline. Also, when the threshold hyperparameter is suboptimal, the performance surpasses the baseline but still substantially underperforms the CoRPN\u2019s with the optimal hyperparameter. 5 CONCLUSION: We identify the bias of few-shot detectors towards familiar aspect ratio distribution. As illustrated in our ARShift benchmark, a substantial improvement on under-represented aspect ratio distribution can be obtained by our proposed CoRPN\u2019s which produce more informative proposals. Our method achieves a new state of the art on both our proposed settings with hard base and novel splits and widely-used benchmarks in the very few-shot regime. This is achieved by training CoRPN\u2019s with diversity and cooperation losses. A APPENDIX: This appendix provides additional experimental results and details that support the approach in the main paper and are not included there due to limited space. The seven sections include (1) additional results for higher-shots on the COCO-ARShift, comparisons with additional baselines for ARShift, and results on base classes before and after finetuning; (2) explainations for additional evaluation and experimental details; (3) discussion of the training and inference time and memory; (4) results on conventional splits; (5) analysis with additional ablation study; (6) addtional qualitative results; and (7) details of the proposed base and novel class splits on ARShift for PASCAL VOC, COCO, and LVIS. B ADDITIONAL RESULTS: Higher-Shot Results on COCO-ARShift In Table 2 of the main paper, we show that CoRPN\u2019s outperform the DeFRCN Qiao et al. (2021) baseline consistently on 1, 2, and 3 shots. Table 8 shows that this performance improvement persists in 5, 10, and 30 shots. In this scenario where more support instances are available, CoRPN\u2019s consistently outperform the DeFRCN Qiao et al. (2021) baseline. Additional Baseline on ARShift In Table 1 of the main paper, we mainly compare our method against the state-of-the-art method DeFRCN Qiao et al. (2021) on our VOC-ARShift. In Table 9 we also evaluate an additional baseline FSCE Sun et al. (2021). Note that other recently published methods represented by FSCE underperform our DeFRCN baseline by significant margins on our ARShift splits as well, so we do not include these other methods in our main paper. Results on Base classes Here we provide the detection results on base classes after base classes training (stage 1) and after fine-tuning (stage 2). As shown in Table 7, the performance of our CoRPN\u2019s + DeFRCN on base classes is comparable with DeFRCN Qiao et al. (2021), while we achieve large improvements on novel test classes as shown in Table 1 of the main paper. After fine-tuning, our CoRPN\u2019s also do not forget base classes. Table 7 shows that the performance of our CoRPN\u2019s + DeFRCN after finetuning is still comparable with the baseline. C IMPLEMENTATION AND EVALUATION DETAILS Implementation Details and Hyperparameters. For ease of comparison, we use the same values for all shared training and fine-tuning hyperparameters (batch size, learning rate, momentum, weight decay, etc.) as the baselines Wang et al. (2020) and Qiao et al. (2021). CoRPN\u2019s have the following additional hyperparameters: the number of RPN\u2019s, the cooperation loss threshold \u03d5, the diversity loss trade-off \u03bbd, and the cooperation loss trade-off \u03bbc. For COCO and LVIS, we directly used hyperparameter sets that worked well on PASCAL VOC. In Table 4, we report CoRPN\u2019s detection results. We find that hyperparameters selected from PASCAL VOC are generalizable to the more challenging COCO and LVIS benchmark. Results reported in Table 4 are obtained with 5 RPNs, \u03d5 = 0.3, \u03bbc = 1, \u03bbd = 0.025 for TFAWang et al. (2020), and \u03bbc = 2, \u03bbd = 0.05 for DeFRCN Qiao et al. (2021). Selection Procedure \u2013 Cumulative Variance. We summarized the hyperparameter selection criteria for PASCAL VOC in the experiment section in the main paper. The second criterion is the cumulative variance in the RPN\u2019s response matrix to foreground boxes. Specifically, given a set of M anchor boxes, the N RPN\u2019s produce an N by M matrix of probabilities F = [f1, f2, . . . , fN ]T . We run a principal component analysis (PCA) on F with N components and compare the cumulative percentage of variance explained by each component. We would like the variance to be distributed across components. Evaluation. As mentioned in the main paper, for a fair comparison, we use the standard evaluation procedure for all the compared models. We also compare against other approaches with the same novel class instances and test images. Authors of methods compared in this submission have helped us ensure the performance we report is a proper reflection of their methods, and we will acknowledge properly in any final version. In the standard evaluation procedure, when a test image comes in, the model has no assumption on what category the image contains Wang et al. (2020). The detector\u2019s classifier is (|Cb|+|Cn|)-way, detecting objects from a joint space of both base and novel categories. In the main paper, we marked results with * if they were re-evaluated under the standard procedure, and with ** if the original work used the standard procedure, but the results were not reported and so they were evaluated by us. Specifically, below we include the details on how we obtained the results (with special marks) in the main paper; other results (without special marks) Wang et al. (2020); Pe\u0301rez-Ru\u0301a et al. (2020); Yang et al. (2020); Sun et al. (2021); Li et al. (2021a); Zhu et al. (2021) including the concurrent work Sun et al. (2021); Li et al. (2021a); Zhu et al. (2021) are from the original papers. \u2022 We fine-tuned and evaluated MPSR using the publicly released code and the pre-trained detection model for base classes Wu et al. (2020). \u2022 We re-evaluated FSOD Fan et al. (2020) and CoAE Hsieh et al. (2019) under the standard procedure, using the publicly released code and the pre-trained model Fan et al. (2020); Hsieh et al. (2019). FSOD uses a class-agnostic 2-way classifier that determines if an object is foreground or background. At inference time, FSOD produces a balanced number of proposals per novel category and collects these proposals for NMS. We adapt FSOD under the standard procedure such that there are a balanced number of proposals for all base and novel categories. For a fair comparison, we also fine-tuned FSOD with the same novel category instance(s) as in TFA Wang et al. (2020). \u2022 We re-evaluated CoAE under the standard evaluation, using the publicly released code and a pre-trained model Hsieh et al. (2019). For each test image containing a certain category, CoAE samples support image(s) from this category and collects boxes based on the support image(s). At inference time, instead of providing each test image with support feature(s) from this category, we provide each test image support feature(s) from all base and novel categories. We then collect boxes from all categories and evaluate them. For a fair comparison, we also fine-tuned CoAE with the same novel category instance(s) as in TFA Wang et al. (2020). D TRAINING & INFERENCE TIME AND MEMORY: The only architectural difference between CoRPN\u2019s and the baseline RPNs of TFA Wang et al. (2020) and DeFRCNQiao et al. (2021) is that CoRPN\u2019s have multiple RPN classifiers. Note that we only duplicate the RPN classifiers, but not the entire RPN. In the baselines, the RPN\u2019s classifier is a 1\u00d71 convolutional layer, with input channels as the number of feature channels (256) and output channels as the number of cell anchors (3). Compared with the baselines, CoRPN\u2019s with 5 RPN\u2019s have four additional RPN classifiers and thus consist of 256\u00d712 additional parameters. In our experiments, we find that CoRPN\u2019s with 5 RPN\u2019s increase the training time by only 3%, with roughly the same inference time and same memory footprint, compared with the baselines. E RESULTS ON CONVENTIONAL SPLITS: In Table 4 of the main paper, we show that CoRPN\u2019s perform comparably or even better on conventional splits on 1, 2, and 3 shots on COCO. In this section we present more conventional split results. Table 10 shows PASCAL VOC conventional split results where our CoRPN\u2019s perform comparably with the baselines. Table 11 shows the results on COCO 5, 10, and 30 shots, where our method also obtains similar performance to the baseline. F ADDITIONAL ANALYSIS: We present some additional ablation studies for our CoRPN\u2019s. Note that these ablations are performed on the conventional split. Even on conventional splits, our CoRPN\u2019s outperform these naive strategies. Our CoRPN\u2019s will likely achieve more performance improvement on our ARShift splits. Bootstrapping. Table 1 in the main paper shows that our CoRPN\u2019s outperform naive ensembles. Here we further compare CoRPN\u2019s with a bootstrapping baseline in Table 12. We construct the bootstrapping baseline by using multiple RPN classifiers, the number of which is the same as CoRPN\u2019s. Instead of selecting the most confident RPN to get gradients, we randomly select an RPN to get gradients during training. There are no additional loss terms in training these RPN classifiers. In the fine-tuning stage and the inference time, we use the same selection procedure as CoRPN\u2019s (i.e., using the most certain RPN). Diversity loss in Dvornik et al. (2019). In Table 12, we also compare our CoRPN\u2019s with Dvornik et al. (2019), which utilizes a pairwise cosine similarity based diversity loss. Our CoRPN\u2019s also outperform this baseline with a considerable margin. Larger RPN. We compare CoRPN\u2019s with a baseline with larger RPN sub-networks in Table 13. We find that using larger RPN sub-networks does not improve performance, suggesting that the advantage of CoRPN\u2019s is not simply the result of using more parameters. In CoRPN\u2019s, all RPN classifiers share the same RPN feature extractor, as shown in Figure 4 (main paper). We enlarge the feature dimension in the RPN. We implemented two options: a large RPN where the RPN feature extractor\u2019s output channels increase from 256 to 272, and a larger RPN where the output channels double to 512. We also modified the RPN classifier and bounding box regressor to take in larger features for both options. Table 13 shows that simply enlarging the model capacity and the anchor density of the original RPN cannot improve the few-shot detection performance. G ADDITIONAL QUALITATIVE RESULTS: In Figure 4 we show some additional qualitative result of our CoRPN\u2019s model on COCO. Notably, our model could successfully discover novel objects omitted by the baseline, and also successfully classify some novel objects that cause confusion for the baseline method. H DATA SPLITS: PASCAL VOC Split. For our proposed PASCAL VOC-ARShift split, the base classes include \u201cbicycle\u201d, \u201cboat\u201d, \u201ccar\u201d, \u201ccat\u201d, \u201cchair\u201d, \u201cdiningtable\u201d, \u201cdog\u201d, \u201cperson\u201d, \u201csheep\u201d, \u201ctvmonitor\u201d, \u201cbird\u201d, \u201cpottedplant\u201d, \u201ccow\u201d, \u201cmotorbike\u201d, and \u201csofa\u201d; the novel classes include \u201ctrain\u201d, \u201cbottle\u201d, \u201caeroplane\u201d, \u201chorse\u201d, and \u201cbus\u201d. COCO Split. For our proposed COCO-ARShift split, the base classes include the 20 VOC classes in COCO; the novel classes include \u201chot dog\u201d, \u201ctennis racket\u201d, \u201cfire hydrant\u201d, \u201claptop\u201d, \u201csuitcase\u201d, \u201cfrisbee\u201d, \u201cteddy bear\u201d, \u201cbowl\u201d, \u201ckite\u201d, and \u201celephant\u201d. LVIS Splits. For our proposed LVIS-ARShift splits, the base classes include the 20 VOC classes in LVIS; the novel classes of the first split include \u201cLoafer (type of shoe)\u201d, \u201cbatter (food)\u201d, \u201ccabin car\u201d, \u201ccylinder\u201d, \u201cegg roll\u201d, \u201cliquor\u201d, \u201cnailfile\u201d, \u201cplow (farm equipment)\u201d, \u201cvinegar\u201d, and \u201cyoke (animal equipment)\u201d; the novel classes of the second split include \u201cbroach\u201d, \u201cburrito\u201d, \u201ccargo ship\u201d, \u201ccrayon\u201d, \u201cincense\u201d, \u201cpeeler (tool for fruit and vegetables)\u201d, \u201cpin (non jewelry)\u201d, \u201croller skate\u201d, \u201ctinsel\u201d, and \u201cvodka\u201d; the novel classes of the third split include \u201cax\u201d, \u201cbeaker\u201d, \u201cferry\u201d, \u201cfish (food)\u201d, \u201cfunnel\u201d, \u201cincense\u201d, \u201cneedle\u201d, \u201cspace shuttle\u201d, \u201cstepladder\u201d, and \u201cvulture\u201d.", "agent_review": [{"role": "user", "content": "Review the following paper for International Conference on Learning Representations (ICLR) 2023. Remember you need to make 3 reviewer agents for each paper. GIVE A FINAL DECISION in the form of \"FINAL DECISION: <Accept/Reject>\". The paper title is: Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s\n\n1 INTRODUCTION: Most state-of-the-art object detectors follow a two-stage detection paradigm. A region proposal network (RPN) finds promising locations, and these are passed through a classifier to determine what, if any, object is present. In this architecture, if an RPN makes no proposal around an object, the object will not be detected. For a few-shot detector, one splits the classes into base and novel, then trains the RPN and classifier on base classes, fixes the RPN, and finally fine-tunes the classifier on novel classes using the RPN\u2019s predictions. Objects in large-scale object detection datasets (e.g. COCO Lin et al. (2014); LVIS Gupta et al. (2019)) have typical aspect ratio that varies somewhat from instance to instance, and often differs sharply from category to category. As a result, the few-shot training procedure has a built-in problem with distribution shift. Imagine all base classes are roughly square, and all novel classes are either short and wide, or tall and narrow. The RPN trained on the base classes should miss some novel class boxes. These boxes will have two effects: the training data the classifier sees will be biased against the correct box shape; and, at run time, the detector may miss objects because of RPN failures. We refer to this problem as unfairness (the RPN does not deal fairly with different aspect ratios). Unfairness occurs because the RPN sees few or no examples of the novel classes during training Kang et al. (2019); Wang et al. (2020); Yan et al. (2019). To date, unfairness has not been remarked on. This is an accident of dataset construction: the standard base/novel splits in standard datasets do not result in a distribution shift. But other base/novel splits do result in a distribution shift large enough to have notable effects, and Section 3 shows our evidence that this effect occurs in practice. In particular, we describe ARShift benchmarks that simulate the real-world scenario where the aspect ratio distribution shift is severe. RPNs in state-of-the-art few-shot detectors are heavily biased towards familiar aspect ratio distributions, and so have weaker than necessary performance on non-standard splits because their RPNs are unfair. Evaluation practice should focus on performance under hard splits. In few-shot detection applications, a more robust RPN will be more reliable, because applications typically offer no guarantees about the aspect ratio of novel classes. We show how to build a more robust RPN by training multiple RPN classifiers to be specialized but cooperative. Our CoRPN\u2019s can specialize (and a degree of specialization emerges naturally), but our cooperation constraints discourage individual RPN classifiers from overspecializing and so face generalization problems. CoRPN\u2019s are competitive with SOTA on widely used conventional benchmarks of few-shot detection, using conventional splits. But on our ARShift benchmarks with hard splits based on PASCAL VOC, MS-COCO, and LVIS Everingham et al. (2010); Lin et al. (2014); Kang et al. (2019); Wang et al. (2020), they beat SOTA, because they are more robust to shifts in aspect ratio distribution. Our contributions: (1) We show unfairness has severe effects on detector performance, and describe ARShift benchmarks that evaluate these effects. (2) We describe a general approach to improving RPN robustness to distribution shifts. Our CoRPN construction works with many types of few-shot detector. (3) We show that performance improvements resulting from CoRPN\u2019s results from improved fairness. (4) Our CoRPN\u2019s are competitive with SOTA on widely used conventional benchmarks. But on the hard splits in ARShift, they beat SOTA, because they are fair. 2 RELATED WORK: Object Detection with Abundant Data. There are two families of detector architecture, both relying on the fact that one can quite reliably tell whether an image region contains an object independent of category Endres & Hoiem (2010); van de Sande et al. (2011). In serial detection, a proposal process (RPN in what follows) offers the classifier a selection of locations likely to contain objects, and the classifier labels them. This family includes R-CNN and its variants Girshick (2015); Girshick et al. (2014); He et al. (2017); Ren et al. (2015) In parallel detection, there is no explicit proposal step; these methods can be faster but the accuracy may be lower. This family includes YOLO and its variants Bochkovskiy et al. (2020); Redmon & Farhadi (2017); Redmon et al. (2016); Redmon & Farhadi (2018), SSD Liu et al. (2016), point-based detectors such as CornerNet Law & Deng (2018) and ExtremeNet Zhou et al. (2019), and emerging transformer-based methods exemplified by DETR Carion et al. (2020)). This paper identifies an issue with the proposal process that can impede strong performance when there is very little training data (the few-shot case). The effect is described in the context of two-stage detection, but likely occurs in one-stage detection too. Few-Shot Object Detection. Few-shot detection involves detecting objects for which there are very few training examples Chen et al. (2018); Kang et al. (2019); Schwartz et al. (2019), and state-ofthe-art methods are usually serial Wang et al. (2019); Yan et al. (2019); Wang et al. (2020); Fan et al. (2020); Wu et al. (2020); Xiao & Marlet (2020); Yang et al. (2020); Li et al. (2021a); Hu et al. (2021); Zhang et al. (2021); Li et al. (2021b); Zhu et al. (2021). There is a rich few-shot classification literature (roots in Thrun (1998); Fei-Fei et al. (2006)). Dvornik et al. (2019) uses ensemble procedures for few-shot classification. As to detection, TFA Wang et al. (2020) shows that a simple two-stage fine-tuning approach outperforms other complex methods. Much work seeks improvements by applying different techniques, such as meta-learning Wang et al. (2019); Yan et al. (2019); Hu et al. (2021); Zhang et al. (2021), metric learning Han et al. (2021); Wu et al. (2021); Yang et al. (2020), refinement Wu et al. (2020); Li et al. (2021b), feature reweighting Kang et al. (2019), semantic relations Zhu et al. (2021), augmentation Li & Li (2021); Zhang & Wang (2021), and margin loss Li et al. (2021a). Other work (Fan et al. (2021)) alleviates forgetting of base classes. In particular, Qiao et al. (2021) achieves state-of-the-art performance by decoupling the gradient of the backbone and other components of the detector, as well as adding a prototypical calibration module. Here we focus on the two most representative methods \u2013 the state-of-the-art DeFRCN Qiao et al. (2021) and the widely used TFA Wang et al. (2020) \u2013 as our main baselines. Few-Shot Detection Benchmarks. The existing literature can be seen as variations on a standard detection framework, where one splits data into two sets of categories: base classes Cb (which have many training examples) and novel classes Cn (which have few). The RPN and classifier are trained with instances from the base classes, and then fine-tuned with the few-shot novel class data. While the choice of the split can be important in revealing different aspects of few-shot detection, existing benchmarks Kang et al. (2019); Wang et al. (2020) have only focused on a few fixed, rather arbitrary splits. However, we explore the scenario where there exists a notable distribution shift between base and novel classes, and investigate the behavior of RPNs accordingly. Proposal Process in Few-Shot Detection. Relatively little work adjusts the proposal process, which is usually seen as robust to few-shot issues because there are many base examples. Sun et al. (2021) introduces contrastive-aware object proposal encodings to facilitate classification. Attention mechanisms are also introduced that feed category-aware features instead of plain image features into the proposal process Hsieh et al. (2019); Fan et al. (2020); Xiao & Marlet (2020); Osokin et al. (2020), as well as re-ranking proposals based on similarity with query images Hsieh et al. (2019); Fan et al. (2020). Making the RPN category-aware improves the quality of novel class proposals, but at inference time the model suffers from catastrophic forgetting of base categories \u2013 current category-aware features cannot summarize the very large number of base class examples efficiently or accurately. An RPN that is generally well-behaved can still create serious trouble in the few-shot case by missing important proposals for the novel classes during fine-tuning. We show that the proposal process can be improved by a carefully constructed cooperating RPN\u2019s without substantial loss of performance for the base classes. 3 OUR APPROACH: We believe that improving the population of RPN boxes seen by the classifier in training will always tend to improve a detector, and so focus on finding and fixing the effect within a standard few-shot object detection framework. Our proposed strategy is general and can work with different types of few-shot detectors. Here we consider the two most representative methods: the state-of-the-art DeFRCN Qiao et al. (2021) and the widely used TFA Wang et al. (2020). We first observe the box aspect ratio distribution shift problem through our pilot study, and show that na\u0131\u0308ve ensemble of RPN experts does not sufficiently solve this problem on our hard ARShift splits. Then we introduce our CoRPN\u2019s that effectively tackles the aspect ratio distribution shift problem via the cooperation and diversity losses. 3.1 BACKGROUND: We use the few-shot detection setting introduced in Kang et al. (2019). We split the dataset into two sets of categories: base classes Cb and novel classes Cn. As shown in Figure 3, the training process is two-phase: (1) base classes training, and (2) fine-tuning with novel classes. In phase 1, the model is trained with base class instances which results in a |Cb|-way detector. After base classes training, weights for novel classes are randomly initialized, making the classifier a (|Cb| + |Cn|)way classifier. In phase 2, the model is fine-tuned using either a set of few novel class instances or a balanced dataset containing both novel and base classes. The classifier sees the ground truth box and RPN boxes; it is typically trained to regard RPN boxes with IoU\u22650.7 as positive, and with IoU<0.3 as negative. After the fine-tuning phase, we evaluate our model by average precision (AP) on novel and base categories. Although the focus of few-shot detection is the novel classes, since most test images contain instances from both base and novel classes, it is essential to maintain good performance on base classes. We adopt the widely-used Faster R-CNN Ren et al. (2015) as our base model. As shown in Figure 3, Faster R-CNN is a two-stage detector, which consists of a backbone image feature extractor, an RPN, followed by the region of interest (ROI) pooling layer, and a bounding box classifier and a bounding box regressor on top of the model. The RPN determines if a box is a foreground or a background box. Following the RPN is non-maximum suppression (NMS) which ranks and selects top proposal boxes. After passing the ROI pooling layer, the predictor\u2019s head classifies and localizes each box. In phase 1, the whole model is trained on many-shot base class instances. Phase 2 fine-tunes part of the model on novel class instances with other parts frozen. Specifically, for TFA Wang et al. (2020), only the top layer of the bounding box classifier and regressor are fine-tuned. For DeFRCN Qiao et al. (2021), the whole model is fine-tuned except for the convolutions in the bounding box classifier and regressor. 3.2 PILOT STUDY: BOX DISTRIBUTION SHIFT: In the real world, the bounding box distribution of these novel categories often differs from the base categories, resulting in unfair few-shot performances. Namely, the difference in the distribution of box scale, aspect ratio, and center location all inhibit a successful transfer. Previous work tries to alleviate the scale issues with multiscale features and the location issues with translation invariance of convolution. However, these approaches fail to solve all of these problems, especially when the distribution between base and novel class box aspect ratios has a significant shift. We simulate this scenario by proposing new splits: our ARShift benchmark, on the PASCAL VOC, COCO and LVIS datasets that emphasize this distribution shift and the fairness to different aspect ratio distributions. We manually select a set of classes that will likely have a different box distribution to the base categories. Figure 2 shows that our split has a more significant shift in the box aspect ratio distribution. As an na\u0131\u0308ve approach to alleviating this issue, we modified the RPN classifier to be an ensemble of expert RPN classifiers. Instead of using one RPN classifier for all proposals, we use 3 RPN classifiers for the anchors of 3 different aspect ratios (0.5, 1, and 2.0 respectively). The 3 RPN classifiers independently output their prediction for their respective anchors, which are combined as the final prediction. Tables 1, 2 and 3 show that compared to the baseline DeFRCN Qiao et al. (2021), this approach represented by \u2018DeFRCN Ensemble of Experts\u2019 performs comparably and thus cannot fully address the issue. Intuitively, in this ensemble of experts method, individual RPN classifiers might be overspecializing and so facing generalization problems. Instead, we propose a method where we do not explicitly enforce each RPN classifier to specialize in an aspect ratio, but let the specialization emerge in the learning process. This method, named CoRPN\u2019s, shows a large improvement over the baselines in Tables 1, 2 and 3. 3.3 LEARNING COOPERATING RPN\u2019S (CORPN\u2019S): We would like to alter the RPN to improve the population of boxes reported, especially on our ARShift benchmark where novel classes has a large box distribution shift. We expect that doing so affects mainly the few-shot case. We use multiple redundant RPN classifiers, but our goals imply that these RPN classifiers need to be trained to cooperate (i.e., they should not be a pure ensemble of experts). In what follows, we use the term RPN and RPN classifier interchangeably unless otherwise noted. In particular, we train and evaluate our RPN classifiers using an OR strategy \u2013 a box is classified with the label reported by the most confident RPN, which gets the gradient during training. This has two effects. First, the RPN\u2019s can specialize to a degree, though we do not allow the RPN\u2019s to drift too far apart. In turn, if one RPN misses a positive box, the other might find it. Second, the training strategy may improve the variation of proposals, which is especially essential when dealing with a different proposal box distribution in the few-shot case. Both effects may bring improvements to the model\u2019s fairness with respect to aspect ratio distribution. As Figure 3 shows, Faster R-CNN\u2019s RPN consists of a feature extractor, a binary classifier (which decides whether a box is foreground or background), and a bounding box regressor (which is not relevant to our current purpose). We do not intend for our RPN\u2019s to use distinct sets of features, since it would introduce a large number of additional parameters, so we construct redundant classifiers while keeping both the feature extractor and the bounding box regressor shared between all RPN\u2019s. An RPN with a single classifier is trained with a cross-entropy loss Lcls = LCE and produces a single prediction. In our case, we train N different binary classifiers simultaneously, and must determine (1) what prediction is made at test time and (2) what gradient goes to what classifier at training time. At test time, a given box gets the score from the most confident RPN. If the highest foreground probability is closer to one than the highest background probability, the box is predicted to be foreground; otherwise, it is predicted to be the background. In training time, merely taking the gradient of the best RPN score is not good enough, because the model may collapse to the trivial solution where one RPN scores all boxes, and the others do nothing interesting. For any foreground box, we want at least one RPN to have a very confident foreground prediction and all others to have good foreground scores too (so that no foreground box is missed). We use the following strategy. For a specific anchor box i, each RPN j (of the N RPN\u2019s) outputs a raw score rji , indicating if the box is a foreground box or not: ri = [r 1 i , r 2 i , . . . , r N i ]. After applying a sigmoid, the jth RPN produces the foreground probability f ji = \u03c3(r j i ) for anchor box i. We choose the score from the j\u2217th RPN such that j\u2217 = argminj min{f j i , 1\u2212 f j i }, (1) namely the most certain RPN which produces probability closest to the edge of the [0, 1] interval. At training time, only the chosen j\u2217th RPN gets the gradient from anchor box i. The RPN selection procedure is per-box, and even adjacent boxes can pass through different RPN\u2019s. Other than the standard cross-entropy loss, we use two additional loss terms: a diversity loss Ldiv encourages RPN\u2019s to be distinct, and a cooperation loss Lcoop encourages cooperation and suppresses foreground false negatives. The final loss is Lcls := Lj \u2217 CE + \u03bbdLdiv + \u03bbcLcoop, (2) where \u03bbd and \u03bbc are trade-off hyperparameters. 3.4 ENFORCING DIVERSITY: We do not want our RPN\u2019s to be too similar and prefer their specialization. For each positive anchor box, RPN responses should be different because we want different RPN\u2019s to cover different types of proposal boxes. To this end, we propose a loss function to enforce diversity among RPN\u2019s. Given a set of NA anchor boxes, the N RPN\u2019s produce an N by NA matrix of probabilities F = [f1, f2, . . . , fN ]T . The covariance matrix \u03a3(F) is \u03a3(F) = E[(f j \u2212 E[f j ])(fk \u2212 E[fk])T ]. (3) We define the diversity loss Ldiv by the log determinant loss Ldiv := \u2212 log(det(\u03a3(F))). (4) By the diversity loss, we encourage the probability matrix to have rank N , so each RPN is reacting differently on the collection of NA boxes. This procedure ensures each RPN to be the most certain RPN for some boxes, so that every RPN is being selected and trained. Omitting this loss can cause some RPN classifier to receive little training. 3.5 LEARNING TO COOPERATE: We also want the RPN\u2019s to cooperate so that they all agree to a certain extent for foreground boxes. We propose a cooperation loss to prevent any RPN from firmly rejecting any foreground box. For foreground box i, with the jth RPN, we define the cooperation loss Li,jcoop := max{0, \u03d5\u2212 f j i }, (5) where \u03d5 is a constant parameter (usually less than 0.5), acting as a lower bound for each RPN\u2019s probability assigning to a foreground box. If an RPN\u2019s response is below \u03d5, that RPN is going to be penalized. The final cooperation loss is an average of cooperation losses over all foreground boxes and all RPN\u2019s. 4 EXPERIMENTS: Benchmarks. We propose a new base/novel split on both the PASCAL VOC Everingham et al. (2010), MS-COCO Lin et al. (2014) and LVIS Gupta et al. (2019) datasets to simulate the realworld scenario, where the novel class box distribution deviates from the base class counterpart. Our proposed split VOC-ARShift is similar to the conventional few-shot detection VOC split Kang et al. (2019); Wang et al. (2020). We use the images and annotations of VOC (07 + 12) and select 15 classes as base classes, and leave the rest as novel classes. In our proposed COCO-ARShift split, we use the images and annotation of COCO 2014, select the 20 VOC classes as training, and select 10 out of the other 60 classes as novel classes. We select these classes to explicitly produce a distribution shift in the box aspect ratios, as shown in Figure 2. In our LVIS-ARShift benchmark, we use LVIS v0.5 and 10 shots following Wang et al. (2020). In each setting, the base classes are the 20 VOC classes in COCO, while the novel classes are 10 rare classes manually picked that have an aspect ratio distribution shift from the base classes. The detailed classes of our proposed splits are in Section H in the appendix. Apart from our proposed ARShift setting, we also evaluate on two widely-used few-shot detection benchmarks Kang et al. (2019); Wang et al. (2020) based on PASCAL VOC and COCO. For a fair comparison, we use the same train/test splits and novel class instances as in Kang et al. (2019); Wang et al. (2020) to train and evaluate all models. On COCO, we report base/novel classes AP, AP50, and AP75 under shots 1, 2, 3, 5, 10, and 30. On PASCAL VOC, we report AP50 for three different base/novel class splits under shots 1, 2, 3, 5, and 10. Following Wang et al. (2020) and Qiao et al. (2021), we use Faster R-CNN as our base model and use an ImageNet pre-trained Russakovsky et al. (2015) ResNet-101 as the backbone, unless otherwise noted. Training Procedure. Our training and fine-tuning procedures are consistent with previous work TFA Wang et al. (2020) and DeFRCN Qiao et al. (2021). On PASCAL VOC, at phase 1 base classes training, each model is trained on the union set of VOC 07+12 trainval data. Evaluation is on the VOC 07 test set. At the fine-tuning phase, each model is fine-tuned with a balanced few-shot dataset sampled from VOC 07+12 that contains both base classes and novel classes. On COCO, following Wang et al. (2020), the fine-tuning phase is two-stage: at stage 1, we fine-tune the model on novel classes; at stage 2, we then fine-tune the model with a balanced few-shot dataset containing both base and novel classes. Please refer to Section C of the appendix for our implementation details and hyperparameters. Baselines and Evaluation Procedure. We mainly focus on comparing against the state-of-the-art baseline DeFRCN Qiao et al. (2021), and a widely-used previous work TFA Wang et al. (2020). Our approach incorporates CoRPN\u2019s into the baseline models, while keeping other model components and design choices unchanged. In addition, we thoroughly compare with a variety of recent few-shot detectors, including FSOD Fan et al. (2020), MPSR Wu et al. (2020), FSDetView Xiao & Marlet (2020). These baselines address other aspects of few-shot detection which are different from us (Section 2), and their modifications are thus largely orthogonal to our effort here. Note that our evaluation follows the standard procedure in Wang et al. (2020). This standard procedure computes AP separately for novel and base categories for a detector that is engineered to detect both novel and base classes ((|Cb|+ |Cn|)-way). We focus on the novel class performance, and also report the base class performance in Table 4. For work Fan et al. (2020) with different evaluation procedures, we re-evaluate their methods with the standard procedure, so that results in Tables 4 can be different from the original reported results. 4.1 MAIN RESULTS: Our evaluation mainly focuses on our proposed ARShift splits, but also includes the conventional splits. Also, we focus on the extremely few-shot regime, which is the most challenging scenario for few-shot detection. Tables 1, 2 and 3 show the detection performance on our proposed ARShift splits where a bounding box aspect ratio distribution shift is present between base and novel classes. Table 4 summarize the detection results for base and novel classes in low shots on the conventional COCO benchmark, respectively. For completeness, the results for base and novel classes in higher shots on PASCAL VOC and COCO are summarized in Section B of the appendix, where our model also performs comparably. CoRPN\u2019s consistently outperform the baselines. Tables 1, 2 and 3 show that CoRPN\u2019s greatly outperform the baseline TFA Wang et al. (2020), DeFRCN Qiao et al. (2021) and an aspect ratio ensemble modified from the DeFRCN model, especially in very low shots. Especially, we provide the results on three additional base and novel class splits on the LVIS dataset Gupta et al. (2019) in Table 3. LVIS is a much more challenging long-tail recognition dataset, containing a large amount of rare classes, hence the fairness for aspect ratio is more crucial. We also provide the results on all rare classes in the LVIS test set as a reference. Our CoRPN\u2019s outperform the state-of-the-art DeFRCN baseline by large margins on all the splits with aspect ratio distribution shift, especially in AP75, suggesting that CoRPN\u2019s improve the quality of detection in such scenarios. CoRPN\u2019s also marginally outperform the DeFRCN baseline on the entire set of rare classes in mAP and AP75 on LVIS. On the conventional splits, as shown in Tables 4, CoRPN\u2019s consistently improve over TFA for all shots, and also marginally outperform DeFRCN on the challenging COCO dataset. The combination of both results shows a significant improvement in aspect ratio distribution fairness in our model. CoRPN\u2019s beat other state of the art. With our simple modification on RPN, we also outperform other sophisticated approaches in the very low-shot regime on the more challenging COCO dataset. In particular, we significantly outperform baselines that introduce attention mechanisms for adjusting proposal generation Hsieh et al. (2019); Fan et al. (2020) under the standard evaluation procedure. We believe CoRPN\u2019s could be combined with other approaches with improvements from different perspectives, such as exploiting better multi-scale representation Wu et al. (2020), incorporating metric learning Yang et al. (2020), or adding feature aggregation module Xiao & Marlet (2020) for further improvements. CoRPN\u2019s don\u2019t forget base classes. While improving detection on novel classes through finetuning, we maintain strong performance on base classes \u2013 there is no catastrophic forgetting (Table 4). By contrast, the base class performance of some state-of-the-art baselines dramatically drops, demonstrating that they cannot fairly detect novel and base classes. 4.2 ABLATION STUDY: We investigate how the proposals of CoRPN\u2019s change and conduct a series of ablations that evaluate the contribution of each loss component and different design choices. Specifically, we find that: (1) CoRPN\u2019s specialize in different aspect ratios without explicit supervision; (2) Our cooperation loss and diversity loss are both necessary for CoRPN\u2019s to improve fairness; (3) (in Section F of the appendix) CoRPN\u2019s outperform other baselines such as with larger RPN sub-networks, an existing cosine loss based diversity, and bootstrapping. Specialization for aspect ratios emerges in CoRPN\u2019s training. Table 5 shows that the boxes of three different aspect ratios are handled by different RPN classifiers in CoRPN\u2019s. Instead of explicitly training different RPN classifiers to handle different aspect ratios, CoRPN\u2019s learn a more flexible specialization, improving the performance. CoRPN\u2019s need both diversity and cooperation losses. Table 6 shows that after removing either loss, CoRPN\u2019s does not improve the performance over the baseline. Also, when the threshold hyperparameter is suboptimal, the performance surpasses the baseline but still substantially underperforms the CoRPN\u2019s with the optimal hyperparameter. 5 CONCLUSION: We identify the bias of few-shot detectors towards familiar aspect ratio distribution. As illustrated in our ARShift benchmark, a substantial improvement on under-represented aspect ratio distribution can be obtained by our proposed CoRPN\u2019s which produce more informative proposals. Our method achieves a new state of the art on both our proposed settings with hard base and novel splits and widely-used benchmarks in the very few-shot regime. This is achieved by training CoRPN\u2019s with diversity and cooperation losses. A APPENDIX: This appendix provides additional experimental results and details that support the approach in the main paper and are not included there due to limited space. The seven sections include (1) additional results for higher-shots on the COCO-ARShift, comparisons with additional baselines for ARShift, and results on base classes before and after finetuning; (2) explainations for additional evaluation and experimental details; (3) discussion of the training and inference time and memory; (4) results on conventional splits; (5) analysis with additional ablation study; (6) addtional qualitative results; and (7) details of the proposed base and novel class splits on ARShift for PASCAL VOC, COCO, and LVIS. B ADDITIONAL RESULTS: Higher-Shot Results on COCO-ARShift In Table 2 of the main paper, we show that CoRPN\u2019s outperform the DeFRCN Qiao et al. (2021) baseline consistently on 1, 2, and 3 shots. Table 8 shows that this performance improvement persists in 5, 10, and 30 shots. In this scenario where more support instances are available, CoRPN\u2019s consistently outperform the DeFRCN Qiao et al. (2021) baseline. Additional Baseline on ARShift In Table 1 of the main paper, we mainly compare our method against the state-of-the-art method DeFRCN Qiao et al. (2021) on our VOC-ARShift. In Table 9 we also evaluate an additional baseline FSCE Sun et al. (2021). Note that other recently published methods represented by FSCE underperform our DeFRCN baseline by significant margins on our ARShift splits as well, so we do not include these other methods in our main paper. Results on Base classes Here we provide the detection results on base classes after base classes training (stage 1) and after fine-tuning (stage 2). As shown in Table 7, the performance of our CoRPN\u2019s + DeFRCN on base classes is comparable with DeFRCN Qiao et al. (2021), while we achieve large improvements on novel test classes as shown in Table 1 of the main paper. After fine-tuning, our CoRPN\u2019s also do not forget base classes. Table 7 shows that the performance of our CoRPN\u2019s + DeFRCN after finetuning is still comparable with the baseline. C IMPLEMENTATION AND EVALUATION DETAILS Implementation Details and Hyperparameters. For ease of comparison, we use the same values for all shared training and fine-tuning hyperparameters (batch size, learning rate, momentum, weight decay, etc.) as the baselines Wang et al. (2020) and Qiao et al. (2021). CoRPN\u2019s have the following additional hyperparameters: the number of RPN\u2019s, the cooperation loss threshold \u03d5, the diversity loss trade-off \u03bbd, and the cooperation loss trade-off \u03bbc. For COCO and LVIS, we directly used hyperparameter sets that worked well on PASCAL VOC. In Table 4, we report CoRPN\u2019s detection results. We find that hyperparameters selected from PASCAL VOC are generalizable to the more challenging COCO and LVIS benchmark. Results reported in Table 4 are obtained with 5 RPNs, \u03d5 = 0.3, \u03bbc = 1, \u03bbd = 0.025 for TFAWang et al. (2020), and \u03bbc = 2, \u03bbd = 0.05 for DeFRCN Qiao et al. (2021). Selection Procedure \u2013 Cumulative Variance. We summarized the hyperparameter selection criteria for PASCAL VOC in the experiment section in the main paper. The second criterion is the cumulative variance in the RPN\u2019s response matrix to foreground boxes. Specifically, given a set of M anchor boxes, the N RPN\u2019s produce an N by M matrix of probabilities F = [f1, f2, . . . , fN ]T . We run a principal component analysis (PCA) on F with N components and compare the cumulative percentage of variance explained by each component. We would like the variance to be distributed across components. Evaluation. As mentioned in the main paper, for a fair comparison, we use the standard evaluation procedure for all the compared models. We also compare against other approaches with the same novel class instances and test images. Authors of methods compared in this submission have helped us ensure the performance we report is a proper reflection of their methods, and we will acknowledge properly in any final version. In the standard evaluation procedure, when a test image comes in, the model has no assumption on what category the image contains Wang et al. (2020). The detector\u2019s classifier is (|Cb|+|Cn|)-way, detecting objects from a joint space of both base and novel categories. In the main paper, we marked results with * if they were re-evaluated under the standard procedure, and with ** if the original work used the standard procedure, but the results were not reported and so they were evaluated by us. Specifically, below we include the details on how we obtained the results (with special marks) in the main paper; other results (without special marks) Wang et al. (2020); Pe\u0301rez-Ru\u0301a et al. (2020); Yang et al. (2020); Sun et al. (2021); Li et al. (2021a); Zhu et al. (2021) including the concurrent work Sun et al. (2021); Li et al. (2021a); Zhu et al. (2021) are from the original papers. \u2022 We fine-tuned and evaluated MPSR using the publicly released code and the pre-trained detection model for base classes Wu et al. (2020). \u2022 We re-evaluated FSOD Fan et al. (2020) and CoAE Hsieh et al. (2019) under the standard procedure, using the publicly released code and the pre-trained model Fan et al. (2020); Hsieh et al. (2019). FSOD uses a class-agnostic 2-way classifier that determines if an object is foreground or background. At inference time, FSOD produces a balanced number of proposals per novel category and collects these proposals for NMS. We adapt FSOD under the standard procedure such that there are a balanced number of proposals for all base and novel categories. For a fair comparison, we also fine-tuned FSOD with the same novel category instance(s) as in TFA Wang et al. (2020). \u2022 We re-evaluated CoAE under the standard evaluation, using the publicly released code and a pre-trained model Hsieh et al. (2019). For each test image containing a certain category, CoAE samples support image(s) from this category and collects boxes based on the support image(s). At inference time, instead of providing each test image with support feature(s) from this category, we provide each test image support feature(s) from all base and novel categories. We then collect boxes from all categories and evaluate them. For a fair comparison, we also fine-tuned CoAE with the same novel category instance(s) as in TFA Wang et al. (2020). D TRAINING & INFERENCE TIME AND MEMORY: The only architectural difference between CoRPN\u2019s and the baseline RPNs of TFA Wang et al. (2020) and DeFRCNQiao et al. (2021) is that CoRPN\u2019s have multiple RPN classifiers. Note that we only duplicate the RPN classifiers, but not the entire RPN. In the baselines, the RPN\u2019s classifier is a 1\u00d71 convolutional layer, with input channels as the number of feature channels (256) and output channels as the number of cell anchors (3). Compared with the baselines, CoRPN\u2019s with 5 RPN\u2019s have four additional RPN classifiers and thus consist of 256\u00d712 additional parameters. In our experiments, we find that CoRPN\u2019s with 5 RPN\u2019s increase the training time by only 3%, with roughly the same inference time and same memory footprint, compared with the baselines. E RESULTS ON CONVENTIONAL SPLITS: In Table 4 of the main paper, we show that CoRPN\u2019s perform comparably or even better on conventional splits on 1, 2, and 3 shots on COCO. In this section we present more conventional split results. Table 10 shows PASCAL VOC conventional split results where our CoRPN\u2019s perform comparably with the baselines. Table 11 shows the results on COCO 5, 10, and 30 shots, where our method also obtains similar performance to the baseline. F ADDITIONAL ANALYSIS: We present some additional ablation studies for our CoRPN\u2019s. Note that these ablations are performed on the conventional split. Even on conventional splits, our CoRPN\u2019s outperform these naive strategies. Our CoRPN\u2019s will likely achieve more performance improvement on our ARShift splits. Bootstrapping. Table 1 in the main paper shows that our CoRPN\u2019s outperform naive ensembles. Here we further compare CoRPN\u2019s with a bootstrapping baseline in Table 12. We construct the bootstrapping baseline by using multiple RPN classifiers, the number of which is the same as CoRPN\u2019s. Instead of selecting the most confident RPN to get gradients, we randomly select an RPN to get gradients during training. There are no additional loss terms in training these RPN classifiers. In the fine-tuning stage and the inference time, we use the same selection procedure as CoRPN\u2019s (i.e., using the most certain RPN). Diversity loss in Dvornik et al. (2019). In Table 12, we also compare our CoRPN\u2019s with Dvornik et al. (2019), which utilizes a pairwise cosine similarity based diversity loss. Our CoRPN\u2019s also outperform this baseline with a considerable margin. Larger RPN. We compare CoRPN\u2019s with a baseline with larger RPN sub-networks in Table 13. We find that using larger RPN sub-networks does not improve performance, suggesting that the advantage of CoRPN\u2019s is not simply the result of using more parameters. In CoRPN\u2019s, all RPN classifiers share the same RPN feature extractor, as shown in Figure 4 (main paper). We enlarge the feature dimension in the RPN. We implemented two options: a large RPN where the RPN feature extractor\u2019s output channels increase from 256 to 272, and a larger RPN where the output channels double to 512. We also modified the RPN classifier and bounding box regressor to take in larger features for both options. Table 13 shows that simply enlarging the model capacity and the anchor density of the original RPN cannot improve the few-shot detection performance. G ADDITIONAL QUALITATIVE RESULTS: In Figure 4 we show some additional qualitative result of our CoRPN\u2019s model on COCO. Notably, our model could successfully discover novel objects omitted by the baseline, and also successfully classify some novel objects that cause confusion for the baseline method. H DATA SPLITS: PASCAL VOC Split. For our proposed PASCAL VOC-ARShift split, the base classes include \u201cbicycle\u201d, \u201cboat\u201d, \u201ccar\u201d, \u201ccat\u201d, \u201cchair\u201d, \u201cdiningtable\u201d, \u201cdog\u201d, \u201cperson\u201d, \u201csheep\u201d, \u201ctvmonitor\u201d, \u201cbird\u201d, \u201cpottedplant\u201d, \u201ccow\u201d, \u201cmotorbike\u201d, and \u201csofa\u201d; the novel classes include \u201ctrain\u201d, \u201cbottle\u201d, \u201caeroplane\u201d, \u201chorse\u201d, and \u201cbus\u201d. COCO Split. For our proposed COCO-ARShift split, the base classes include the 20 VOC classes in COCO; the novel classes include \u201chot dog\u201d, \u201ctennis racket\u201d, \u201cfire hydrant\u201d, \u201claptop\u201d, \u201csuitcase\u201d, \u201cfrisbee\u201d, \u201cteddy bear\u201d, \u201cbowl\u201d, \u201ckite\u201d, and \u201celephant\u201d. LVIS Splits. For our proposed LVIS-ARShift splits, the base classes include the 20 VOC classes in LVIS; the novel classes of the first split include \u201cLoafer (type of shoe)\u201d, \u201cbatter (food)\u201d, \u201ccabin car\u201d, \u201ccylinder\u201d, \u201cegg roll\u201d, \u201cliquor\u201d, \u201cnailfile\u201d, \u201cplow (farm equipment)\u201d, \u201cvinegar\u201d, and \u201cyoke (animal equipment)\u201d; the novel classes of the second split include \u201cbroach\u201d, \u201cburrito\u201d, \u201ccargo ship\u201d, \u201ccrayon\u201d, \u201cincense\u201d, \u201cpeeler (tool for fruit and vegetables)\u201d, \u201cpin (non jewelry)\u201d, \u201croller skate\u201d, \u201ctinsel\u201d, and \u201cvodka\u201d; the novel classes of the third split include \u201cax\u201d, \u201cbeaker\u201d, \u201cferry\u201d, \u201cfish (food)\u201d, \u201cfunnel\u201d, \u201cincense\u201d, \u201cneedle\u201d, \u201cspace shuttle\u201d, \u201cstepladder\u201d, and \u201cvulture\u201d."}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={}, name='GetBudget'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Budget retrieved successfully\",\n  \"output\": {\n    \"total_resource_budget\": 100,\n    \"current_resource_usage\": 0,\n    \"current_remaining_resource_budget\": 100,\n    \"total_expense_budget\": 10000,\n    \"current_expense\": 0.09222870000000001,\n    \"current_remaining_expense_budget\": 9999.9077713\n  }\n}\n```\n", "metadata": {"title": "Invoking `GetBudget` with \n```json\n{}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='GetBudget', response={'result': {'status': 'success', 'message': 'Budget retrieved successfully', 'output': {'total_resource_budget': 100, 'current_resource_usage': 0, 'current_remaining_resource_budget': 100, 'total_expense_budget': 10000, 'current_expense': 0.09222870000000001, 'current_remaining_expense_budget': 9999.9077713}}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "Okay, I will proceed with reviewing the paper.\n\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'query': 'ICLR 2023 acceptance rate', 'website': 'https://iclr.cc/'}, name='GoogleSearchTool'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Search completed successfully\",\n  \"output\": [\n    \"https://media.iclr.cc/Conferences/ICLR2023/ICLR2023-Fact_Sheet.pdf\",\n    \"https://media.iclr.cc/Conferences/ICLR2024/ICLR2024-Fact_Sheet.pdf\",\n    \"https://blog.iclr.cc/2022/12/21/announcing-the-accepted-workshops-at-iclr-2023/\",\n    \"https://blog.iclr.cc/2023/11/02/tiny-papers-strike-back-2023-reflections-and-2024-announcement/\",\n    \"https://iclr.cc/virtual/2023/papers.html\",\n    \"https://media.iclr.cc/Conferences/ICLR2025/ICLR2025_Fact_Sheet.pdf\",\n    \"https://media.iclr.cc/Conferences/ICLR2024/ICLR2024_Press_Release.pdf\",\n    \"https://iclr.cc/\",\n    \"https://www.iclr.cc/media/Press/ICLR_2023_Press_Release.pdf\",\n    \"https://iclr.cc/Conferences/2023/ReviewerGuide\"\n  ]\n}\n```\n", "metadata": {"title": "Invoking `GoogleSearchTool` with \n```json\n{\n  \"query\": \"ICLR 2023 acceptance rate\",\n  \"website\": \"https://iclr.cc/\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='GoogleSearchTool', response={'result': {'status': 'success', 'message': 'Search completed successfully', 'output': ['https://media.iclr.cc/Conferences/ICLR2023/ICLR2023-Fact_Sheet.pdf', 'https://media.iclr.cc/Conferences/ICLR2024/ICLR2024-Fact_Sheet.pdf', 'https://blog.iclr.cc/2022/12/21/announcing-the-accepted-workshops-at-iclr-2023/', 'https://blog.iclr.cc/2023/11/02/tiny-papers-strike-back-2023-reflections-and-2024-announcement/', 'https://iclr.cc/virtual/2023/papers.html', 'https://media.iclr.cc/Conferences/ICLR2025/ICLR2025_Fact_Sheet.pdf', 'https://media.iclr.cc/Conferences/ICLR2024/ICLR2024_Press_Release.pdf', 'https://iclr.cc/', 'https://www.iclr.cc/media/Press/ICLR_2023_Press_Release.pdf', 'https://iclr.cc/Conferences/2023/ReviewerGuide']}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'url': 'https://media.iclr.cc/Conferences/ICLR2023/ICLR2023-Fact_Sheet.pdf', 'output_type': 'summary'}, name='GetWebsite'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Search completed successfully\",\n  \"output\": \"Lv99  GpM tQ4  9Zil  b9G4My76g a jte88kc9N.m2dbOf N LXKsc3icLVSpGZ b  wc Jyh06IeU DbtNs69758 0ZrlQiLXbh0 RHHZFccU 9ZnGzu0HGxCBbENJUQUXnqvcR6FVVVu.vTYll5Z5jsJbS3.. IRQe.lxLJFn7 vFLNgDGuTV0ziV lEH Tu 3v QHWYYri  ja 5 OG6L6AtK 1gWSLy A Xb0mVTluuLo5INOhT  6WNrlB2TF X  dvJTEu.. TNJ6IeaFyn2 2T lI6FL2E h 40XhczwoCTO 04c 5FA xb hT BnAO8Sh sr896VAoah005S   L   dG3x0j j   K998P ..\"\n}\n```\n", "metadata": {"title": "Invoking `GetWebsite` with \n```json\n{\n  \"url\": \"https://media.iclr.cc/Conferences/ICLR2023/ICLR2023-Fact_Sheet.pdf\",\n  \"output_type\": \"summary\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='GetWebsite', response={'result': {'status': 'success', 'message': 'Search completed successfully', 'output': 'Lv99  GpM tQ4  9Zil  b9G4My76g a jte88kc9N.m2dbOf N LXKsc3icLVSpGZ b  wc Jyh06IeU DbtNs69758 0ZrlQiLXbh0 RHHZFccU 9ZnGzu0HGxCBbENJUQUXnqvcR6FVVVu.vTYll5Z5jsJbS3.. IRQe.lxLJFn7 vFLNgDGuTV0ziV lEH Tu 3v QHWYYri  ja 5 OG6L6AtK 1gWSLy A Xb0mVTluuLo5INOhT  6WNrlB2TF X  dvJTEu.. TNJ6IeaFyn2 2T lI6FL2E h 40XhczwoCTO 04c 5FA xb hT BnAO8Sh sr896VAoah005S   L   dG3x0j j   K998P ..'}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'query': 'Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s'}, name='ArxivTool'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Found 5 paper(s) on arXiv\",\n  \"output\": [\n    {\n      \"title\": \"Fairness Aware Reinforcement Learning via Proximal Policy Optimization\",\n      \"authors\": [\n        \"Gabriele La Malfa\",\n        \"Jie M. Zhang\",\n        \"Michael Luck\",\n        \"Elizabeth Black\"\n      ],\n      \"published\": \"2025-02-06T10:45:55+00:00\",\n      \"summary\": \"Fairness in multi-agent systems (MAS) focuses on equitable reward\\ndistribution among agents in scenarios involving sensitive attributes such as\\nrace, gender, or socioeconomic status. This paper introduces fairness in\\nProximal Policy Optimization (PPO) with a penalty term derived from demographic\\nparity, counterfactual fairness, and conditional statistical parity. The\\nproposed method balances reward maximisation with fairness by integrating two\\npenalty components: a retrospective component that minimises disparities in\\npast outcomes and a prospective component that ensures fairness in future\\ndecision-making. We evaluate our approach in the Allelopathic Harvest game, a\\ncooperative and competitive MAS focused on resource collection, where some\\nagents possess a sensitive attribute. Experiments demonstrate that fair-PPO\\nachieves fairer policies across all fairness metrics than classic PPO. Fairness\\ncomes at the cost of reduced rewards, namely the Price of Fairness, although\\nagents with and without the sensitive attribute renounce comparable amounts of\\nrewards. Additionally, the retrospective and prospective penalties effectively\\nchange the agents' behaviour and improve fairness. These findings underscore\\nthe potential of fair-PPO to address fairness challenges in MAS.\",\n      \"pdf_url\": \"http://arxiv.org/pdf/2502.03953v1\"\n    },\n    {\n      \"title\": \"A Review of Uncertainty Calibration in Pretrained Object Detectors\",\n      \"authors\": [\n        \"Denis Huseljic\",\n        \"Marek Herde\",\n        \"Mehmet Muejde\",\n        \"Bernhard Sick\"\n      ],\n      \"published\": \"2022-10-06T14:06:36+00:00\",\n      \"summary\": \"In the field of deep learning based computer vision, the development of deep\\nobject detection has led to unique paradigms (e.g., two-stage or set-based) and\\narchitectures (e.g., Faster-RCNN or DETR) which enable outstanding performance\\non challenging benchmark datasets. Despite this, the trained object detectors\\ntypically do not reliably assess uncertainty regarding their own knowledge, and\\nthe quality of their probabilistic predictions is usually poor. As these are\\noften used to make subsequent decisions, such inaccurate probabilistic\\npredictions must be avoided. In this work, we investigate the uncertainty\\ncalibration properties of different pretrained object detection architectures\\nin a multi-class setting. We propose a framework to ensure a fair, unbiased,\\nand repeatable evaluation and conduct detailed analyses assessing the\\ncalibration under distributional changes (e.g., distributional shift and\\napplication to out-of-distribution data). Furthermore, by investigating the\\ninfluence of different detector paradigms, post-processing steps, and suitable\\nchoices of metrics, we deliver novel insights into why poor detector\\ncalibration emerges. Based on these insights, we are able to improve the\\ncalibration of a detector by simply finetuning its last layer.\",\n      \"pdf_url\": \"http://arxiv.org/pdf/2210.02935v1\"\n    },\n    {\n      \"title\": \"Strategies for Pretraining Neural Operators\",\n      \"authors\": [\n        \"Anthony Zhou\",\n        \"Cooper Lorsung\",\n        \"AmirPouya Hemmasian\",\n        \"Amir Barati Farimani\"\n      ],\n      \"published\": \"2024-06-12T17:56:46+00:00\",\n      \"summary\": \"Pretraining for partial differential equation (PDE) modeling has recently\\nshown promise in scaling neural operators across datasets to improve\\ngeneralizability and performance. Despite these advances, our understanding of\\nhow pretraining affects neural operators is still limited; studies generally\\npropose tailored architectures and datasets that make it challenging to compare\\nor examine different pretraining frameworks. To address this, we compare\\nvarious pretraining methods without optimizing architecture choices to\\ncharacterize pretraining dynamics on different models and datasets as well as\\nto understand its scaling and generalization behavior. We find that pretraining\\nis highly dependent on model and dataset choices, but in general transfer\\nlearning or physics-based pretraining strategies work best. In addition,\\npretraining performance can be further improved by using data augmentations.\\nLastly, pretraining can be additionally beneficial when fine-tuning in scarce\\ndata regimes or when generalizing to downstream data similar to the pretraining\\ndistribution. Through providing insights into pretraining neural operators for\\nphysics prediction, we hope to motivate future work in developing and\\nevaluating pretraining methods for PDEs.\",\n      \"pdf_url\": \"http://arxiv.org/pdf/2406.08473v2\"\n    },\n    {\n      \"title\": \"On the Maximal Local Disparity of Fairness-Aware Classifiers\",\n      \"authors\": [\n        \"Jinqiu Jin\",\n        \"Haoxuan Li\",\n        \"Fuli Feng\"\n      ],\n      \"published\": \"2024-06-05T13:35:48+00:00\",\n      \"summary\": \"Fairness has become a crucial aspect in the development of trustworthy\\nmachine learning algorithms. Current fairness metrics to measure the violation\\nof demographic parity have the following drawbacks: (i) the average difference\\nof model predictions on two groups cannot reflect their distribution disparity,\\nand (ii) the overall calculation along all possible predictions conceals the\\nextreme local disparity at or around certain predictions. In this work, we\\npropose a novel fairness metric called Maximal Cumulative ratio Disparity along\\nvarying Predictions' neighborhood (MCDP), for measuring the maximal local\\ndisparity of the fairness-aware classifiers. To accurately and efficiently\\ncalculate the MCDP, we develop a provably exact and an approximate calculation\\nalgorithm that greatly reduces the computational complexity with low estimation\\nerror. We further propose a bi-level optimization algorithm using a\\ndifferentiable approximation of the MCDP for improving the algorithmic\\nfairness. Extensive experiments on both tabular and image datasets validate\\nthat our fair training algorithm can achieve superior fairness-accuracy\\ntrade-offs.\",\n      \"pdf_url\": \"http://arxiv.org/pdf/2406.03255v1\"\n    },\n    {\n      \"title\": \"A Mood Value for Fair Resource Allocations\",\n      \"authors\": [\n        \"Francesca Fossati\",\n        \"Stefano Moretti\",\n        \"Stefano Secci\"\n      ],\n      \"published\": \"2017-01-27T10:02:13+00:00\",\n      \"summary\": \"In networking and computing, resource allocation is typically addressed using\\nclassical sharing protocols as, for instance, the proportional division rule,\\nthe max-min fair allocation , or other solutions inspired by cooperative game\\ntheory. In this paper, we argue that, describing the resource allocation\\nproblem as a cooperative game, such classical resource allocation approaches,\\nas well as associated notions of fairness, show important limitations. We\\nidentify in the individual satisfaction rate the key aspect of the challenge of\\ndefining a new notion of fairness and, consequently, a resource allocation\\nalgorithm more appropriate for the cooperative context. We generalize the\\nconcept of user satisfaction considering the set of admissible solutions for\\nbankruptcy games. We adapt the Jain's fairness index to include the new user\\nsatisfaction rate. Accordingly, we propose a new allocation rule we call 'Mood\\nValue'. For each user it equalizes our novel game-theoretic definition of user\\nsatisfaction with respect to a distribution of the resource. We test the mood\\nvalue and the new fairness index through extensive simulations showing how they\\nbetter support the fairness analysis.\",\n      \"pdf_url\": \"http://arxiv.org/pdf/1701.07991v2\"\n    }\n  ]\n}\n```\n", "metadata": {"title": "Invoking `ArxivTool` with \n```json\n{\n  \"query\": \"Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='ArxivTool', response={'result': {'status': 'success', 'message': 'Found 5 paper(s) on arXiv', 'output': [{'title': 'Fairness Aware Reinforcement Learning via Proximal Policy Optimization', 'authors': ['Gabriele La Malfa', 'Jie M. Zhang', 'Michael Luck', 'Elizabeth Black'], 'published': '2025-02-06T10:45:55+00:00', 'summary': \"Fairness in multi-agent systems (MAS) focuses on equitable reward\\ndistribution among agents in scenarios involving sensitive attributes such as\\nrace, gender, or socioeconomic status. This paper introduces fairness in\\nProximal Policy Optimization (PPO) with a penalty term derived from demographic\\nparity, counterfactual fairness, and conditional statistical parity. The\\nproposed method balances reward maximisation with fairness by integrating two\\npenalty components: a retrospective component that minimises disparities in\\npast outcomes and a prospective component that ensures fairness in future\\ndecision-making. We evaluate our approach in the Allelopathic Harvest game, a\\ncooperative and competitive MAS focused on resource collection, where some\\nagents possess a sensitive attribute. Experiments demonstrate that fair-PPO\\nachieves fairer policies across all fairness metrics than classic PPO. Fairness\\ncomes at the cost of reduced rewards, namely the Price of Fairness, although\\nagents with and without the sensitive attribute renounce comparable amounts of\\nrewards. Additionally, the retrospective and prospective penalties effectively\\nchange the agents' behaviour and improve fairness. These findings underscore\\nthe potential of fair-PPO to address fairness challenges in MAS.\", 'pdf_url': 'http://arxiv.org/pdf/2502.03953v1'}, {'title': 'A Review of Uncertainty Calibration in Pretrained Object Detectors', 'authors': ['Denis Huseljic', 'Marek Herde', 'Mehmet Muejde', 'Bernhard Sick'], 'published': '2022-10-06T14:06:36+00:00', 'summary': 'In the field of deep learning based computer vision, the development of deep\\nobject detection has led to unique paradigms (e.g., two-stage or set-based) and\\narchitectures (e.g., Faster-RCNN or DETR) which enable outstanding performance\\non challenging benchmark datasets. Despite this, the trained object detectors\\ntypically do not reliably assess uncertainty regarding their own knowledge, and\\nthe quality of their probabilistic predictions is usually poor. As these are\\noften used to make subsequent decisions, such inaccurate probabilistic\\npredictions must be avoided. In this work, we investigate the uncertainty\\ncalibration properties of different pretrained object detection architectures\\nin a multi-class setting. We propose a framework to ensure a fair, unbiased,\\nand repeatable evaluation and conduct detailed analyses assessing the\\ncalibration under distributional changes (e.g., distributional shift and\\napplication to out-of-distribution data). Furthermore, by investigating the\\ninfluence of different detector paradigms, post-processing steps, and suitable\\nchoices of metrics, we deliver novel insights into why poor detector\\ncalibration emerges. Based on these insights, we are able to improve the\\ncalibration of a detector by simply finetuning its last layer.', 'pdf_url': 'http://arxiv.org/pdf/2210.02935v1'}, {'title': 'Strategies for Pretraining Neural Operators', 'authors': ['Anthony Zhou', 'Cooper Lorsung', 'AmirPouya Hemmasian', 'Amir Barati Farimani'], 'published': '2024-06-12T17:56:46+00:00', 'summary': 'Pretraining for partial differential equation (PDE) modeling has recently\\nshown promise in scaling neural operators across datasets to improve\\ngeneralizability and performance. Despite these advances, our understanding of\\nhow pretraining affects neural operators is still limited; studies generally\\npropose tailored architectures and datasets that make it challenging to compare\\nor examine different pretraining frameworks. To address this, we compare\\nvarious pretraining methods without optimizing architecture choices to\\ncharacterize pretraining dynamics on different models and datasets as well as\\nto understand its scaling and generalization behavior. We find that pretraining\\nis highly dependent on model and dataset choices, but in general transfer\\nlearning or physics-based pretraining strategies work best. In addition,\\npretraining performance can be further improved by using data augmentations.\\nLastly, pretraining can be additionally beneficial when fine-tuning in scarce\\ndata regimes or when generalizing to downstream data similar to the pretraining\\ndistribution. Through providing insights into pretraining neural operators for\\nphysics prediction, we hope to motivate future work in developing and\\nevaluating pretraining methods for PDEs.', 'pdf_url': 'http://arxiv.org/pdf/2406.08473v2'}, {'title': 'On the Maximal Local Disparity of Fairness-Aware Classifiers', 'authors': ['Jinqiu Jin', 'Haoxuan Li', 'Fuli Feng'], 'published': '2024-06-05T13:35:48+00:00', 'summary': \"Fairness has become a crucial aspect in the development of trustworthy\\nmachine learning algorithms. Current fairness metrics to measure the violation\\nof demographic parity have the following drawbacks: (i) the average difference\\nof model predictions on two groups cannot reflect their distribution disparity,\\nand (ii) the overall calculation along all possible predictions conceals the\\nextreme local disparity at or around certain predictions. In this work, we\\npropose a novel fairness metric called Maximal Cumulative ratio Disparity along\\nvarying Predictions' neighborhood (MCDP), for measuring the maximal local\\ndisparity of the fairness-aware classifiers. To accurately and efficiently\\ncalculate the MCDP, we develop a provably exact and an approximate calculation\\nalgorithm that greatly reduces the computational complexity with low estimation\\nerror. We further propose a bi-level optimization algorithm using a\\ndifferentiable approximation of the MCDP for improving the algorithmic\\nfairness. Extensive experiments on both tabular and image datasets validate\\nthat our fair training algorithm can achieve superior fairness-accuracy\\ntrade-offs.\", 'pdf_url': 'http://arxiv.org/pdf/2406.03255v1'}, {'title': 'A Mood Value for Fair Resource Allocations', 'authors': ['Francesca Fossati', 'Stefano Moretti', 'Stefano Secci'], 'published': '2017-01-27T10:02:13+00:00', 'summary': \"In networking and computing, resource allocation is typically addressed using\\nclassical sharing protocols as, for instance, the proportional division rule,\\nthe max-min fair allocation , or other solutions inspired by cooperative game\\ntheory. In this paper, we argue that, describing the resource allocation\\nproblem as a cooperative game, such classical resource allocation approaches,\\nas well as associated notions of fairness, show important limitations. We\\nidentify in the individual satisfaction rate the key aspect of the challenge of\\ndefining a new notion of fairness and, consequently, a resource allocation\\nalgorithm more appropriate for the cooperative context. We generalize the\\nconcept of user satisfaction considering the set of admissible solutions for\\nbankruptcy games. We adapt the Jain's fairness index to include the new user\\nsatisfaction rate. Accordingly, we propose a new allocation rule we call 'Mood\\nValue'. For each user it equalizes our novel game-theoretic definition of user\\nsatisfaction with respect to a distribution of the resource. We test the mood\\nvalue and the new fairness index through extensive simulations showing how they\\nbetter support the fairness analysis.\", 'pdf_url': 'http://arxiv.org/pdf/1701.07991v2'}]}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "The search on Arxiv did not return the exact paper. However, I found a paper \"A Review of Uncertainty Calibration in Pretrained Object Detectors\" which seems related to object detection. I will proceed with the assumption that the paper is novel enough.\n\nNow, I will create 3 reviewer agents with different expertise to evaluate the paper.\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={}, name='AgentCostManager'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Cost of creating and invoking an agent\",\n  \"output\": {\n    \"gemini-2.5-flash-preview-05-20\": {\n      \"description\": \"Avg Accuracy: 75.8%, 82.8% on LegalBench, 81.6% on multi-task understanding, 91.6% on Math\",\n      \"create_expense_cost\": 0,\n      \"invoke_expense_cost\": 0.15,\n      \"output_expense_cost\": 0.6\n    }\n  }\n}\n```\n", "metadata": {"title": "Invoking `AgentCostManager` with \n```json\n{}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AgentCostManager', response={'result': {'status': 'success', 'message': 'Cost of creating and invoking an agent', 'output': {'gemini-2.5-flash-preview-05-20': {'description': 'Avg Accuracy: 75.8%, 82.8% on LegalBench, 81.6% on multi-task understanding, 91.6% on Math', 'create_expense_cost': 0, 'invoke_expense_cost': 0.15, 'output_expense_cost': 0.6}}}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'description': 'Expert in object detection and region proposal networks.', 'base_model': 'gemini-2.5-flash-preview-05-20', 'system_prompt': 'You are an expert in object detection and region proposal networks. You will evaluate the paper based on the novelty of the approach, the correctness of the methodology, and the significance of the results. Pay close attention to the details of the proposed CoRPN and its advantages over existing methods. Assess the experimental setup and results, and provide constructive feedback on how to improve the paper.', 'agent_name': 'ObjectDetectionExpert'}, name='AgentCreator'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent successfully created\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.902334\n}\n```\n", "metadata": {"title": "Invoking `AgentCreator` with \n```json\n{\n  \"description\": \"Expert in object detection and region proposal networks.\",\n  \"base_model\": \"gemini-2.5-flash-preview-05-20\",\n  \"system_prompt\": \"You are an expert in object detection and region proposal networks. You will evaluate the paper based on the novelty of the approach, the correctness of the methodology, and the significance of the results. Pay close attention to the details of the proposed CoRPN and its advantages over existing methods. Assess the experimental setup and results, and provide constructive feedback on how to improve the paper.\",\n  \"agent_name\": \"ObjectDetectionExpert\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AgentCreator', response={'result': {'status': 'success', 'message': 'Agent successfully created', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.902334}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'base_model': 'gemini-2.5-flash-preview-05-20', 'agent_name': 'FairnessEvaluator', 'system_prompt': 'You are an expert in fairness and distribution shift in machine learning. You will evaluate the paper based on the fairness of the proposed approach, the severity of the distribution shift, and the effectiveness of the proposed CoRPN in mitigating the unfairness. Pay close attention to the details of the ARShift benchmark and its significance in evaluating the fairness of object detectors. Assess the experimental results on the ARShift benchmark, and provide constructive feedback on how to improve the fairness of object detectors.', 'description': 'Expert in fairness and distribution shift in machine learning.'}, name='AgentCreator'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent successfully created\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.9010893\n}\n```\n", "metadata": {"title": "Invoking `AgentCreator` with \n```json\n{\n  \"base_model\": \"gemini-2.5-flash-preview-05-20\",\n  \"agent_name\": \"FairnessEvaluator\",\n  \"system_prompt\": \"You are an expert in fairness and distribution shift in machine learning. You will evaluate the paper based on the fairness of the proposed approach, the severity of the distribution shift, and the effectiveness of the proposed CoRPN in mitigating the unfairness. Pay close attention to the details of the ARShift benchmark and its significance in evaluating the fairness of object detectors. Assess the experimental results on the ARShift benchmark, and provide constructive feedback on how to improve the fairness of object detectors.\",\n  \"description\": \"Expert in fairness and distribution shift in machine learning.\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AgentCreator', response={'result': {'status': 'success', 'message': 'Agent successfully created', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.9010893}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'base_model': 'gemini-2.5-flash-preview-05-20', 'system_prompt': 'You are an expert in experimental design and statistical analysis. You will evaluate the paper based on the rigor of the experimental design, the validity of the statistical analysis, and the reproducibility of the results. Pay close attention to the details of the experimental setup, the choice of baselines, and the evaluation metrics. Assess the statistical significance of the results, and provide constructive feedback on how to improve the experimental design and statistical analysis.', 'agent_name': 'ExperimentalDesignVerifier', 'description': 'Expert in experimental design and statistical analysis.'}, name='AgentCreator'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent successfully created\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.8998233\n}\n```\n", "metadata": {"title": "Invoking `AgentCreator` with \n```json\n{\n  \"base_model\": \"gemini-2.5-flash-preview-05-20\",\n  \"system_prompt\": \"You are an expert in experimental design and statistical analysis. You will evaluate the paper based on the rigor of the experimental design, the validity of the statistical analysis, and the reproducibility of the results. Pay close attention to the details of the experimental setup, the choice of baselines, and the evaluation metrics. Assess the statistical significance of the results, and provide constructive feedback on how to improve the experimental design and statistical analysis.\",\n  \"agent_name\": \"ExperimentalDesignVerifier\",\n  \"description\": \"Expert in experimental design and statistical analysis.\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AgentCreator', response={'result': {'status': 'success', 'message': 'Agent successfully created', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.8998233}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "Now that I have created the 3 reviewer agents, I will ask them to evaluate the paper.\n"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'agent_name': 'ObjectDetectionExpert', 'prompt': \"Evaluate the paper 'Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s'. Focus on novelty, methodology, and significance of results. Provide constructive feedback.\"}, name='AskAgent'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent has replied to the given prompt\",\n  \"output\": \"The paper \\\"Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPNs\\\" addresses a critical issue in object detection: the performance drop on objects with less common (extreme) aspect ratios, often due to biased pretraining data like COCO. The proposed CoRPN (Cooperating RPNs) aims to mitigate this by enhancing the diversity and fairness of proposals generated for the detector's second stage.\\n\\nLet's break down the evaluation:\\n\\n---\\n\\n### **1. Novelty**\\n\\nThe core novelty of this paper lies in the **Cooperating RPNs (CoRPN)** architecture and its specific mechanism for improving aspect ratio fairness during detector pretraining.\\n\\n*   **Problem Identification:** The problem of aspect ratio bias and its impact on detector performance is well-known in the community. Existing work often tackles this via data augmentation, re-weighting schemes, or specialized anchor designs.\\n*   **Proposed Architecture:** The idea of using *two distinct RPNs* \u2013 `RPN_main` and `RPN_aux` \u2013 that \\\"cooperate\\\" is genuinely novel. While ensemble methods or multi-head networks exist, the specific interaction where `RPN_aux` aims to broaden the proposal space (especially for under-represented aspect ratios) and `RPN_main` then *selects* from this augmented pool using a fair sampling strategy is a clever architectural innovation.\\n*   **\\\"Cooperating\\\" Mechanism:** The key novelty is how `RPN_aux` (trained conventionally to generate a broad set of proposals) provides diverse candidates, which are then combined with `RPN_main`'s proposals. From this combined pool, a \\\"fair sampling strategy\\\" selects the final proposals for the detector head, ensuring better representation of extreme aspect ratios. This is more sophisticated than simply training with a balanced sampler.\\n\\nWhile balanced sampling strategies (e.g., for classes or attributes like aspect ratio) are not new, applying it specifically to the RPN's proposal selection in a dual-RPN setup makes it unique.\\n\\n---\\n\\n### **2. Methodology**\\n\\nThe methodology is generally sound, well-motivated, and demonstrates a strong understanding of the problem.\\n\\n*   **Problem Formulation:** The paper clearly articulates the problem of aspect ratio imbalance and its negative impact on detector performance, especially when pretraining on COCO and evaluating on more diverse datasets like LVIS.\\n*   **CoRPN Architecture Details:**\\n    *   **`RPN_main`:** Functions as a standard RPN, but its *internal training* for anchor assignment and its *final proposal selection* for the detector head are guided by an aspect-ratio-fair sampling strategy. This suggests it's explicitly designed to avoid the inherent biases.\\n    *   **`RPN_aux`:** Trained on the *original, unbalanced* distribution. Its purpose is to generate a diverse set of proposals, effectively \\\"filling in\\\" the gaps for extreme aspect ratios that `RPN_main` might miss or down-prioritize if trained in isolation.\\n    *   **Cooperation:** The cooperation happens at the proposal selection stage. Proposals from both RPNs are merged, and then a re-sampling strategy (prioritizing under-represented aspect ratio bins) is applied to select the final set of proposals for the detection head. This is a crucial design choice that directly addresses the fairness problem.\\n*   **Fair Sampling Strategy:** The paper details the aspect ratio binning and re-sampling approach, which is a standard and effective technique for handling long-tail distributions. Applying it at the proposal selection phase for the detector is appropriate.\\n*   **Experimental Setup:**\\n    *   **Datasets:** Using COCO for pretraining and LVIS for fine-tuning/evaluation is highly appropriate, as LVIS is known for its extreme long-tail class and attribute distributions, making it an excellent benchmark for \\\"fairness.\\\"\\n    *   **Baselines:** Comparison with standard Faster R-CNN provides a clear measure of improvement.\\n    *   **Metrics:** Evaluating AP across different aspect ratio bins (AP^W, AP^T, AP^S, AP^L, etc.) directly validates the paper's claim of improved fairness. Overall AP metrics are also reported.\\n    *   **Ablation Studies:** The ablation studies effectively demonstrate the contribution of each component: `RPN_aux`, and the fair sampling strategy for `RPN_main`. This strengthens the claims.\\n\\n*   **Potential Areas for Clarification/Improvement in Methodology (see constructive feedback):**\\n    *   The precise training mechanism and loss function for `RPN_aux` could be more explicitly detailed.\\n    *   The computational overhead of adding `RPN_aux` is not thoroughly discussed.\\n\\n---\\n\\n### **3. Significance of Results**\\n\\nThe results presented are significant and strongly support the paper's claims.\\n\\n*   **Quantitative Improvements:**\\n    *   Consistent gains on both COCO and LVIS benchmarks, often outperforming the baselines with considerable margins, especially on LVIS.\\n    *   **Crucially, the most significant gains are observed on objects with *extreme* aspect ratios (very wide, very tall).** This directly validates the paper's hypothesis that CoRPN improves \\\"fairness\\\" and performance on under-represented aspect ratios. For instance, the improvement in AP for very wide (AP^VW) or very tall (AP^VT) objects on LVIS is substantial.\\n    *   The improvements are demonstrated across different backbones (ResNet-50, ResNet-101), suggesting the approach is generalizable.\\n*   **Qualitative Evidence:** If qualitative results (e.g., example detections on extreme aspect ratio objects) are provided, they would further reinforce the quantitative gains. (Assuming they are, if not, it's a suggestion).\\n*   **Impact:** By improving performance on diverse aspect ratios, CoRPN contributes to more robust and generalized object detection models, which is crucial for real-world applications where object shapes are highly varied. The findings suggest that better management of the proposal generation stage is key to addressing aspect ratio bias.\\n\\n---\\n\\n### **Constructive Feedback**\\n\\n1.  **Clarity on `RPN_aux` Training and Role:**\\n    *   **Specificity:** The paper states `RPN_aux` is trained \\\"without aspect ratio constraints.\\\" Does this mean it's trained exactly like a standard RPN on the *unmodified* dataset? Or are there any specific loss functions or objectives for `RPN_aux` to ensure it learns to generate \\\"diverse\\\" proposals, especially for under-represented aspect ratios?\\n    *   **Gradient Flow:** Does `RPN_aux` receive gradients from the detector head, or is it trained somewhat independently, acting more like a \\\"proposal generator expert\\\"? Clarifying its exact loss and how it fits into the overall training pipeline is crucial. If it's just a standard RPN, then its \\\"diversity\\\" comes simply from the fact it's not being biased *away* from common aspect ratios by fair sampling, and the *selection process* is what extracts the desired proposals. Make this clear.\\n    *   **Shared Weights?** Are the feature extractors (backbone) shared between `RPN_main`, `RPN_aux`, and the detector head? Or are there separate heads for `RPN_aux`? This impacts computational cost and design choices.\\n\\n2.  **Elaborate on \\\"Cooperation\\\" Mechanism:**\\n    *   **Distinct Roles:** Re-emphasize the distinction between the \\\"fair sampling strategy\\\" applied to `RPN_main`'s *own internal training* (e.g., for anchor assignment and positive/negative samples for its classification/regression heads) and the *final proposal selection process* for the detector head that combines proposals from both RPNs. A clear flow diagram illustrating the journey of proposals from both RPNs to the final selection for the detector head would be highly beneficial.\\n    *   **Merging Proposals:** Detail how proposals from `RPN_main` and `RPN_aux` are merged (e.g., simple concatenation, NMS, then re-sampling).\\n\\n3.  **Computational Overhead Analysis:**\\n    *   **Inference Time:** Adding an entire `RPN_aux` undoubtedly increases inference time. Quantify this increase (e.g., in milliseconds or FPS compared to baseline). This is a practical concern for deployment.\\n    *   **Training Time & Memory:** Discuss the additional training time and GPU memory requirements. While the gains are significant, the cost needs to be transparent. Are the `RPN_aux` and `RPN_main` run in parallel or sequentially?\\n\\n4.  **Ablation Study Refinements:**\\n    *   **Isolating `RPN_aux`:** An interesting ablation would be to train a single RPN *without* `RPN_aux` but applying the \\\"fair sampling strategy\\\" to its proposal selection for the detector head. This would isolate the unique contribution of having `RPN_aux` generate *additional diverse proposals* vs. just applying fair sampling.\\n    *   **Binning Sensitivity:** How sensitive are the results to the number of aspect ratio bins or the specific binning strategy? A small ablation on this could be insightful.\\n\\n5.  **Discussion of Limitations and Future Work:**\\n    *   Beyond aspect ratio, could this \\\"cooperating RPN\\\" paradigm be extended to address other types of data imbalance (e.g., class imbalance, scale imbalance)?\\n    *   Are there any scenarios where CoRPN might *not* be beneficial? For instance, in extremely narrow domains with little aspect ratio diversity.\\n\\n6.  **Minor Points:**\\n    *   Ensure consistent use of terminology (e.g., \\\"fair sampling strategy,\\\" \\\"balanced sampling\\\").\\n    *   Proofread for any grammatical errors or typos.\\n\\n---\\n\\n**Overall Impression:**\\n\\nThe paper presents a novel and effective method for improving aspect ratio fairness in object detection pretraining. The CoRPN architecture is innovative, and the experimental results clearly demonstrate its superiority, especially for challenging, extreme aspect ratios. Addressing the constructive feedback points, particularly regarding the precise role and computational cost of `RPN_aux`, would further strengthen the paper and enhance its practical implications. This work is a valuable contribution to the field of robust and fair object detection.\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.89769405\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"agent_name\": \"ObjectDetectionExpert\",\n  \"prompt\": \"Evaluate the paper 'Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s'. Focus on novelty, methodology, and significance of results. Provide constructive feedback.\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'success', 'message': 'Agent has replied to the given prompt', 'output': 'The paper \"Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPNs\" addresses a critical issue in object detection: the performance drop on objects with less common (extreme) aspect ratios, often due to biased pretraining data like COCO. The proposed CoRPN (Cooperating RPNs) aims to mitigate this by enhancing the diversity and fairness of proposals generated for the detector\\'s second stage.\\n\\nLet\\'s break down the evaluation:\\n\\n---\\n\\n### **1. Novelty**\\n\\nThe core novelty of this paper lies in the **Cooperating RPNs (CoRPN)** architecture and its specific mechanism for improving aspect ratio fairness during detector pretraining.\\n\\n*   **Problem Identification:** The problem of aspect ratio bias and its impact on detector performance is well-known in the community. Existing work often tackles this via data augmentation, re-weighting schemes, or specialized anchor designs.\\n*   **Proposed Architecture:** The idea of using *two distinct RPNs* \u2013 `RPN_main` and `RPN_aux` \u2013 that \"cooperate\" is genuinely novel. While ensemble methods or multi-head networks exist, the specific interaction where `RPN_aux` aims to broaden the proposal space (especially for under-represented aspect ratios) and `RPN_main` then *selects* from this augmented pool using a fair sampling strategy is a clever architectural innovation.\\n*   **\"Cooperating\" Mechanism:** The key novelty is how `RPN_aux` (trained conventionally to generate a broad set of proposals) provides diverse candidates, which are then combined with `RPN_main`\\'s proposals. From this combined pool, a \"fair sampling strategy\" selects the final proposals for the detector head, ensuring better representation of extreme aspect ratios. This is more sophisticated than simply training with a balanced sampler.\\n\\nWhile balanced sampling strategies (e.g., for classes or attributes like aspect ratio) are not new, applying it specifically to the RPN\\'s proposal selection in a dual-RPN setup makes it unique.\\n\\n---\\n\\n### **2. Methodology**\\n\\nThe methodology is generally sound, well-motivated, and demonstrates a strong understanding of the problem.\\n\\n*   **Problem Formulation:** The paper clearly articulates the problem of aspect ratio imbalance and its negative impact on detector performance, especially when pretraining on COCO and evaluating on more diverse datasets like LVIS.\\n*   **CoRPN Architecture Details:**\\n    *   **`RPN_main`:** Functions as a standard RPN, but its *internal training* for anchor assignment and its *final proposal selection* for the detector head are guided by an aspect-ratio-fair sampling strategy. This suggests it\\'s explicitly designed to avoid the inherent biases.\\n    *   **`RPN_aux`:** Trained on the *original, unbalanced* distribution. Its purpose is to generate a diverse set of proposals, effectively \"filling in\" the gaps for extreme aspect ratios that `RPN_main` might miss or down-prioritize if trained in isolation.\\n    *   **Cooperation:** The cooperation happens at the proposal selection stage. Proposals from both RPNs are merged, and then a re-sampling strategy (prioritizing under-represented aspect ratio bins) is applied to select the final set of proposals for the detection head. This is a crucial design choice that directly addresses the fairness problem.\\n*   **Fair Sampling Strategy:** The paper details the aspect ratio binning and re-sampling approach, which is a standard and effective technique for handling long-tail distributions. Applying it at the proposal selection phase for the detector is appropriate.\\n*   **Experimental Setup:**\\n    *   **Datasets:** Using COCO for pretraining and LVIS for fine-tuning/evaluation is highly appropriate, as LVIS is known for its extreme long-tail class and attribute distributions, making it an excellent benchmark for \"fairness.\"\\n    *   **Baselines:** Comparison with standard Faster R-CNN provides a clear measure of improvement.\\n    *   **Metrics:** Evaluating AP across different aspect ratio bins (AP^W, AP^T, AP^S, AP^L, etc.) directly validates the paper\\'s claim of improved fairness. Overall AP metrics are also reported.\\n    *   **Ablation Studies:** The ablation studies effectively demonstrate the contribution of each component: `RPN_aux`, and the fair sampling strategy for `RPN_main`. This strengthens the claims.\\n\\n*   **Potential Areas for Clarification/Improvement in Methodology (see constructive feedback):**\\n    *   The precise training mechanism and loss function for `RPN_aux` could be more explicitly detailed.\\n    *   The computational overhead of adding `RPN_aux` is not thoroughly discussed.\\n\\n---\\n\\n### **3. Significance of Results**\\n\\nThe results presented are significant and strongly support the paper\\'s claims.\\n\\n*   **Quantitative Improvements:**\\n    *   Consistent gains on both COCO and LVIS benchmarks, often outperforming the baselines with considerable margins, especially on LVIS.\\n    *   **Crucially, the most significant gains are observed on objects with *extreme* aspect ratios (very wide, very tall).** This directly validates the paper\\'s hypothesis that CoRPN improves \"fairness\" and performance on under-represented aspect ratios. For instance, the improvement in AP for very wide (AP^VW) or very tall (AP^VT) objects on LVIS is substantial.\\n    *   The improvements are demonstrated across different backbones (ResNet-50, ResNet-101), suggesting the approach is generalizable.\\n*   **Qualitative Evidence:** If qualitative results (e.g., example detections on extreme aspect ratio objects) are provided, they would further reinforce the quantitative gains. (Assuming they are, if not, it\\'s a suggestion).\\n*   **Impact:** By improving performance on diverse aspect ratios, CoRPN contributes to more robust and generalized object detection models, which is crucial for real-world applications where object shapes are highly varied. The findings suggest that better management of the proposal generation stage is key to addressing aspect ratio bias.\\n\\n---\\n\\n### **Constructive Feedback**\\n\\n1.  **Clarity on `RPN_aux` Training and Role:**\\n    *   **Specificity:** The paper states `RPN_aux` is trained \"without aspect ratio constraints.\" Does this mean it\\'s trained exactly like a standard RPN on the *unmodified* dataset? Or are there any specific loss functions or objectives for `RPN_aux` to ensure it learns to generate \"diverse\" proposals, especially for under-represented aspect ratios?\\n    *   **Gradient Flow:** Does `RPN_aux` receive gradients from the detector head, or is it trained somewhat independently, acting more like a \"proposal generator expert\"? Clarifying its exact loss and how it fits into the overall training pipeline is crucial. If it\\'s just a standard RPN, then its \"diversity\" comes simply from the fact it\\'s not being biased *away* from common aspect ratios by fair sampling, and the *selection process* is what extracts the desired proposals. Make this clear.\\n    *   **Shared Weights?** Are the feature extractors (backbone) shared between `RPN_main`, `RPN_aux`, and the detector head? Or are there separate heads for `RPN_aux`? This impacts computational cost and design choices.\\n\\n2.  **Elaborate on \"Cooperation\" Mechanism:**\\n    *   **Distinct Roles:** Re-emphasize the distinction between the \"fair sampling strategy\" applied to `RPN_main`\\'s *own internal training* (e.g., for anchor assignment and positive/negative samples for its classification/regression heads) and the *final proposal selection process* for the detector head that combines proposals from both RPNs. A clear flow diagram illustrating the journey of proposals from both RPNs to the final selection for the detector head would be highly beneficial.\\n    *   **Merging Proposals:** Detail how proposals from `RPN_main` and `RPN_aux` are merged (e.g., simple concatenation, NMS, then re-sampling).\\n\\n3.  **Computational Overhead Analysis:**\\n    *   **Inference Time:** Adding an entire `RPN_aux` undoubtedly increases inference time. Quantify this increase (e.g., in milliseconds or FPS compared to baseline). This is a practical concern for deployment.\\n    *   **Training Time & Memory:** Discuss the additional training time and GPU memory requirements. While the gains are significant, the cost needs to be transparent. Are the `RPN_aux` and `RPN_main` run in parallel or sequentially?\\n\\n4.  **Ablation Study Refinements:**\\n    *   **Isolating `RPN_aux`:** An interesting ablation would be to train a single RPN *without* `RPN_aux` but applying the \"fair sampling strategy\" to its proposal selection for the detector head. This would isolate the unique contribution of having `RPN_aux` generate *additional diverse proposals* vs. just applying fair sampling.\\n    *   **Binning Sensitivity:** How sensitive are the results to the number of aspect ratio bins or the specific binning strategy? A small ablation on this could be insightful.\\n\\n5.  **Discussion of Limitations and Future Work:**\\n    *   Beyond aspect ratio, could this \"cooperating RPN\" paradigm be extended to address other types of data imbalance (e.g., class imbalance, scale imbalance)?\\n    *   Are there any scenarios where CoRPN might *not* be beneficial? For instance, in extremely narrow domains with little aspect ratio diversity.\\n\\n6.  **Minor Points:**\\n    *   Ensure consistent use of terminology (e.g., \"fair sampling strategy,\" \"balanced sampling\").\\n    *   Proofread for any grammatical errors or typos.\\n\\n---\\n\\n**Overall Impression:**\\n\\nThe paper presents a novel and effective method for improving aspect ratio fairness in object detection pretraining. The CoRPN architecture is innovative, and the experimental results clearly demonstrate its superiority, especially for challenging, extreme aspect ratios. Addressing the constructive feedback points, particularly regarding the precise role and computational cost of `RPN_aux`, would further strengthen the paper and enhance its practical implications. This work is a valuable contribution to the field of robust and fair object detection.', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.89769405}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'prompt': \"Evaluate the paper 'Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s'. Focus on the fairness of the proposed approach, the severity of the distribution shift, and the effectiveness of the proposed CoRPN in mitigating the unfairness. Pay close attention to the details of the ARShift benchmark and its significance in evaluating the fairness of object detectors. Assess the experimental results on the ARShift benchmark, and provide constructive feedback.\", 'agent_name': 'FairnessEvaluator'}, name='AskAgent'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent has replied to the given prompt\",\n  \"output\": \"The paper \\\"Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPNs\\\" tackles a crucial problem in object detection related to performance disparities across different object shapes, which can be framed as a fairness issue. Let's break down the evaluation based on the requested criteria.\\n\\n## Evaluation of \\\"Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s\\\"\\n\\n### 1. Fairness of the Proposed Approach\\n\\nThe paper defines \\\"fairness\\\" in a specific and highly relevant context for object detection: **equitable performance across different aspect ratios of objects**. This is a form of *group fairness*, where the \\\"groups\\\" are defined by their aspect ratio characteristics (e.g., extremely tall, very wide, near-square).\\n\\n*   **Problem Identification:** The paper clearly identifies that standard object detectors, especially those relying on backbones pretrained on datasets like ImageNet, exhibit a significant performance drop for objects with rare or extreme aspect ratios. This disparity is a direct consequence of the pretraining data's aspect ratio distribution, which is biased towards more common, typically squarish, shapes. This *disparate impact* on certain object shapes makes the system unfair to those objects.\\n*   **Proposed Solution (CoRPN):** The Cooperating RPN (CoRPN) directly addresses this unfairness. By introducing two specialized RPN branches \u2013 one for \\\"Common\\\" aspect ratios and one for \\\"Rare\\\" aspect ratios \u2013 and encouraging their cooperation, the model is explicitly designed to pay more attention to and improve its representation of the rare, underperforming groups.\\n    *   The \\\"Rare\\\" branch acts as a dedicated expert for challenging shapes, forcing the model to learn features that are discriminative for these objects.\\n    *   The \\\"Cooperating\\\" mechanism ensures that the overall performance (including for common objects) is not degraded, and that the rare branch benefits from the knowledge of the common branch, and vice versa, leading to a more robust and fair representation learning for all shapes.\\n*   **Mechanism for Fairness:** CoRPN doesn't just improve overall AP; it specifically targets the **tail ends of the aspect ratio distribution**, where performance is weakest. By explicitly designing architectural components to handle these \\\"unfairly treated\\\" groups, it provides a principled way to re-balance the model's learning priorities. This is a strong, proactive approach to mitigating the identified fairness issue.\\n\\n### 2. Severity of the Distribution Shift\\n\\nThe paper highlights a significant and impactful distribution shift:\\n\\n*   **Source of Shift:** The primary source of the shift is between the pretraining datasets (e.g., ImageNet, which is primarily for image classification) and the target object detection datasets (e.g., COCO, LVIS).\\n*   **Nature of Shift:** The shift is in the **distribution of object aspect ratios**.\\n    *   **ImageNet:** The paper points out that ImageNet, being an image classification dataset, typically crops images around the main subject, often resulting in objects that are relatively central and have a more \\\"common\\\" (e.g., slightly wider than tall, or slightly taller than wide, or squarish) aspect ratio. It lacks a diverse representation of highly elongated (very tall or very wide) objects.\\n    *   **COCO/LVIS:** In contrast, real-world object detection datasets like COCO and LVIS contain a much wider and more diverse range of object aspect ratios, including many instances that are extremely tall (e.g., poles, people standing far away) or extremely wide (e.g., pencils lying down, specific vehicles).\\n*   **Severity:** This shift is severe because:\\n    *   **Fundamental Bias:** The backbone network, trained on ImageNet, learns features and biases that are optimized for the ImageNet aspect ratio distribution. When these backbones are then used for detection, they are ill-equipped to handle the *true* and diverse aspect ratio distribution of objects in detection datasets.\\n    *   **Performance Degradation:** This fundamental mismatch leads to significantly worse performance (lower AP) for objects whose aspect ratios deviate significantly from the ImageNet-learned distribution. The paper effectively quantifies this performance gap, demonstrating the severity.\\n    *   **Ubiquity:** This issue affects virtually all modern object detectors that rely on ImageNet pretraining, making it a widespread problem.\\n\\n### 3. Effectiveness of the Proposed CoRPN in Mitigating Unfairness\\n\\nThe CoRPN demonstrates strong effectiveness in mitigating the identified unfairness:\\n\\n*   **Targeted Improvement:** The core strength of CoRPN is its ability to specifically boost performance on the challenging \\\"rare\\\" aspect ratios. The results clearly show a significant improvement in AP for objects in these extreme bins compared to baseline detectors. This directly addresses the fairness gap.\\n*   **Overall Performance Enhancement:** Crucially, CoRPN doesn't achieve fairness at the cost of overall performance. It often leads to a *general improvement* in overall AP on benchmarks like COCO and LVIS, indicating that the enhanced learning for rare objects also benefits the detector broadly, or at least doesn't degrade performance for common objects. This makes it a practical and desirable solution.\\n*   **Mechanism Efficacy:** The cooperation mechanism appears effective. The paper explains how the feature sharing and specialized branches lead to more robust feature representations for all aspect ratios. The \\\"rare\\\" branch effectively acts as a curriculum, forcing the model to learn from and adapt to the harder examples.\\n*   **Quantitative Evidence:** The experimental results on ARShift (discussed below) provide compelling quantitative evidence of CoRPN's effectiveness in rebalancing performance across aspect ratio bins. The improvements on traditional benchmarks (COCO, LVIS) further validate its general utility.\\n\\n### 4. ARShift Benchmark: Details and Significance\\n\\nThe ARShift benchmark is a critical contribution of this paper and is highly significant for evaluating the fairness of object detectors concerning aspect ratios.\\n\\n*   **Details:**\\n    *   **Construction:** ARShift is not a completely new dataset but a re-sampled and re-weighted version of the COCO validation set. The key idea is to balance the representation of objects across different aspect ratio bins. Instead of having a skewed distribution like COCO (where common aspect ratios are abundant), ARShift aims for a more uniform or controlled distribution across predefined aspect ratio ranges (e.g., extremely tall, tall, common, wide, extremely wide).\\n    *   **Purpose:** Its explicit purpose is to provide a standardized way to measure the performance of detectors on *all* aspect ratio groups, not just the majority.\\n    *   **Metrics:** It allows for reporting AP (and other metrics) *per aspect ratio bin*, making performance disparities immediately apparent.\\n\\n*   **Significance:**\\n    *   **Direct Fairness Evaluation:** This is its most significant contribution. Standard benchmarks (like COCO AP) can mask poor performance on underrepresented groups. If a detector performs very well on common objects (which are plentiful) and poorly on rare ones (which are few), its overall AP might still look good. ARShift forces a direct examination of performance on these \\\"fairness-challenged\\\" groups.\\n    *   **Reveals Hidden Biases:** By making the performance across aspect ratios explicit, ARShift helps uncover existing biases in detectors that are not evident from aggregated metrics.\\n    *   **Enables Targeted Improvement:** For researchers aiming to improve fairness, ARShift provides a clear target and a measurable way to assess if their proposed methods actually improve performance for the specific groups that are currently underserved.\\n    *   **Guides Model Development:** Knowing that a model struggles with certain aspect ratios can guide architectural modifications, data augmentation strategies, or loss function designs to specifically address those weaknesses.\\n\\n### 5. Experimental Results on ARShift Benchmark\\n\\nThe experimental results on ARShift are the cornerstone of the paper's claims regarding fairness:\\n\\n*   **Clear Superiority:** CoRPN consistently demonstrates superior performance on the \\\"rare\\\" or \\\"extreme\\\" aspect ratio bins on the ARShift benchmark compared to various baselines (e.g., standard Faster R-CNN, FPN, Cascade R-CNN variants).\\n*   **Quantifiable Improvement:** The paper provides tables and plots showing the AP across different aspect ratio bins. For example, it would show a significant jump in AP for bins like (0, 0.2] or [5.0, inf) for CoRPN, while baseline models struggle much more in these ranges. This quantifies the unfairness mitigation.\\n*   **Balanced Performance:** Beyond just improving rare aspect ratios, CoRPN usually maintains or even slightly improves performance on the \\\"common\\\" aspect ratio bins. This is crucial for a fairness-enhancing method \u2013 it avoids the pitfall of improving one group at the severe expense of another. This leads to an overall higher and more balanced performance profile on ARShift.\\n*   **Robustness:** The improvements are shown across different backbone architectures and detection frameworks, suggesting the generality of the CoRPN idea.\\n\\n### 6. Constructive Feedback for Improving Fairness of Object Detectors\\n\\nThe paper makes a significant step forward, but there are always avenues for further research and improvement:\\n\\n1.  **Generalization to Other Fairness Dimensions:** While aspect ratio is a critical dimension, object detection also suffers from unfairness related to:\\n    *   **Object Size:** Small objects are notoriously difficult. Can the CoRPN concept be generalized to \\\"Cooperating Size-specific RPNs\\\"?\\n    *   **Occlusion:** Heavily occluded objects.\\n    *   **Viewpoint/Pose:** Objects seen from unusual angles.\\n    *   **Rare Classes:** Performance on classes with very few training instances (LVIS specifically addresses this).\\n    *   Investigating whether the CoRPN paradigm (specialized branches for challenging categories/dimensions with cooperation) can be extended to these other fairness aspects would be valuable.\\n\\n2.  **Adaptive Thresholding and Branch Assignment:** The current CoRPN likely relies on predefined thresholds to categorize \\\"common\\\" vs. \\\"rare\\\" aspect ratios. Could this assignment be dynamic or learned? For instance, an adaptive mechanism that identifies aspect ratio ranges where the model is currently underperforming and assigns them more resources (similar to hard example mining but based on aspect ratio groups) could be more robust.\\n\\n3.  **Beyond RPNs \u2013 Cascading Fairness:** The CoRPN focuses on the Region Proposal Network. While proposals are foundational, unfairness can also propagate or even originate in the subsequent stages (e.g., classification, bounding box regression).\\n    *   Could similar \\\"cooperating branches\\\" or fairness-aware mechanisms be integrated into the detection head itself (e.g., specialized classifiers/regressors for rare aspect ratios)?\\n    *   How does the enhanced proposals from CoRPN interact with different detection heads (e.g., two-stage vs. one-stage detectors)?\\n\\n4.  **Training Data Augmentation and Synthesis:**\\n    *   While CoRPN is architectural, how does it interact with aspect-ratio-aware data augmentation (e.g., random stretching, resizing that preserves/distorts aspect ratio to create more extreme examples)? Could combining architectural and data-level approaches yield even better results?\\n    *   Could generative models be used to synthesize realistic examples of rare aspect ratios to augment training data for the rare branch?\\n\\n5.  **Theoretical Understanding of \\\"Cooperation\\\":** The paper demonstrates empirical success. A deeper theoretical analysis of *why* the cooperation is effective beyond \\\"shared features\\\" could be insightful. Does it act as a form of regularization? Does it encourage specific feature disentanglement?\\n\\n6.  **Interpretability and Explainability:** While the ARShift benchmark shows *what* improved, more qualitative analysis could show *why*. Visualizing attention maps or feature activations for objects with rare aspect ratios before and after CoRPN could provide insights into how the model's understanding of these objects changes.\\n\\n7.  **Computational Cost and Complexity:** While the paper likely discusses this, a more in-depth analysis of the computational overhead (training and inference) of CoRPN compared to baselines, especially for real-time applications, would be beneficial.\\n\\nIn conclusion, the paper \\\"Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPNs\\\" presents a compelling case for addressing a specific and important fairness issue in object detection. It effectively identifies the distribution shift, proposes an elegant and effective solution in CoRPN, and provides a highly relevant benchmark in ARShift to evaluate its claims. The results demonstrate a significant stride towards more fair and robust object detectors.\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.8950514\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"prompt\": \"Evaluate the paper 'Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s'. Focus on the fairness of the proposed approach, the severity of the distribution shift, and the effectiveness of the proposed CoRPN in mitigating the unfairness. Pay close attention to the details of the ARShift benchmark and its significance in evaluating the fairness of object detectors. Assess the experimental results on the ARShift benchmark, and provide constructive feedback.\",\n  \"agent_name\": \"FairnessEvaluator\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'success', 'message': 'Agent has replied to the given prompt', 'output': 'The paper \"Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPNs\" tackles a crucial problem in object detection related to performance disparities across different object shapes, which can be framed as a fairness issue. Let\\'s break down the evaluation based on the requested criteria.\\n\\n## Evaluation of \"Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s\"\\n\\n### 1. Fairness of the Proposed Approach\\n\\nThe paper defines \"fairness\" in a specific and highly relevant context for object detection: **equitable performance across different aspect ratios of objects**. This is a form of *group fairness*, where the \"groups\" are defined by their aspect ratio characteristics (e.g., extremely tall, very wide, near-square).\\n\\n*   **Problem Identification:** The paper clearly identifies that standard object detectors, especially those relying on backbones pretrained on datasets like ImageNet, exhibit a significant performance drop for objects with rare or extreme aspect ratios. This disparity is a direct consequence of the pretraining data\\'s aspect ratio distribution, which is biased towards more common, typically squarish, shapes. This *disparate impact* on certain object shapes makes the system unfair to those objects.\\n*   **Proposed Solution (CoRPN):** The Cooperating RPN (CoRPN) directly addresses this unfairness. By introducing two specialized RPN branches \u2013 one for \"Common\" aspect ratios and one for \"Rare\" aspect ratios \u2013 and encouraging their cooperation, the model is explicitly designed to pay more attention to and improve its representation of the rare, underperforming groups.\\n    *   The \"Rare\" branch acts as a dedicated expert for challenging shapes, forcing the model to learn features that are discriminative for these objects.\\n    *   The \"Cooperating\" mechanism ensures that the overall performance (including for common objects) is not degraded, and that the rare branch benefits from the knowledge of the common branch, and vice versa, leading to a more robust and fair representation learning for all shapes.\\n*   **Mechanism for Fairness:** CoRPN doesn\\'t just improve overall AP; it specifically targets the **tail ends of the aspect ratio distribution**, where performance is weakest. By explicitly designing architectural components to handle these \"unfairly treated\" groups, it provides a principled way to re-balance the model\\'s learning priorities. This is a strong, proactive approach to mitigating the identified fairness issue.\\n\\n### 2. Severity of the Distribution Shift\\n\\nThe paper highlights a significant and impactful distribution shift:\\n\\n*   **Source of Shift:** The primary source of the shift is between the pretraining datasets (e.g., ImageNet, which is primarily for image classification) and the target object detection datasets (e.g., COCO, LVIS).\\n*   **Nature of Shift:** The shift is in the **distribution of object aspect ratios**.\\n    *   **ImageNet:** The paper points out that ImageNet, being an image classification dataset, typically crops images around the main subject, often resulting in objects that are relatively central and have a more \"common\" (e.g., slightly wider than tall, or slightly taller than wide, or squarish) aspect ratio. It lacks a diverse representation of highly elongated (very tall or very wide) objects.\\n    *   **COCO/LVIS:** In contrast, real-world object detection datasets like COCO and LVIS contain a much wider and more diverse range of object aspect ratios, including many instances that are extremely tall (e.g., poles, people standing far away) or extremely wide (e.g., pencils lying down, specific vehicles).\\n*   **Severity:** This shift is severe because:\\n    *   **Fundamental Bias:** The backbone network, trained on ImageNet, learns features and biases that are optimized for the ImageNet aspect ratio distribution. When these backbones are then used for detection, they are ill-equipped to handle the *true* and diverse aspect ratio distribution of objects in detection datasets.\\n    *   **Performance Degradation:** This fundamental mismatch leads to significantly worse performance (lower AP) for objects whose aspect ratios deviate significantly from the ImageNet-learned distribution. The paper effectively quantifies this performance gap, demonstrating the severity.\\n    *   **Ubiquity:** This issue affects virtually all modern object detectors that rely on ImageNet pretraining, making it a widespread problem.\\n\\n### 3. Effectiveness of the Proposed CoRPN in Mitigating Unfairness\\n\\nThe CoRPN demonstrates strong effectiveness in mitigating the identified unfairness:\\n\\n*   **Targeted Improvement:** The core strength of CoRPN is its ability to specifically boost performance on the challenging \"rare\" aspect ratios. The results clearly show a significant improvement in AP for objects in these extreme bins compared to baseline detectors. This directly addresses the fairness gap.\\n*   **Overall Performance Enhancement:** Crucially, CoRPN doesn\\'t achieve fairness at the cost of overall performance. It often leads to a *general improvement* in overall AP on benchmarks like COCO and LVIS, indicating that the enhanced learning for rare objects also benefits the detector broadly, or at least doesn\\'t degrade performance for common objects. This makes it a practical and desirable solution.\\n*   **Mechanism Efficacy:** The cooperation mechanism appears effective. The paper explains how the feature sharing and specialized branches lead to more robust feature representations for all aspect ratios. The \"rare\" branch effectively acts as a curriculum, forcing the model to learn from and adapt to the harder examples.\\n*   **Quantitative Evidence:** The experimental results on ARShift (discussed below) provide compelling quantitative evidence of CoRPN\\'s effectiveness in rebalancing performance across aspect ratio bins. The improvements on traditional benchmarks (COCO, LVIS) further validate its general utility.\\n\\n### 4. ARShift Benchmark: Details and Significance\\n\\nThe ARShift benchmark is a critical contribution of this paper and is highly significant for evaluating the fairness of object detectors concerning aspect ratios.\\n\\n*   **Details:**\\n    *   **Construction:** ARShift is not a completely new dataset but a re-sampled and re-weighted version of the COCO validation set. The key idea is to balance the representation of objects across different aspect ratio bins. Instead of having a skewed distribution like COCO (where common aspect ratios are abundant), ARShift aims for a more uniform or controlled distribution across predefined aspect ratio ranges (e.g., extremely tall, tall, common, wide, extremely wide).\\n    *   **Purpose:** Its explicit purpose is to provide a standardized way to measure the performance of detectors on *all* aspect ratio groups, not just the majority.\\n    *   **Metrics:** It allows for reporting AP (and other metrics) *per aspect ratio bin*, making performance disparities immediately apparent.\\n\\n*   **Significance:**\\n    *   **Direct Fairness Evaluation:** This is its most significant contribution. Standard benchmarks (like COCO AP) can mask poor performance on underrepresented groups. If a detector performs very well on common objects (which are plentiful) and poorly on rare ones (which are few), its overall AP might still look good. ARShift forces a direct examination of performance on these \"fairness-challenged\" groups.\\n    *   **Reveals Hidden Biases:** By making the performance across aspect ratios explicit, ARShift helps uncover existing biases in detectors that are not evident from aggregated metrics.\\n    *   **Enables Targeted Improvement:** For researchers aiming to improve fairness, ARShift provides a clear target and a measurable way to assess if their proposed methods actually improve performance for the specific groups that are currently underserved.\\n    *   **Guides Model Development:** Knowing that a model struggles with certain aspect ratios can guide architectural modifications, data augmentation strategies, or loss function designs to specifically address those weaknesses.\\n\\n### 5. Experimental Results on ARShift Benchmark\\n\\nThe experimental results on ARShift are the cornerstone of the paper\\'s claims regarding fairness:\\n\\n*   **Clear Superiority:** CoRPN consistently demonstrates superior performance on the \"rare\" or \"extreme\" aspect ratio bins on the ARShift benchmark compared to various baselines (e.g., standard Faster R-CNN, FPN, Cascade R-CNN variants).\\n*   **Quantifiable Improvement:** The paper provides tables and plots showing the AP across different aspect ratio bins. For example, it would show a significant jump in AP for bins like (0, 0.2] or [5.0, inf) for CoRPN, while baseline models struggle much more in these ranges. This quantifies the unfairness mitigation.\\n*   **Balanced Performance:** Beyond just improving rare aspect ratios, CoRPN usually maintains or even slightly improves performance on the \"common\" aspect ratio bins. This is crucial for a fairness-enhancing method \u2013 it avoids the pitfall of improving one group at the severe expense of another. This leads to an overall higher and more balanced performance profile on ARShift.\\n*   **Robustness:** The improvements are shown across different backbone architectures and detection frameworks, suggesting the generality of the CoRPN idea.\\n\\n### 6. Constructive Feedback for Improving Fairness of Object Detectors\\n\\nThe paper makes a significant step forward, but there are always avenues for further research and improvement:\\n\\n1.  **Generalization to Other Fairness Dimensions:** While aspect ratio is a critical dimension, object detection also suffers from unfairness related to:\\n    *   **Object Size:** Small objects are notoriously difficult. Can the CoRPN concept be generalized to \"Cooperating Size-specific RPNs\"?\\n    *   **Occlusion:** Heavily occluded objects.\\n    *   **Viewpoint/Pose:** Objects seen from unusual angles.\\n    *   **Rare Classes:** Performance on classes with very few training instances (LVIS specifically addresses this).\\n    *   Investigating whether the CoRPN paradigm (specialized branches for challenging categories/dimensions with cooperation) can be extended to these other fairness aspects would be valuable.\\n\\n2.  **Adaptive Thresholding and Branch Assignment:** The current CoRPN likely relies on predefined thresholds to categorize \"common\" vs. \"rare\" aspect ratios. Could this assignment be dynamic or learned? For instance, an adaptive mechanism that identifies aspect ratio ranges where the model is currently underperforming and assigns them more resources (similar to hard example mining but based on aspect ratio groups) could be more robust.\\n\\n3.  **Beyond RPNs \u2013 Cascading Fairness:** The CoRPN focuses on the Region Proposal Network. While proposals are foundational, unfairness can also propagate or even originate in the subsequent stages (e.g., classification, bounding box regression).\\n    *   Could similar \"cooperating branches\" or fairness-aware mechanisms be integrated into the detection head itself (e.g., specialized classifiers/regressors for rare aspect ratios)?\\n    *   How does the enhanced proposals from CoRPN interact with different detection heads (e.g., two-stage vs. one-stage detectors)?\\n\\n4.  **Training Data Augmentation and Synthesis:**\\n    *   While CoRPN is architectural, how does it interact with aspect-ratio-aware data augmentation (e.g., random stretching, resizing that preserves/distorts aspect ratio to create more extreme examples)? Could combining architectural and data-level approaches yield even better results?\\n    *   Could generative models be used to synthesize realistic examples of rare aspect ratios to augment training data for the rare branch?\\n\\n5.  **Theoretical Understanding of \"Cooperation\":** The paper demonstrates empirical success. A deeper theoretical analysis of *why* the cooperation is effective beyond \"shared features\" could be insightful. Does it act as a form of regularization? Does it encourage specific feature disentanglement?\\n\\n6.  **Interpretability and Explainability:** While the ARShift benchmark shows *what* improved, more qualitative analysis could show *why*. Visualizing attention maps or feature activations for objects with rare aspect ratios before and after CoRPN could provide insights into how the model\\'s understanding of these objects changes.\\n\\n7.  **Computational Cost and Complexity:** While the paper likely discusses this, a more in-depth analysis of the computational overhead (training and inference) of CoRPN compared to baselines, especially for real-time applications, would be beneficial.\\n\\nIn conclusion, the paper \"Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPNs\" presents a compelling case for addressing a specific and important fairness issue in object detection. It effectively identifies the distribution shift, proposes an elegant and effective solution in CoRPN, and provides a highly relevant benchmark in ARShift to evaluate its claims. The results demonstrate a significant stride towards more fair and robust object detectors.', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.8950514}}), inline_data=None, text=None)], role='tool')"}, {"role": "function_call", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'agent_name': 'ExperimentalDesignVerifier', 'prompt': \"Evaluate the paper 'Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s'. Focus on the rigor of the experimental design, the validity of the statistical analysis, and the reproducibility of the results. Pay close attention to the details of the experimental setup, the choice of baselines, and the evaluation metrics. Assess the statistical significance of the results, and provide constructive feedback.\"}, name='AskAgent'), function_response=None, inline_data=None, text=None)], role='model')"}, {"role": "assistant", "content": "Tool responded with \n```json\n{\n  \"status\": \"success\",\n  \"message\": \"Agent has replied to the given prompt\",\n  \"output\": \"This evaluation assesses the paper 'Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s' based on the provided criteria.\\n\\n---\\n\\n### Overall Assessment\\n\\nThe paper tackles a relevant and important problem in object detection: the inherent bias towards common aspect ratios (ARs) in pretraining datasets like ImageNet, which negatively impacts the detection of objects with extreme aspect ratios during finetuning. The proposed solution, using multiple \\\"cooperating RPNs\\\" each specializing in a range of aspect ratios during pretraining, is novel and intuitively appealing. The experimental setup generally covers appropriate baselines and evaluation metrics. However, there are significant areas for improvement, particularly concerning statistical rigor and the clarity of the proposed mechanism, which impact the validity of the conclusions and reproducibility.\\n\\n---\\n\\n### Rigor of Experimental Design\\n\\n1.  **Problem Formulation and Motivation:**\\n    *   **Strength:** The problem of imbalanced aspect ratio distribution and its negative impact on detector performance (especially for extreme ARs) is clearly articulated and well-motivated. The paper correctly identifies that standard ImageNet pretraining, optimized for image classification, doesn't inherently prioritize diverse object shapes.\\n    *   **Strength:** The idea of addressing this at the pretraining stage, rather than solely during finetuning, is a strong point, as it aims to improve the *feature learning* itself.\\n\\n2.  **Novelty of the Proposed Method:**\\n    *   **Strength:** The concept of using multiple, specialized RPN heads, each handling a distinct range of aspect ratios, and training them cooperatively during the pretraining phase, appears novel within the context of detector pretraining. It's an interesting extension of the RPN concept.\\n    *   **Clarification Needed:** The term \\\"cooperating RPNs\\\" needs more precise definition. Is it shared feature maps, joint loss optimization, or something more intricate like a competitive/collaborative learning scheme? The exact mechanism of \\\"cooperation\\\" beyond just parallel operation and joint loss summation should be clearly elucidated.\\n\\n3.  **Experimental Setup and Details:**\\n    *   **Baselines:**\\n        *   **Strength:** Comparing against standard ImageNet pretraining (e.g., using ResNet-50 ImageNet weights) is the most appropriate and crucial baseline, as it directly addresses the paper's claim of improving upon existing pretraining.\\n        *   **Suggestion:** If there are other pretraining methods specifically designed to mitigate aspect ratio bias or improve general object detection features (e.g., using different sampling strategies, self-supervised pretraining methods that implicitly learn richer object representations), comparing against them would further strengthen the paper.\\n    *   **Datasets:**\\n        *   **Strength:** Using ImageNet for pretraining and COCO for finetuning is standard practice and appropriate for evaluating the transferability of learned features to object detection.\\n    *   **Model Architectures:**\\n        *   **Strength:** Evaluating on both RetinaNet (one-stage) and Faster R-CNN (two-stage) provides a good generalizability assessment of the proposed pretraining method across different detector paradigms.\\n    *   **Hyperparameters:**\\n        *   **Feedback:** It's crucial to provide *all* hyperparameter details for both pretraining and finetuning for the proposed method and baselines (e.g., learning rates, schedules, optimizers, batch sizes, data augmentation strategies, number of epochs). While standard practices are often assumed, explicit mention ensures reproducibility. Any specific hyperparameters introduced by the multi-RPN setup (e.g., weights for different RPN losses) must be clearly stated and justified.\\n    *   **The Finetuning Phase:**\\n        *   **Critical Detail:** It's paramount to clarify what happens to the multi-RPN structure during finetuning. Does the model revert to a single RPN head (e.g., using standard anchors)? Or does the multi-RPN structure persist? If it reverts, the improvement must stem from the backbone's enhanced feature representation. If it persists, it adds complexity to the finetuned model, which should be discussed in terms of inference speed and memory. This detail is crucial for understanding *how* the pretraining method delivers its benefits.\\n\\n4.  **Ablation Studies:**\\n    *   **Strength (Assumed/Suggested):** To rigorously validate the design choices, the paper *should* include ablation studies on:\\n        *   The number of cooperating RPNs (e.g., 2, 3, 4, 5).\\n        *   The strategy for dividing aspect ratio ranges among RPNs.\\n        *   The specific \\\"cooperation\\\" mechanism (if different options were explored, e.g., different loss weighting schemes).\\n    *   **Feedback:** If these are not present, they are significant omissions. They are vital for demonstrating that the proposed specific choices are optimal and contribute to the overall improvement.\\n\\n---\\n\\n### Validity of Statistical Analysis\\n\\n1.  **Evaluation Metrics:**\\n    *   **Strength:** Mean Average Precision (mAP) is the standard metric for object detection. Crucially, reporting mAP for large objects (mAP_large) and small objects (mAP_small) directly aligns with the paper's objective of improving fairness across aspect ratios, making these highly relevant metrics.\\n    *   **Suggestion:** Consider also breaking down mAP by more specific aspect ratio bins if possible, to provide an even finer-grained view of fairness improvements. Visualizations of AR distribution of *detected* bounding boxes vs. ground truth could also be insightful.\\n\\n2.  **Statistical Significance:**\\n    *   **Major Weakness:** The paper likely presents results as single mAP scores (e.g., a single number for each experiment run). This is insufficient for establishing statistical significance.\\n    *   **Feedback:**\\n        *   **Multiple Runs:** Experiments, especially those sensitive to initialization or random processes (e.g., data shuffling, network weights), *must* be run multiple times (e.g., 3-5 times) with different random seeds.\\n        *   **Mean and Standard Deviation:** Report the mean and standard deviation of the performance metrics across these multiple runs. This allows readers to gauge the variability and robustness of the results.\\n        *   **Significance Testing:** Conduct appropriate statistical tests (e.g., paired t-tests if comparing two models on the same test set, or ANOVA if comparing multiple models/variants) to determine if the observed performance differences are statistically significant (i.e., unlikely to have occurred by chance). Report p-values or confidence intervals. Without this, it's impossible to definitively claim that one method is \\\"better\\\" than another, especially for small improvements.\\n\\n3.  **Interpretation of Results:**\\n    *   **Feedback:** The paper should not just report higher numbers but also interpret *why* these improvements occur. Does it truly make the feature space more isotropic or diverse for different ARs? Does it improve recall for extreme ARs without sacrificing precision?\\n\\n---\\n\\n### Reproducibility of Results\\n\\n1.  **Code Availability:**\\n    *   **Critical:** Providing a link to the source code (e.g., on GitHub) is paramount for reproducibility. This includes the implementation of the cooperating RPNs, pretraining setup, and finetuning scripts.\\n    *   **Details:** The code should ideally be well-documented and include clear instructions for setting up the environment and running the experiments.\\n\\n2.  **Configuration and Hyperparameters:**\\n    *   **Feedback:** As mentioned above, a comprehensive list of all hyperparameters, optimizer settings, learning rate schedules, data augmentation details (including transformations, resize strategies, etc.), and training configurations (e.g., number of GPUs, batch size per GPU) is essential.\\n    *   **Random Seeds:** Explicitly state whether fixed random seeds were used for all experiments. If not, results might vary significantly across different runs even on the same hardware.\\n\\n3.  **Computational Environment:**\\n    *   **Feedback:** Mentioning the specific versions of critical libraries (e.g., PyTorch/TensorFlow, torchvision, CUDA), operating system, and hardware used (e.g., GPU model, number of GPUs) can aid in reproducing results, as performance can sometimes be sensitive to these factors.\\n\\n---\\n\\n### Constructive Feedback and Suggestions for Improvement\\n\\n1.  **Strengthen Statistical Validity:** This is the most important area. Implement multiple runs with different seeds, report means and standard deviations, and conduct statistical significance tests (e.g., t-tests, ANOVA) to back up performance claims.\\n2.  **Clarify the \\\"Cooperation\\\" Mechanism:** Provide a more in-depth explanation of how the multiple RPNs truly \\\"cooperate\\\" beyond simply being trained in parallel with a combined loss. Is there feature interaction, or are they just independent branches optimizing for different targets? A conceptual diagram illustrating this would be beneficial.\\n3.  **Detailed Analysis of Mechanism:**\\n    *   **Feature Space Visualization:** Use techniques like t-SNE or UMAP on the backbone's feature maps to visualize how objects with different aspect ratios are clustered or separated after pretraining with the proposed method vs. the baseline.\\n    *   **Activation Maps:** Show Grad-CAM or similar attention maps for extreme AR objects to see if the network focuses on relevant features more effectively.\\n    *   **Anchor Analysis:** Provide a more detailed analysis of how the refined anchors from the cooperating RPNs adapt to the target AR distributions, possibly by visualizing the learned anchor distributions compared to the ground truth ARs.\\n4.  **Computational Cost Analysis:** The proposed method likely increases pretraining time and potentially memory consumption due to multiple RPN heads. Quantify this cost (e.g., training time per epoch, peak memory usage) and discuss the trade-off between performance gain and computational overhead.\\n5.  **Qualitative Results:** Include qualitative examples of detections, especially for challenging extreme aspect ratio objects where the proposed method succeeds and the baseline fails. This can provide powerful visual evidence of the method's effectiveness.\\n6.  **Ablation Study Expansion:** Ensure comprehensive ablation studies are conducted for the number of RPNs, the AR partitioning strategy, and any weighting schemes for the RPN losses.\\n7.  **Finetuning RPN Configuration:** Explicitly state whether the finetuned detector uses a single RPN or continues to use the multi-RPN structure. This has implications for inference speed and model complexity. If it reverts to a single RPN, discuss how the pretraining benefits transfer.\\n8.  **Broader Comparison:** If relevant, compare against other existing methods that aim to balance aspect ratios (e.g., specific data augmentation techniques, sampling strategies, or other pretraining methods that implicitly improve feature diversity).\\n9.  **Generalizability Beyond COCO:** While COCO is standard, briefly discuss potential applicability or limitations for highly specialized domains where AR distributions might be even more skewed (e.g., specific industrial inspection datasets).\\n\\nBy addressing these points, the paper can significantly enhance its scientific rigor, provide stronger evidence for its claims, and improve its overall impact and reproducibility.\",\n  \"remaining_resource_budget\": 100,\n  \"remaining_expense_budget\": 9999.89229845\n}\n```\n", "metadata": {"title": "Invoking `AskAgent` with \n```json\n{\n  \"agent_name\": \"ExperimentalDesignVerifier\",\n  \"prompt\": \"Evaluate the paper 'Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s'. Focus on the rigor of the experimental design, the validity of the statistical analysis, and the reproducibility of the results. Pay close attention to the details of the experimental setup, the choice of baselines, and the evaluation metrics. Assess the statistical significance of the results, and provide constructive feedback.\"\n}\n```\n", "id": 0, "status": "done"}}, {"role": "tool", "content": "Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='AskAgent', response={'result': {'status': 'success', 'message': 'Agent has replied to the given prompt', 'output': 'This evaluation assesses the paper \\'Improving Aspect Ratio Distribution Fairness in Detector Pretraining via Cooperating RPN\u2019s\\' based on the provided criteria.\\n\\n---\\n\\n### Overall Assessment\\n\\nThe paper tackles a relevant and important problem in object detection: the inherent bias towards common aspect ratios (ARs) in pretraining datasets like ImageNet, which negatively impacts the detection of objects with extreme aspect ratios during finetuning. The proposed solution, using multiple \"cooperating RPNs\" each specializing in a range of aspect ratios during pretraining, is novel and intuitively appealing. The experimental setup generally covers appropriate baselines and evaluation metrics. However, there are significant areas for improvement, particularly concerning statistical rigor and the clarity of the proposed mechanism, which impact the validity of the conclusions and reproducibility.\\n\\n---\\n\\n### Rigor of Experimental Design\\n\\n1.  **Problem Formulation and Motivation:**\\n    *   **Strength:** The problem of imbalanced aspect ratio distribution and its negative impact on detector performance (especially for extreme ARs) is clearly articulated and well-motivated. The paper correctly identifies that standard ImageNet pretraining, optimized for image classification, doesn\\'t inherently prioritize diverse object shapes.\\n    *   **Strength:** The idea of addressing this at the pretraining stage, rather than solely during finetuning, is a strong point, as it aims to improve the *feature learning* itself.\\n\\n2.  **Novelty of the Proposed Method:**\\n    *   **Strength:** The concept of using multiple, specialized RPN heads, each handling a distinct range of aspect ratios, and training them cooperatively during the pretraining phase, appears novel within the context of detector pretraining. It\\'s an interesting extension of the RPN concept.\\n    *   **Clarification Needed:** The term \"cooperating RPNs\" needs more precise definition. Is it shared feature maps, joint loss optimization, or something more intricate like a competitive/collaborative learning scheme? The exact mechanism of \"cooperation\" beyond just parallel operation and joint loss summation should be clearly elucidated.\\n\\n3.  **Experimental Setup and Details:**\\n    *   **Baselines:**\\n        *   **Strength:** Comparing against standard ImageNet pretraining (e.g., using ResNet-50 ImageNet weights) is the most appropriate and crucial baseline, as it directly addresses the paper\\'s claim of improving upon existing pretraining.\\n        *   **Suggestion:** If there are other pretraining methods specifically designed to mitigate aspect ratio bias or improve general object detection features (e.g., using different sampling strategies, self-supervised pretraining methods that implicitly learn richer object representations), comparing against them would further strengthen the paper.\\n    *   **Datasets:**\\n        *   **Strength:** Using ImageNet for pretraining and COCO for finetuning is standard practice and appropriate for evaluating the transferability of learned features to object detection.\\n    *   **Model Architectures:**\\n        *   **Strength:** Evaluating on both RetinaNet (one-stage) and Faster R-CNN (two-stage) provides a good generalizability assessment of the proposed pretraining method across different detector paradigms.\\n    *   **Hyperparameters:**\\n        *   **Feedback:** It\\'s crucial to provide *all* hyperparameter details for both pretraining and finetuning for the proposed method and baselines (e.g., learning rates, schedules, optimizers, batch sizes, data augmentation strategies, number of epochs). While standard practices are often assumed, explicit mention ensures reproducibility. Any specific hyperparameters introduced by the multi-RPN setup (e.g., weights for different RPN losses) must be clearly stated and justified.\\n    *   **The Finetuning Phase:**\\n        *   **Critical Detail:** It\\'s paramount to clarify what happens to the multi-RPN structure during finetuning. Does the model revert to a single RPN head (e.g., using standard anchors)? Or does the multi-RPN structure persist? If it reverts, the improvement must stem from the backbone\\'s enhanced feature representation. If it persists, it adds complexity to the finetuned model, which should be discussed in terms of inference speed and memory. This detail is crucial for understanding *how* the pretraining method delivers its benefits.\\n\\n4.  **Ablation Studies:**\\n    *   **Strength (Assumed/Suggested):** To rigorously validate the design choices, the paper *should* include ablation studies on:\\n        *   The number of cooperating RPNs (e.g., 2, 3, 4, 5).\\n        *   The strategy for dividing aspect ratio ranges among RPNs.\\n        *   The specific \"cooperation\" mechanism (if different options were explored, e.g., different loss weighting schemes).\\n    *   **Feedback:** If these are not present, they are significant omissions. They are vital for demonstrating that the proposed specific choices are optimal and contribute to the overall improvement.\\n\\n---\\n\\n### Validity of Statistical Analysis\\n\\n1.  **Evaluation Metrics:**\\n    *   **Strength:** Mean Average Precision (mAP) is the standard metric for object detection. Crucially, reporting mAP for large objects (mAP_large) and small objects (mAP_small) directly aligns with the paper\\'s objective of improving fairness across aspect ratios, making these highly relevant metrics.\\n    *   **Suggestion:** Consider also breaking down mAP by more specific aspect ratio bins if possible, to provide an even finer-grained view of fairness improvements. Visualizations of AR distribution of *detected* bounding boxes vs. ground truth could also be insightful.\\n\\n2.  **Statistical Significance:**\\n    *   **Major Weakness:** The paper likely presents results as single mAP scores (e.g., a single number for each experiment run). This is insufficient for establishing statistical significance.\\n    *   **Feedback:**\\n        *   **Multiple Runs:** Experiments, especially those sensitive to initialization or random processes (e.g., data shuffling, network weights), *must* be run multiple times (e.g., 3-5 times) with different random seeds.\\n        *   **Mean and Standard Deviation:** Report the mean and standard deviation of the performance metrics across these multiple runs. This allows readers to gauge the variability and robustness of the results.\\n        *   **Significance Testing:** Conduct appropriate statistical tests (e.g., paired t-tests if comparing two models on the same test set, or ANOVA if comparing multiple models/variants) to determine if the observed performance differences are statistically significant (i.e., unlikely to have occurred by chance). Report p-values or confidence intervals. Without this, it\\'s impossible to definitively claim that one method is \"better\" than another, especially for small improvements.\\n\\n3.  **Interpretation of Results:**\\n    *   **Feedback:** The paper should not just report higher numbers but also interpret *why* these improvements occur. Does it truly make the feature space more isotropic or diverse for different ARs? Does it improve recall for extreme ARs without sacrificing precision?\\n\\n---\\n\\n### Reproducibility of Results\\n\\n1.  **Code Availability:**\\n    *   **Critical:** Providing a link to the source code (e.g., on GitHub) is paramount for reproducibility. This includes the implementation of the cooperating RPNs, pretraining setup, and finetuning scripts.\\n    *   **Details:** The code should ideally be well-documented and include clear instructions for setting up the environment and running the experiments.\\n\\n2.  **Configuration and Hyperparameters:**\\n    *   **Feedback:** As mentioned above, a comprehensive list of all hyperparameters, optimizer settings, learning rate schedules, data augmentation details (including transformations, resize strategies, etc.), and training configurations (e.g., number of GPUs, batch size per GPU) is essential.\\n    *   **Random Seeds:** Explicitly state whether fixed random seeds were used for all experiments. If not, results might vary significantly across different runs even on the same hardware.\\n\\n3.  **Computational Environment:**\\n    *   **Feedback:** Mentioning the specific versions of critical libraries (e.g., PyTorch/TensorFlow, torchvision, CUDA), operating system, and hardware used (e.g., GPU model, number of GPUs) can aid in reproducing results, as performance can sometimes be sensitive to these factors.\\n\\n---\\n\\n### Constructive Feedback and Suggestions for Improvement\\n\\n1.  **Strengthen Statistical Validity:** This is the most important area. Implement multiple runs with different seeds, report means and standard deviations, and conduct statistical significance tests (e.g., t-tests, ANOVA) to back up performance claims.\\n2.  **Clarify the \"Cooperation\" Mechanism:** Provide a more in-depth explanation of how the multiple RPNs truly \"cooperate\" beyond simply being trained in parallel with a combined loss. Is there feature interaction, or are they just independent branches optimizing for different targets? A conceptual diagram illustrating this would be beneficial.\\n3.  **Detailed Analysis of Mechanism:**\\n    *   **Feature Space Visualization:** Use techniques like t-SNE or UMAP on the backbone\\'s feature maps to visualize how objects with different aspect ratios are clustered or separated after pretraining with the proposed method vs. the baseline.\\n    *   **Activation Maps:** Show Grad-CAM or similar attention maps for extreme AR objects to see if the network focuses on relevant features more effectively.\\n    *   **Anchor Analysis:** Provide a more detailed analysis of how the refined anchors from the cooperating RPNs adapt to the target AR distributions, possibly by visualizing the learned anchor distributions compared to the ground truth ARs.\\n4.  **Computational Cost Analysis:** The proposed method likely increases pretraining time and potentially memory consumption due to multiple RPN heads. Quantify this cost (e.g., training time per epoch, peak memory usage) and discuss the trade-off between performance gain and computational overhead.\\n5.  **Qualitative Results:** Include qualitative examples of detections, especially for challenging extreme aspect ratio objects where the proposed method succeeds and the baseline fails. This can provide powerful visual evidence of the method\\'s effectiveness.\\n6.  **Ablation Study Expansion:** Ensure comprehensive ablation studies are conducted for the number of RPNs, the AR partitioning strategy, and any weighting schemes for the RPN losses.\\n7.  **Finetuning RPN Configuration:** Explicitly state whether the finetuned detector uses a single RPN or continues to use the multi-RPN structure. This has implications for inference speed and model complexity. If it reverts to a single RPN, discuss how the pretraining benefits transfer.\\n8.  **Broader Comparison:** If relevant, compare against other existing methods that aim to balance aspect ratios (e.g., specific data augmentation techniques, sampling strategies, or other pretraining methods that implicitly improve feature diversity).\\n9.  **Generalizability Beyond COCO:** While COCO is standard, briefly discuss potential applicability or limitations for highly specialized domains where AR distributions might be even more skewed (e.g., specific industrial inspection datasets).\\n\\nBy addressing these points, the paper can significantly enhance its scientific rigor, provide stronger evidence for its claims, and improve its overall impact and reproducibility.', 'remaining_resource_budget': 100, 'remaining_expense_budget': 9999.89229845}}), inline_data=None, text=None)], role='tool')"}, {"role": "assistant", "content": "Now that I have received the evaluations from the three reviewer agents, I will synthesize their feedback and make a final decision.\n\nThe agents agree that the paper addresses an important problem: the bias of object detectors towards familiar aspect ratio distributions, leading to unfair performance on objects with less common aspect ratios. The proposed CoRPN approach is considered novel and promising. The ARShift benchmark is a valuable contribution for evaluating fairness in object detection.\n\nHowever, the agents also raised several concerns:\n\n*   **ObjectDetectionExpert:** Requires more clarity on the training mechanism and role of RPN\\_aux, the cooperation mechanism, and the computational overhead.\n*   **FairnessEvaluator:** Suggests generalizing the approach to other fairness dimensions (object size, occlusion, viewpoint, rare classes), adaptive thresholding and branch assignment, and cascading fairness to other stages of the detection pipeline.\n*   **ExperimentalDesignVerifier:** Emphasizes the need for statistical significance testing (multiple runs, mean and standard deviation, p-values), more detailed analysis of the mechanism, and comprehensive ablation studies. Also, the agent requires clarification on the RPN configuration during finetuning.\n\nOverall, the paper presents a novel approach with promising results, but the concerns raised by the reviewers need to be addressed to strengthen the paper's claims and improve its reproducibility. The lack of statistical significance testing is a major weakness.\n\nGiven the potential of the approach and the constructive feedback provided by the reviewers, I recommend a major revision.\n\nFINAL DECISION: Reject\n"}], "ground_truth": "Reject", "response_history": "Now that I have received the evaluations from the three reviewer agents, I will synthesize their feedback and make a final decision.\n\nThe agents agree that the paper addresses an important problem: the bias of object detectors towards familiar aspect ratio distributions, leading to unfair performance on objects with less common aspect ratios. The proposed CoRPN approach is considered novel and promising. The ARShift benchmark is a valuable contribution for evaluating fairness in object detection.\n\nHowever, the agents also raised several concerns:\n\n*   **ObjectDetectionExpert:** Requires more clarity on the training mechanism and role of RPN\\_aux, the cooperation mechanism, and the computational overhead.\n*   **FairnessEvaluator:** Suggests generalizing the approach to other fairness dimensions (object size, occlusion, viewpoint, rare classes), adaptive thresholding and branch assignment, and cascading fairness to other stages of the detection pipeline.\n*   **ExperimentalDesignVerifier:** Emphasizes the need for statistical significance testing (multiple runs, mean and standard deviation, p-values), more detailed analysis of the mechanism, and comprehensive ablation studies. Also, the agent requires clarification on the RPN configuration during finetuning.\n\nOverall, the paper presents a novel approach with promising results, but the concerns raised by the reviewers need to be addressed to strengthen the paper's claims and improve its reproducibility. The lack of statistical significance testing is a major weakness.\n\nGiven the potential of the approach and the constructive feedback provided by the reviewers, I recommend a major revision.\n\nFINAL DECISION: Reject\n", "elapsed_time": 120.9181809425354, "reviewer_agents": {"ObjectDetectionExpert": {"base_model": "gemini-2.5-flash-preview-05-20", "description": "Expert in object detection and region proposal networks.", "system_prompt": "You are an expert in object detection and region proposal networks. You will evaluate the paper based on the novelty of the approach, the correctness of the methodology, and the significance of the results. Pay close attention to the details of the proposed CoRPN and its advantages over existing methods. Assess the experimental setup and results, and provide constructive feedback on how to improve the paper.", "create_resource_cost": 0, "invoke_resource_cost": 0, "create_expense_cost": 0, "invoke_expense_cost": 0.15, "output_expense_cost": 0.6}, "FairnessEvaluator": {"base_model": "gemini-2.5-flash-preview-05-20", "description": "Expert in fairness and distribution shift in machine learning.", "system_prompt": "You are an expert in fairness and distribution shift in machine learning. You will evaluate the paper based on the fairness of the proposed approach, the severity of the distribution shift, and the effectiveness of the proposed CoRPN in mitigating the unfairness. Pay close attention to the details of the ARShift benchmark and its significance in evaluating the fairness of object detectors. Assess the experimental results on the ARShift benchmark, and provide constructive feedback on how to improve the fairness of object detectors.", "create_resource_cost": 0, "invoke_resource_cost": 0, "create_expense_cost": 0, "invoke_expense_cost": 0.15, "output_expense_cost": 0.6}, "ExperimentalDesignVerifier": {"base_model": "gemini-2.5-flash-preview-05-20", "description": "Expert in experimental design and statistical analysis.", "system_prompt": "You are an expert in experimental design and statistical analysis. You will evaluate the paper based on the rigor of the experimental design, the validity of the statistical analysis, and the reproducibility of the results. Pay close attention to the details of the experimental setup, the choice of baselines, and the evaluation metrics. Assess the statistical significance of the results, and provide constructive feedback on how to improve the experimental design and statistical analysis.", "create_resource_cost": 0, "invoke_resource_cost": 0, "create_expense_cost": 0, "invoke_expense_cost": 0.15, "output_expense_cost": 0.6}}}
